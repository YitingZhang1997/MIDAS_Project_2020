{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tensorflow_federated_nightly also bring in tf_nightly, which\n",
    "# # can causes a duplicate tensorboard install, leading to errors.\n",
    "# !pip uninstall --yes tensorboard tb-nightly\n",
    "\n",
    "# !pip install --quiet --upgrade tensorflow_federated_nightly\n",
    "# !pip install --quiet --upgrade nest_asyncio\n",
    "# !pip install --quiet tb-nightly  # or tensorboard, but not both\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yitzhang/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:43: UserWarning: You are currently using a nightly version of TensorFlow (2.5.0-dev20210103). \n",
      "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
      "If you encounter a bug, do not file an issue on GitHub.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yitzhang/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:59: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yitzhang/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:59: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'Hello, World!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "tff.federated_computation(lambda: 'Hello, World!')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "filename = 'BRAZPD_UnofM_all.csv'\n",
    "\n",
    "df = pd.read_csv(filename, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODPAX</th>\n",
       "      <th>Hemoglobin</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Phosphate</th>\n",
       "      <th>Mean_PAS_1T</th>\n",
       "      <th>Mean_PAD_1T</th>\n",
       "      <th>Mean_PAS_2T</th>\n",
       "      <th>Mean_PAD_2T</th>\n",
       "      <th>Mean_PAS_3T</th>\n",
       "      <th>Mean_PAD_3T</th>\n",
       "      <th>...</th>\n",
       "      <th>Diastolic70</th>\n",
       "      <th>Systolic71</th>\n",
       "      <th>Diastolic71</th>\n",
       "      <th>Systolic72</th>\n",
       "      <th>Diastolic72</th>\n",
       "      <th>Systolic73</th>\n",
       "      <th>Diastolic73</th>\n",
       "      <th>Systolic74</th>\n",
       "      <th>Diastolic74</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1349037</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>110.500000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1349040</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.766667</td>\n",
       "      <td>5.933333</td>\n",
       "      <td>129.500000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>120.333333</td>\n",
       "      <td>68.666667</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1349048</td>\n",
       "      <td>11.833333</td>\n",
       "      <td>4.366667</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>154.666667</td>\n",
       "      <td>87.666667</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1349051</td>\n",
       "      <td>10.066667</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>147.333333</td>\n",
       "      <td>92.333333</td>\n",
       "      <td>169.333333</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1349055</td>\n",
       "      <td>11.933333</td>\n",
       "      <td>4.033333</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>103.500000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>154.666667</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>129.333333</td>\n",
       "      <td>72.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>347457070</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>347457071</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>3.233333</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>113.333333</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>347457072</td>\n",
       "      <td>10.466667</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>4.466667</td>\n",
       "      <td>136.666667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>143.333333</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>347457073</td>\n",
       "      <td>11.766667</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>136.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>347457074</td>\n",
       "      <td>9.866667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5707 rows × 1735 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CODPAX  Hemoglobin  Potassium  Phosphate  Mean_PAS_1T  Mean_PAD_1T  \\\n",
       "0       1349037   12.933333   4.433333   5.300000   110.500000    70.000000   \n",
       "1       1349040   14.000000   3.766667   5.933333   129.500000    77.000000   \n",
       "2       1349048   11.833333   4.366667   6.100000   158.000000    81.000000   \n",
       "3       1349051   10.066667   4.733333   5.533333   140.000000    75.000000   \n",
       "4       1349055   11.933333   4.033333   4.066667   103.500000    60.000000   \n",
       "...         ...         ...        ...        ...          ...          ...   \n",
       "5702  347457070    8.400000   5.500000   4.700000   126.666667    76.666667   \n",
       "5703  347457071    9.700000   4.300000   3.233333   130.000000    80.000000   \n",
       "5704  347457072   10.466667   4.433333   4.466667   136.666667    80.000000   \n",
       "5705  347457073   11.766667   4.533333   3.566667   126.666667    80.000000   \n",
       "5706  347457074    9.866667   4.000000   4.100000   126.666667    80.000000   \n",
       "\n",
       "      Mean_PAS_2T  Mean_PAD_2T  Mean_PAS_3T  Mean_PAD_3T  ...  Diastolic70  \\\n",
       "0      125.000000    80.000000          NaN          NaN  ...          NaN   \n",
       "1      120.333333    68.666667   136.000000    82.000000  ...          NaN   \n",
       "2      154.666667    87.666667   147.000000    80.000000  ...          NaN   \n",
       "3      147.333333    92.333333   169.333333    99.000000  ...          NaN   \n",
       "4      154.666667    82.000000   129.333333    72.666667  ...          NaN   \n",
       "...           ...          ...          ...          ...  ...          ...   \n",
       "5702   126.666667    83.333333   120.000000    80.000000  ...          NaN   \n",
       "5703   113.333333    73.333333          NaN          NaN  ...          NaN   \n",
       "5704   143.333333    73.333333          NaN          NaN  ...          NaN   \n",
       "5705   136.666667    83.333333          NaN          NaN  ...          NaN   \n",
       "5706   130.000000    76.666667          NaN          NaN  ...          NaN   \n",
       "\n",
       "      Systolic71  Diastolic71  Systolic72  Diastolic72  Systolic73  \\\n",
       "0            NaN          NaN         NaN          NaN         NaN   \n",
       "1            NaN          NaN         NaN          NaN         NaN   \n",
       "2            NaN          NaN         NaN          NaN         NaN   \n",
       "3            NaN          NaN         NaN          NaN         NaN   \n",
       "4            NaN          NaN         NaN          NaN         NaN   \n",
       "...          ...          ...         ...          ...         ...   \n",
       "5702         NaN          NaN         NaN          NaN         NaN   \n",
       "5703         NaN          NaN         NaN          NaN         NaN   \n",
       "5704         NaN          NaN         NaN          NaN         NaN   \n",
       "5705         NaN          NaN         NaN          NaN         NaN   \n",
       "5706         NaN          NaN         NaN          NaN         NaN   \n",
       "\n",
       "      Diastolic73  Systolic74  Diastolic74  _merge  \n",
       "0             NaN         NaN          NaN       3  \n",
       "1             NaN         NaN          NaN       3  \n",
       "2             NaN         NaN          NaN       3  \n",
       "3             NaN         NaN          NaN       3  \n",
       "4             NaN         NaN          NaN       3  \n",
       "...           ...         ...          ...     ...  \n",
       "5702          NaN         NaN          NaN       3  \n",
       "5703          NaN         NaN          NaN       3  \n",
       "5704          NaN         NaN          NaN       3  \n",
       "5705          NaN         NaN          NaN       3  \n",
       "5706          NaN         NaN          NaN       3  \n",
       "\n",
       "[5707 rows x 1735 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODPAX</th>\n",
       "      <th>Hemoglobin</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Phosphate</th>\n",
       "      <th>Mean_PAS_1T</th>\n",
       "      <th>Mean_PAD_1T</th>\n",
       "      <th>Mean_PAS_2T</th>\n",
       "      <th>Mean_PAD_2T</th>\n",
       "      <th>Mean_PAS_3T</th>\n",
       "      <th>Mean_PAD_3T</th>\n",
       "      <th>...</th>\n",
       "      <th>OUTROS65</th>\n",
       "      <th>OUTROS66</th>\n",
       "      <th>OUTROS67</th>\n",
       "      <th>OUTROS68</th>\n",
       "      <th>OUTROS69</th>\n",
       "      <th>OUTROS70</th>\n",
       "      <th>OUTROS71</th>\n",
       "      <th>OUTROS72</th>\n",
       "      <th>OUTROS73</th>\n",
       "      <th>OUTROS74</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1349037</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>110.500000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1349040</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.766667</td>\n",
       "      <td>5.933333</td>\n",
       "      <td>129.500000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>120.333333</td>\n",
       "      <td>68.666667</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1349048</td>\n",
       "      <td>11.833333</td>\n",
       "      <td>4.366667</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>154.666667</td>\n",
       "      <td>87.666667</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1349051</td>\n",
       "      <td>10.066667</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>147.333333</td>\n",
       "      <td>92.333333</td>\n",
       "      <td>169.333333</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1349055</td>\n",
       "      <td>11.933333</td>\n",
       "      <td>4.033333</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>103.500000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>154.666667</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>129.333333</td>\n",
       "      <td>72.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>347457070</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>347457071</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>3.233333</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>113.333333</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>347457072</td>\n",
       "      <td>10.466667</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>4.466667</td>\n",
       "      <td>136.666667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>143.333333</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>347457073</td>\n",
       "      <td>11.766667</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>136.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>347457074</td>\n",
       "      <td>9.866667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5707 rows × 1735 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CODPAX  Hemoglobin  Potassium  Phosphate  Mean_PAS_1T  Mean_PAD_1T  \\\n",
       "0       1349037   12.933333   4.433333   5.300000   110.500000    70.000000   \n",
       "1       1349040   14.000000   3.766667   5.933333   129.500000    77.000000   \n",
       "2       1349048   11.833333   4.366667   6.100000   158.000000    81.000000   \n",
       "3       1349051   10.066667   4.733333   5.533333   140.000000    75.000000   \n",
       "4       1349055   11.933333   4.033333   4.066667   103.500000    60.000000   \n",
       "...         ...         ...        ...        ...          ...          ...   \n",
       "5702  347457070    8.400000   5.500000   4.700000   126.666667    76.666667   \n",
       "5703  347457071    9.700000   4.300000   3.233333   130.000000    80.000000   \n",
       "5704  347457072   10.466667   4.433333   4.466667   136.666667    80.000000   \n",
       "5705  347457073   11.766667   4.533333   3.566667   126.666667    80.000000   \n",
       "5706  347457074    9.866667   4.000000   4.100000   126.666667    80.000000   \n",
       "\n",
       "      Mean_PAS_2T  Mean_PAD_2T  Mean_PAS_3T  Mean_PAD_3T  ...  OUTROS65  \\\n",
       "0      125.000000    80.000000          NaN          NaN  ...         0   \n",
       "1      120.333333    68.666667   136.000000    82.000000  ...         0   \n",
       "2      154.666667    87.666667   147.000000    80.000000  ...         0   \n",
       "3      147.333333    92.333333   169.333333    99.000000  ...         0   \n",
       "4      154.666667    82.000000   129.333333    72.666667  ...         0   \n",
       "...           ...          ...          ...          ...  ...       ...   \n",
       "5702   126.666667    83.333333   120.000000    80.000000  ...         0   \n",
       "5703   113.333333    73.333333          NaN          NaN  ...         0   \n",
       "5704   143.333333    73.333333          NaN          NaN  ...         0   \n",
       "5705   136.666667    83.333333          NaN          NaN  ...         0   \n",
       "5706   130.000000    76.666667          NaN          NaN  ...         0   \n",
       "\n",
       "      OUTROS66  OUTROS67  OUTROS68  OUTROS69  OUTROS70  OUTROS71  OUTROS72  \\\n",
       "0            0         0         0         0         0         0         0   \n",
       "1            0         0         0         0         0         0         0   \n",
       "2            0         0         0         0         0         0         0   \n",
       "3            0         0         0         0         0         0         0   \n",
       "4            0         0         0         0         0         0         0   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5702         0         0         0         0         0         0         0   \n",
       "5703         0         0         0         0         0         0         0   \n",
       "5704         0         0         0         0         0         0         0   \n",
       "5705         0         0         0         0         0         0         0   \n",
       "5706         0         0         0         0         0         0         0   \n",
       "\n",
       "      OUTROS73  OUTROS74  \n",
       "0            0         0  \n",
       "1            0         0  \n",
       "2            0         0  \n",
       "3            0         0  \n",
       "4            0         0  \n",
       "...        ...       ...  \n",
       "5702         0         0  \n",
       "5703         0         0  \n",
       "5704         0         0  \n",
       "5705         0         0  \n",
       "5706         0         0  \n",
       "\n",
       "[5707 rows x 1735 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "nMeasurements = 75\n",
    "nColumns = 1735\n",
    "nRecords = 5707\n",
    "timeseries_names = ['Ureia', 'Creatinine', 'TGP', 'Potassium', 'Calcium', 'Phosphate', 'Glucose', \n",
    "              'Hemoglobin', 'Hematocrit','Volume_Total', 'Systolic', 'Diastolic', 'N_AH_']\n",
    "\n",
    "different_format_ts_names = ['Mes_1_PAS', 'Mes_1_PAD', 'Mes_1_Uso_de_anti_hipert', 'Mes_1_inibidor',\\\n",
    "                             'Mes_1_beta', 'Mes_1_ant', 'Mes_1_diu', 'Mes_1_at_i', 'Mes_1_OUTROS']\n",
    "\n",
    "# Put timeseries names into standard format\n",
    "p = re.compile('[0-9]')\n",
    "strip = re.compile('Mes_[0-9]_')\n",
    "for timeseries in different_format_ts_names:\n",
    "    for i in range(1,nMeasurements):\n",
    "        try:\n",
    "            old_label = p.sub(str(i), timeseries)\n",
    "            new_label = strip.sub('',timeseries)\n",
    "            df[new_label+str(i)] = pd.Series(df[old_label])\n",
    "            df.drop([old_label],axis=1, inplace=True)\n",
    "        except:\n",
    "            print(f'Column {timeseries}{i} does not exist')\n",
    "    timeseries_names.append(new_label)\n",
    "    \n",
    "# make sure we don't have duplicate columns\n",
    "assert nColumns == df.shape[1]\n",
    "\n",
    "rename_dict = dict()\n",
    "rename_keys = {\"Uso_de_anti_hipert\": \"Use antihypertensive drug\",\\\n",
    "               \"inibidor\": \"ACE-inhibitor\",\\\n",
    "               \"at_i\": \"ATI blocker\",\\\n",
    "               \"beta\": \"beta-blocker\",\\\n",
    "               \"ant\": \"calcium antagonist\",\\\n",
    "               \"diu\": \"diuretic\"}\n",
    "for item in rename_keys.items():\n",
    "    key, value = item\n",
    "    for i in range(74):\n",
    "        new_key = key+str(i+1)\n",
    "        new_value = value+str(i+1)\n",
    "        rename_dict[new_key] = new_value\n",
    "        \n",
    "df = df.rename(columns=rename_dict)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODPAX</th>\n",
       "      <th>Hemoglobin</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Phosphate</th>\n",
       "      <th>Mean_PAS_1T</th>\n",
       "      <th>Mean_PAD_1T</th>\n",
       "      <th>Mean_PAS_2T</th>\n",
       "      <th>Mean_PAD_2T</th>\n",
       "      <th>Mean_PAS_3T</th>\n",
       "      <th>Mean_PAD_3T</th>\n",
       "      <th>...</th>\n",
       "      <th>OUTROS70</th>\n",
       "      <th>OUTROS71</th>\n",
       "      <th>OUTROS72</th>\n",
       "      <th>OUTROS73</th>\n",
       "      <th>OUTROS74</th>\n",
       "      <th>Primary renal disease (Diabetes)</th>\n",
       "      <th>Primary renal disease (Hypertension)</th>\n",
       "      <th>Primary renal disease (CGN (including LES))</th>\n",
       "      <th>Primary renal disease (Unknown)</th>\n",
       "      <th>Primary renal disease (Others)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1349037</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>110.500000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1349040</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.766667</td>\n",
       "      <td>5.933333</td>\n",
       "      <td>129.500000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>120.333333</td>\n",
       "      <td>68.666667</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1349048</td>\n",
       "      <td>11.833333</td>\n",
       "      <td>4.366667</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>154.666667</td>\n",
       "      <td>87.666667</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1349051</td>\n",
       "      <td>10.066667</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>147.333333</td>\n",
       "      <td>92.333333</td>\n",
       "      <td>169.333333</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1349055</td>\n",
       "      <td>11.933333</td>\n",
       "      <td>4.033333</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>103.500000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>154.666667</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>129.333333</td>\n",
       "      <td>72.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>347457070</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>347457071</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>3.233333</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>113.333333</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>347457072</td>\n",
       "      <td>10.466667</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>4.466667</td>\n",
       "      <td>136.666667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>143.333333</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>347457073</td>\n",
       "      <td>11.766667</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>136.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>347457074</td>\n",
       "      <td>9.866667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5707 rows × 1740 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CODPAX  Hemoglobin  Potassium  Phosphate  Mean_PAS_1T  Mean_PAD_1T  \\\n",
       "0       1349037   12.933333   4.433333   5.300000   110.500000    70.000000   \n",
       "1       1349040   14.000000   3.766667   5.933333   129.500000    77.000000   \n",
       "2       1349048   11.833333   4.366667   6.100000   158.000000    81.000000   \n",
       "3       1349051   10.066667   4.733333   5.533333   140.000000    75.000000   \n",
       "4       1349055   11.933333   4.033333   4.066667   103.500000    60.000000   \n",
       "...         ...         ...        ...        ...          ...          ...   \n",
       "5702  347457070    8.400000   5.500000   4.700000   126.666667    76.666667   \n",
       "5703  347457071    9.700000   4.300000   3.233333   130.000000    80.000000   \n",
       "5704  347457072   10.466667   4.433333   4.466667   136.666667    80.000000   \n",
       "5705  347457073   11.766667   4.533333   3.566667   126.666667    80.000000   \n",
       "5706  347457074    9.866667   4.000000   4.100000   126.666667    80.000000   \n",
       "\n",
       "      Mean_PAS_2T  Mean_PAD_2T  Mean_PAS_3T  Mean_PAD_3T  ...  OUTROS70  \\\n",
       "0      125.000000    80.000000     0.000000     0.000000  ...         0   \n",
       "1      120.333333    68.666667   136.000000    82.000000  ...         0   \n",
       "2      154.666667    87.666667   147.000000    80.000000  ...         0   \n",
       "3      147.333333    92.333333   169.333333    99.000000  ...         0   \n",
       "4      154.666667    82.000000   129.333333    72.666667  ...         0   \n",
       "...           ...          ...          ...          ...  ...       ...   \n",
       "5702   126.666667    83.333333   120.000000    80.000000  ...         0   \n",
       "5703   113.333333    73.333333     0.000000     0.000000  ...         0   \n",
       "5704   143.333333    73.333333     0.000000     0.000000  ...         0   \n",
       "5705   136.666667    83.333333     0.000000     0.000000  ...         0   \n",
       "5706   130.000000    76.666667     0.000000     0.000000  ...         0   \n",
       "\n",
       "      OUTROS71  OUTROS72  OUTROS73  OUTROS74  \\\n",
       "0            0         0         0         0   \n",
       "1            0         0         0         0   \n",
       "2            0         0         0         0   \n",
       "3            0         0         0         0   \n",
       "4            0         0         0         0   \n",
       "...        ...       ...       ...       ...   \n",
       "5702         0         0         0         0   \n",
       "5703         0         0         0         0   \n",
       "5704         0         0         0         0   \n",
       "5705         0         0         0         0   \n",
       "5706         0         0         0         0   \n",
       "\n",
       "      Primary renal disease (Diabetes)  Primary renal disease (Hypertension)  \\\n",
       "0                                  1.0                                   0.0   \n",
       "1                                  0.0                                   0.0   \n",
       "2                                  1.0                                   0.0   \n",
       "3                                  1.0                                   0.0   \n",
       "4                                  0.0                                   1.0   \n",
       "...                                ...                                   ...   \n",
       "5702                               0.0                                   1.0   \n",
       "5703                               0.0                                   0.0   \n",
       "5704                               0.0                                   0.0   \n",
       "5705                               0.0                                   0.0   \n",
       "5706                               1.0                                   0.0   \n",
       "\n",
       "      Primary renal disease (CGN (including LES))  \\\n",
       "0                                             0.0   \n",
       "1                                             0.0   \n",
       "2                                             0.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "...                                           ...   \n",
       "5702                                          0.0   \n",
       "5703                                          0.0   \n",
       "5704                                          0.0   \n",
       "5705                                          0.0   \n",
       "5706                                          0.0   \n",
       "\n",
       "      Primary renal disease (Unknown)  Primary renal disease (Others)  \n",
       "0                                 0.0                             0.0  \n",
       "1                                 1.0                             0.0  \n",
       "2                                 0.0                             0.0  \n",
       "3                                 0.0                             0.0  \n",
       "4                                 0.0                             0.0  \n",
       "...                               ...                             ...  \n",
       "5702                              0.0                             0.0  \n",
       "5703                              0.0                             1.0  \n",
       "5704                              0.0                             1.0  \n",
       "5705                              0.0                             1.0  \n",
       "5706                              0.0                             0.0  \n",
       "\n",
       "[5707 rows x 1740 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Primaryrenaldisease']==81,'Primary renal disease (Diabetes)'] = 1\n",
    "\n",
    "df.loc[df['Primaryrenaldisease']==100,'Primary renal disease (Hypertension)'] = 1\n",
    "\n",
    "df.loc[df['Primaryrenaldisease']==13,'Primary renal disease (CGN (including LES))'] = 1\n",
    "df.loc[df['Primaryrenaldisease']==10,'Primary renal disease (CGN (including LES))'] = 1\n",
    "\n",
    "df.loc[df['Primaryrenaldisease']==0,'Primary renal disease (Unknown)'] = 1\n",
    "\n",
    "df.loc[df['Primaryrenaldisease']==20,'Primary renal disease (Others)'] = 1\n",
    "df.loc[df['Primaryrenaldisease']==20,'Primary renal disease (Others)'] = 1\n",
    "df.loc[df['Primaryrenaldisease']==30,'Primary renal disease (Others)'] = 1\n",
    "df.loc[df['Primaryrenaldisease']==40,'Primary renal disease (Others)'] = 1\n",
    "df.loc[df['Primaryrenaldisease']==42,'Primary renal disease (Others)'] = 1\n",
    "df.loc[df['Primaryrenaldisease']==50,'Primary renal disease (Others)'] = 1\n",
    "df.loc[df['Primaryrenaldisease']==70,'Primary renal disease (Others)'] = 1\n",
    "\n",
    "df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection and Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hemoglobin', 'Potassium', 'Phosphate', 'FRR', 'codigoclinica', 'ModalidadeCAPD0APD1Mix2', 'CenterSizenpatients', 'ModalidadeDPInicial', 'Age', 'BMI', 'IncidentinPD', 'PrevalentinPDNet', 'DialysisvintageprePDNet', 'totaldialysisvintage', 'Primary renal disease (Diabetes)', 'Primary renal disease (Hypertension)', 'Primary renal disease (CGN (including LES))', 'Primary renal disease (Unknown)', 'Primary renal disease (Others)', 'PreviousHD', 'Previoustx', 'DaviesScore', 'Peripheralarterydisease', 'DM', 'CAD', 'LVH', 'LES', 'HF', 'Cancer', 'Stroke', 'Hypertension', 'HIV', 'HCV', 'HBC', 'Gender', 'Familyincome', 'Distancefromcenter', 'predialysiscare', 'timeofpredialysiscare', 'Racedicwhite', 'Educationdic4y', 'Region', 'Centerexperiencepatientyear', 'Regionsdic', 'cidade']\n",
      "['Mean_PAS_1T', 'Mean_PAD_1T', 'Mean_PAS_2T', 'Mean_PAD_2T', 'Mean_PAS_3T', 'Mean_PAD_3T', 'Mean_PAS_4T', 'Mean_PAD_4T', 'Mean_PAS_5T', 'Mean_PAD_5T', 'Mean_PAS_6T', 'Mean_PAD_6T', 'Mean_PAS_7T', 'Mean_PAD_7T', 'Mean_PAS_8T', 'Mean_PAD_8T', 'CR_death_event_1y', 'CR_death_event_2y', 'CR_death_event_3y', 'Group_2T', 'Group_3T', 'Ureia1', 'Creatinine1', 'TGP1', 'Potassium1', 'Calcium1', 'Phosphate1', 'Glucose1', 'Hemoglobin1', 'Hematocrit1', 'Ureia2', 'Creatinine2', 'TGP2', 'Potassium2', 'Calcium2', 'Phosphate2', 'Glucose2', 'Hemoglobin2', 'Hematocrit2', 'Ureia3', 'Creatinine3', 'TGP3', 'Potassium3', 'Calcium3', 'Phosphate3', 'Glucose3', 'Hemoglobin3', 'Hematocrit3', 'Ureia4', 'Creatinine4', 'TGP4', 'Potassium4', 'Calcium4', 'Phosphate4', 'Glucose4', 'Hemoglobin4', 'Hematocrit4', 'Ureia5', 'Creatinine5', 'TGP5', 'Potassium5', 'Calcium5', 'Phosphate5', 'Glucose5', 'Hemoglobin5', 'Hematocrit5', 'Ureia6', 'Creatinine6', 'TGP6', 'Potassium6', 'Calcium6', 'Phosphate6', 'Glucose6', 'Hemoglobin6', 'Hematocrit6', 'Ureia7', 'Creatinine7', 'TGP7', 'Potassium7', 'Calcium7', 'Phosphate7', 'Glucose7', 'Hemoglobin7', 'Hematocrit7', 'Ureia8', 'Creatinine8', 'TGP8', 'Potassium8', 'Calcium8', 'Phosphate8', 'Glucose8', 'Hemoglobin8', 'Hematocrit8', 'Ureia9', 'Creatinine9', 'TGP9', 'Potassium9', 'Calcium9', 'Phosphate9', 'Glucose9', 'Hemoglobin9', 'Hematocrit9', 'Ureia10', 'Creatinine10', 'TGP10', 'Potassium10', 'Calcium10', 'Phosphate10', 'Glucose10', 'Hemoglobin10', 'Hematocrit10', 'Ureia11', 'Creatinine11', 'TGP11', 'Potassium11', 'Calcium11', 'Phosphate11', 'Glucose11', 'Hemoglobin11', 'Hematocrit11', 'Ureia12', 'Creatinine12', 'TGP12', 'Potassium12', 'Calcium12', 'Phosphate12', 'Glucose12', 'Hemoglobin12', 'Hematocrit12', 'Ureia13', 'Creatinine13', 'TGP13', 'Potassium13', 'Calcium13', 'Phosphate13', 'Glucose13', 'Hemoglobin13', 'Hematocrit13', 'Ureia14', 'Creatinine14', 'TGP14', 'Potassium14', 'Calcium14', 'Phosphate14', 'Glucose14', 'Hemoglobin14', 'Hematocrit14', 'Ureia15', 'Creatinine15', 'TGP15', 'Potassium15', 'Calcium15', 'Phosphate15', 'Glucose15', 'Hemoglobin15', 'Hematocrit15', 'Ureia16', 'Creatinine16', 'TGP16', 'Potassium16', 'Calcium16', 'Phosphate16', 'Glucose16', 'Hemoglobin16', 'Hematocrit16', 'Ureia17', 'Creatinine17', 'TGP17', 'Potassium17', 'Calcium17', 'Phosphate17', 'Glucose17', 'Hemoglobin17', 'Hematocrit17', 'Ureia18', 'Creatinine18', 'TGP18', 'Potassium18', 'Calcium18', 'Phosphate18', 'Glucose18', 'Hemoglobin18', 'Hematocrit18', 'Ureia19', 'Creatinine19', 'TGP19', 'Potassium19', 'Calcium19', 'Phosphate19', 'Glucose19', 'Hemoglobin19', 'Hematocrit19', 'Ureia20', 'Creatinine20', 'TGP20', 'Potassium20', 'Calcium20', 'Phosphate20', 'Glucose20', 'Hemoglobin20', 'Hematocrit20', 'Ureia21', 'Creatinine21', 'TGP21', 'Potassium21', 'Calcium21', 'Phosphate21', 'Glucose21', 'Hemoglobin21', 'Hematocrit21', 'Ureia22', 'Creatinine22', 'TGP22', 'Potassium22', 'Calcium22', 'Phosphate22', 'Glucose22', 'Hemoglobin22', 'Hematocrit22', 'Ureia23', 'Creatinine23', 'TGP23', 'Potassium23', 'Calcium23', 'Phosphate23', 'Glucose23', 'Hemoglobin23', 'Hematocrit23', 'Ureia24', 'Creatinine24', 'TGP24', 'Potassium24', 'Calcium24', 'Phosphate24', 'Glucose24', 'Hemoglobin24', 'Hematocrit24', 'Ureia25', 'Creatinine25', 'TGP25', 'Potassium25', 'Calcium25', 'Phosphate25', 'Glucose25', 'Hemoglobin25', 'Hematocrit25', 'Ureia26', 'Creatinine26', 'TGP26', 'Potassium26', 'Calcium26', 'Phosphate26', 'Glucose26', 'Hemoglobin26', 'Hematocrit26', 'Ureia27', 'Creatinine27', 'TGP27', 'Potassium27', 'Calcium27', 'Phosphate27', 'Glucose27', 'Hemoglobin27', 'Hematocrit27', 'Ureia28', 'Creatinine28', 'TGP28', 'Potassium28', 'Calcium28', 'Phosphate28', 'Glucose28', 'Hemoglobin28', 'Hematocrit28', 'Ureia29', 'Creatinine29', 'TGP29', 'Potassium29', 'Calcium29', 'Phosphate29', 'Glucose29', 'Hemoglobin29', 'Hematocrit29', 'Ureia30', 'Creatinine30', 'TGP30', 'Potassium30', 'Calcium30', 'Phosphate30', 'Glucose30', 'Hemoglobin30', 'Hematocrit30', 'Ureia31', 'Creatinine31', 'TGP31', 'Potassium31', 'Calcium31', 'Phosphate31', 'Glucose31', 'Hemoglobin31', 'Hematocrit31', 'Ureia32', 'Creatinine32', 'TGP32', 'Potassium32', 'Calcium32', 'Phosphate32', 'Glucose32', 'Hemoglobin32', 'Hematocrit32', 'Ureia33', 'Creatinine33', 'TGP33', 'Potassium33', 'Calcium33', 'Phosphate33', 'Glucose33', 'Hemoglobin33', 'Hematocrit33', 'Ureia34', 'Creatinine34', 'TGP34', 'Potassium34', 'Calcium34', 'Phosphate34', 'Glucose34', 'Hemoglobin34', 'Hematocrit34', 'Ureia35', 'Creatinine35', 'TGP35', 'Potassium35', 'Calcium35', 'Phosphate35', 'Glucose35', 'Hemoglobin35', 'Hematocrit35', 'Ureia36', 'Creatinine36', 'TGP36', 'Potassium36', 'Calcium36', 'Phosphate36', 'Glucose36', 'Hemoglobin36', 'Hematocrit36', 'Ureia37', 'Creatinine37', 'TGP37', 'Potassium37', 'Calcium37', 'Phosphate37', 'Glucose37', 'Hemoglobin37', 'Hematocrit37', 'Ureia38', 'Creatinine38', 'TGP38', 'Potassium38', 'Calcium38', 'Phosphate38', 'Glucose38', 'Hemoglobin38', 'Hematocrit38', 'Ureia39', 'Creatinine39', 'TGP39', 'Potassium39', 'Calcium39', 'Phosphate39', 'Glucose39', 'Hemoglobin39', 'Hematocrit39', 'Ureia40', 'Creatinine40', 'TGP40', 'Potassium40', 'Calcium40', 'Phosphate40', 'Glucose40', 'Hemoglobin40', 'Hematocrit40', 'Ureia41', 'Creatinine41', 'TGP41', 'Potassium41', 'Calcium41', 'Phosphate41', 'Glucose41', 'Hemoglobin41', 'Hematocrit41', 'Ureia42', 'Creatinine42', 'TGP42', 'Potassium42', 'Calcium42', 'Phosphate42', 'Glucose42', 'Hemoglobin42', 'Hematocrit42', 'Ureia43', 'Creatinine43', 'TGP43', 'Potassium43', 'Calcium43', 'Phosphate43', 'Glucose43', 'Hemoglobin43', 'Hematocrit43', 'Ureia44', 'Creatinine44', 'TGP44', 'Potassium44', 'Calcium44', 'Phosphate44', 'Glucose44', 'Hemoglobin44', 'Hematocrit44', 'Ureia45', 'Creatinine45', 'TGP45', 'Potassium45', 'Calcium45', 'Phosphate45', 'Glucose45', 'Hemoglobin45', 'Hematocrit45', 'Ureia46', 'Creatinine46', 'TGP46', 'Potassium46', 'Calcium46', 'Phosphate46', 'Glucose46', 'Hemoglobin46', 'Hematocrit46', 'Ureia47', 'Creatinine47', 'TGP47', 'Potassium47', 'Calcium47', 'Phosphate47', 'Glucose47', 'Hemoglobin47', 'Hematocrit47', 'Ureia48', 'Creatinine48', 'TGP48', 'Potassium48', 'Calcium48', 'Phosphate48', 'Glucose48', 'Hemoglobin48', 'Hematocrit48', 'Ureia49', 'Creatinine49', 'TGP49', 'Potassium49', 'Calcium49', 'Phosphate49', 'Glucose49', 'Hemoglobin49', 'Hematocrit49', 'Ureia50', 'Creatinine50', 'TGP50', 'Potassium50', 'Calcium50', 'Phosphate50', 'Glucose50', 'Hemoglobin50', 'Hematocrit50', 'Ureia51', 'Creatinine51', 'TGP51', 'Potassium51', 'Calcium51', 'Phosphate51', 'Glucose51', 'Hemoglobin51', 'Hematocrit51', 'Ureia52', 'Creatinine52', 'TGP52', 'Potassium52', 'Calcium52', 'Phosphate52', 'Glucose52', 'Hemoglobin52', 'Hematocrit52', 'Ureia53', 'Creatinine53', 'TGP53', 'Potassium53', 'Calcium53', 'Phosphate53', 'Glucose53', 'Hemoglobin53', 'Hematocrit53', 'Ureia54', 'Creatinine54', 'TGP54', 'Potassium54', 'Calcium54', 'Phosphate54', 'Glucose54', 'Hemoglobin54', 'Hematocrit54', 'Ureia55', 'Creatinine55', 'TGP55', 'Potassium55', 'Calcium55', 'Phosphate55', 'Glucose55', 'Hemoglobin55', 'Hematocrit55', 'Ureia56', 'Creatinine56', 'TGP56', 'Potassium56', 'Calcium56', 'Phosphate56', 'Glucose56', 'Hemoglobin56', 'Hematocrit56', 'Ureia57', 'Creatinine57', 'TGP57', 'Potassium57', 'Calcium57', 'Phosphate57', 'Glucose57', 'Hemoglobin57', 'Hematocrit57', 'Ureia58', 'Creatinine58', 'TGP58', 'Potassium58', 'Calcium58', 'Phosphate58', 'Glucose58', 'Hemoglobin58', 'Hematocrit58', 'Ureia59', 'Creatinine59', 'TGP59', 'Potassium59', 'Calcium59', 'Phosphate59', 'Glucose59', 'Hemoglobin59', 'Hematocrit59', 'Ureia60', 'Creatinine60', 'TGP60', 'Potassium60', 'Calcium60', 'Phosphate60', 'Glucose60', 'Hemoglobin60', 'Hematocrit60', 'Ureia61', 'Creatinine61', 'TGP61', 'Potassium61', 'Calcium61', 'Phosphate61', 'Glucose61', 'Hemoglobin61', 'Hematocrit61', 'Ureia62', 'Creatinine62', 'TGP62', 'Potassium62', 'Calcium62', 'Phosphate62', 'Glucose62', 'Hemoglobin62', 'Hematocrit62', 'Ureia63', 'Creatinine63', 'TGP63', 'Potassium63', 'Calcium63', 'Phosphate63', 'Glucose63', 'Hemoglobin63', 'Hematocrit63', 'Ureia64', 'Creatinine64', 'TGP64', 'Potassium64', 'Calcium64', 'Phosphate64', 'Glucose64', 'Hemoglobin64', 'Hematocrit64', 'Ureia65', 'Creatinine65', 'TGP65', 'Potassium65', 'Calcium65', 'Phosphate65', 'Glucose65', 'Hemoglobin65', 'Hematocrit65', 'Ureia66', 'Creatinine66', 'TGP66', 'Potassium66', 'Calcium66', 'Phosphate66', 'Glucose66', 'Hemoglobin66', 'Hematocrit66', 'Ureia67', 'Creatinine67', 'TGP67', 'Potassium67', 'Calcium67', 'Phosphate67', 'Glucose67', 'Hemoglobin67', 'Hematocrit67', 'Ureia68', 'Creatinine68', 'TGP68', 'Potassium68', 'Calcium68', 'Phosphate68', 'Glucose68', 'Hemoglobin68', 'Hematocrit68', 'Ureia69', 'Creatinine69', 'TGP69', 'Potassium69', 'Calcium69', 'Phosphate69', 'Glucose69', 'Hemoglobin69', 'Hematocrit69', 'Ureia70', 'Creatinine70', 'TGP70', 'Potassium70', 'Calcium70', 'Phosphate70', 'Glucose70', 'Hemoglobin70', 'Hematocrit70', 'Ureia71', 'Creatinine71', 'TGP71', 'Potassium71', 'Calcium71', 'Phosphate71', 'Glucose71', 'Hemoglobin71', 'Hematocrit71', 'Volume_Total1', 'Volume_Total2', 'Volume_Total3', 'Volume_Total4', 'Volume_Total5', 'Volume_Total6', 'Volume_Total7', 'Volume_Total8', 'Volume_Total9', 'Volume_Total10', 'Volume_Total11', 'Volume_Total12', 'Volume_Total13', 'Volume_Total14', 'Volume_Total15', 'Volume_Total16', 'Volume_Total17', 'Volume_Total18', 'Volume_Total19', 'Volume_Total20', 'Volume_Total21', 'Volume_Total22', 'Volume_Total23', 'Volume_Total24', 'Volume_Total25', 'Volume_Total26', 'Volume_Total27', 'Volume_Total28', 'Volume_Total29', 'Volume_Total30', 'Volume_Total31', 'Volume_Total32', 'Volume_Total33', 'Volume_Total34', 'Volume_Total35', 'Volume_Total36', 'Volume_Total37', 'Volume_Total38', 'Volume_Total39', 'Volume_Total40', 'Volume_Total41', 'Volume_Total42', 'Volume_Total43', 'Volume_Total44', 'Volume_Total45', 'Volume_Total46', 'Volume_Total47', 'Volume_Total48', 'Volume_Total49', 'Volume_Total50', 'Volume_Total51', 'Volume_Total52', 'Volume_Total53', 'Volume_Total54', 'Volume_Total55', 'Volume_Total56', 'Volume_Total57', 'Volume_Total58', 'Volume_Total59', 'Volume_Total60', 'Volume_Total61', 'Volume_Total62', 'Volume_Total63', 'Volume_Total64', 'Volume_Total65', 'Volume_Total66', 'Volume_Total67', 'Volume_Total68', 'Volume_Total69', 'Volume_Total70', 'Volume_Total71', 'Volume_Total72', 'N_AH_1', 'N_AH_2', 'N_AH_3', 'N_AH_4', 'N_AH_5', 'N_AH_6', 'N_AH_7', 'N_AH_8', 'N_AH_9', 'N_AH_10', 'N_AH_11', 'N_AH_12', 'N_AH_13', 'N_AH_14', 'N_AH_15', 'N_AH_16', 'N_AH_17', 'N_AH_18', 'N_AH_19', 'N_AH_20', 'N_AH_21', 'N_AH_22', 'N_AH_23', 'N_AH_24', 'N_AH_25', 'N_AH_26', 'N_AH_27', 'N_AH_28', 'N_AH_29', 'N_AH_30', 'N_AH_31', 'N_AH_32', 'N_AH_33', 'N_AH_34', 'N_AH_35', 'N_AH_36', 'N_AH_37', 'N_AH_38', 'N_AH_39', 'N_AH_40', 'N_AH_41', 'N_AH_42', 'N_AH_43', 'N_AH_44', 'N_AH_45', 'N_AH_46', 'N_AH_47', 'N_AH_48', 'N_AH_49', 'N_AH_50', 'N_AH_51', 'N_AH_52', 'N_AH_53', 'N_AH_54', 'N_AH_55', 'N_AH_56', 'N_AH_57', 'N_AH_58', 'N_AH_59', 'N_AH_60', 'N_AH_61', 'N_AH_62', 'N_AH_63', 'N_AH_64', 'N_AH_65', 'N_AH_66', 'N_AH_67', 'N_AH_68', 'N_AH_69', 'N_AH_70', 'N_AH_71', 'N_AH_72', 'N_AH_73', 'N_AH_74', 'Phosphate_pre1', 'Phosphate_pre2', 'Phosphate_pre3', 'Phosphate_pre4', 'Phosphate_pre5', 'Phosphate_pre6', 'Potassium_pre1', 'Potassium_pre2', 'Potassium_pre3', 'Potassium_pre4', 'Potassium_pre5', 'Potassium_pre6', 'Ms10ou1', 'Systolic1', 'Diastolic1', 'Systolic2', 'Diastolic2', 'Systolic3', 'Diastolic3', 'Systolic4', 'Diastolic4', 'Systolic5', 'Diastolic5', 'Systolic6', 'Diastolic6', 'Systolic7', 'Diastolic7', 'Systolic8', 'Diastolic8', 'Systolic9', 'Diastolic9', 'Systolic10', 'Diastolic10', 'Systolic11', 'Diastolic11', 'Systolic12', 'Diastolic12', 'Systolic13', 'Diastolic13', 'Systolic14', 'Diastolic14', 'Systolic15', 'Diastolic15', 'Systolic16', 'Diastolic16', 'Systolic17', 'Diastolic17', 'Systolic18', 'Diastolic18', 'Systolic19', 'Diastolic19', 'Systolic20', 'Diastolic20', 'Systolic21', 'Diastolic21', 'Systolic22', 'Diastolic22', 'Systolic23', 'Diastolic23', 'Systolic24', 'Diastolic24', 'Systolic25', 'Diastolic25', 'Systolic26', 'Diastolic26', 'Systolic27', 'Diastolic27', 'Systolic28', 'Diastolic28', 'Systolic29', 'Diastolic29', 'Systolic30', 'Diastolic30', 'Systolic31', 'Diastolic31', 'Systolic32', 'Diastolic32', 'Systolic33', 'Diastolic33', 'Systolic34', 'Diastolic34', 'Systolic35', 'Diastolic35', 'Systolic36', 'Diastolic36', 'Systolic37', 'Diastolic37', 'Systolic38', 'Diastolic38', 'Systolic39', 'Diastolic39', 'Systolic40', 'Diastolic40', 'Systolic41', 'Diastolic41', 'Systolic42', 'Diastolic42', 'Systolic43', 'Diastolic43', 'Systolic44', 'Diastolic44', 'Systolic45', 'Diastolic45', 'Systolic46', 'Diastolic46', 'Systolic47', 'Diastolic47', 'Systolic48', 'Diastolic48', 'Systolic49', 'Diastolic49', 'Systolic50', 'Diastolic50', 'Systolic51', 'Diastolic51', 'Systolic52', 'Diastolic52', 'Systolic53', 'Diastolic53', 'Systolic54', 'Diastolic54', 'Systolic55', 'Diastolic55', 'Systolic56', 'Diastolic56', 'Systolic57', 'Diastolic57', 'Systolic58', 'Diastolic58', 'Systolic59', 'Diastolic59', 'Systolic60', 'Diastolic60', 'Systolic61', 'Diastolic61', 'Systolic62', 'Diastolic62', 'Systolic63', 'Diastolic63', 'Systolic64', 'Diastolic64', 'Systolic65', 'Diastolic65', 'Systolic66', 'Diastolic66', 'Systolic67', 'Diastolic67', 'Systolic68', 'Diastolic68', 'Systolic69', 'Diastolic69', 'Systolic70', 'Diastolic70', 'Systolic71', 'Diastolic71', 'Systolic72', 'Diastolic72', 'Systolic73', 'Diastolic73', 'Systolic74', 'Diastolic74', 'PAS1', 'PAS2', 'PAS3', 'PAS4', 'PAS5', 'PAS6', 'PAS7', 'PAS8', 'PAS9', 'PAS10', 'PAS11', 'PAS12', 'PAS13', 'PAS14', 'PAS15', 'PAS16', 'PAS17', 'PAS18', 'PAS19', 'PAS20', 'PAS21', 'PAS22', 'PAS23', 'PAS24', 'PAS25', 'PAS26', 'PAS27', 'PAS28', 'PAS29', 'PAS30', 'PAS31', 'PAS32', 'PAS33', 'PAS34', 'PAS35', 'PAS36', 'PAS37', 'PAS38', 'PAS39', 'PAS40', 'PAS41', 'PAS42', 'PAS43', 'PAS44', 'PAS45', 'PAS46', 'PAS47', 'PAS48', 'PAS49', 'PAS50', 'PAS51', 'PAS52', 'PAS53', 'PAS54', 'PAS55', 'PAS56', 'PAS57', 'PAS58', 'PAS59', 'PAS60', 'PAS61', 'PAS62', 'PAS63', 'PAS64', 'PAS65', 'PAS66', 'PAS67', 'PAS68', 'PAS69', 'PAS70', 'PAS71', 'PAS72', 'PAS73', 'PAS74', 'PAD1', 'PAD2', 'PAD3', 'PAD4', 'PAD5', 'PAD6', 'PAD7', 'PAD8', 'PAD9', 'PAD10', 'PAD11', 'PAD12', 'PAD13', 'PAD14', 'PAD15', 'PAD16', 'PAD17', 'PAD18', 'PAD19', 'PAD20', 'PAD21', 'PAD22', 'PAD23', 'PAD24', 'PAD25', 'PAD26', 'PAD27', 'PAD28', 'PAD29', 'PAD30', 'PAD31', 'PAD32', 'PAD33', 'PAD34', 'PAD35', 'PAD36', 'PAD37', 'PAD38', 'PAD39', 'PAD40', 'PAD41', 'PAD42', 'PAD43', 'PAD44', 'PAD45', 'PAD46', 'PAD47', 'PAD48', 'PAD49', 'PAD50', 'PAD51', 'PAD52', 'PAD53', 'PAD54', 'PAD55', 'PAD56', 'PAD57', 'PAD58', 'PAD59', 'PAD60', 'PAD61', 'PAD62', 'PAD63', 'PAD64', 'PAD65', 'PAD66', 'PAD67', 'PAD68', 'PAD69', 'PAD70', 'PAD71', 'PAD72', 'PAD73', 'PAD74', 'Use antihypertensive drug1', 'Use antihypertensive drug2', 'Use antihypertensive drug3', 'Use antihypertensive drug4', 'Use antihypertensive drug5', 'Use antihypertensive drug6', 'Use antihypertensive drug7', 'Use antihypertensive drug8', 'Use antihypertensive drug9', 'Use antihypertensive drug10', 'Use antihypertensive drug11', 'Use antihypertensive drug12', 'Use antihypertensive drug13', 'Use antihypertensive drug14', 'Use antihypertensive drug15', 'Use antihypertensive drug16', 'Use antihypertensive drug17', 'Use antihypertensive drug18', 'Use antihypertensive drug19', 'Use antihypertensive drug20', 'Use antihypertensive drug21', 'Use antihypertensive drug22', 'Use antihypertensive drug23', 'Use antihypertensive drug24', 'Use antihypertensive drug25', 'Use antihypertensive drug26', 'Use antihypertensive drug27', 'Use antihypertensive drug28', 'Use antihypertensive drug29', 'Use antihypertensive drug30', 'Use antihypertensive drug31', 'Use antihypertensive drug32', 'Use antihypertensive drug33', 'Use antihypertensive drug34', 'Use antihypertensive drug35', 'Use antihypertensive drug36', 'Use antihypertensive drug37', 'Use antihypertensive drug38', 'Use antihypertensive drug39', 'Use antihypertensive drug40', 'Use antihypertensive drug41', 'Use antihypertensive drug42', 'Use antihypertensive drug43', 'Use antihypertensive drug44', 'Use antihypertensive drug45', 'Use antihypertensive drug46', 'Use antihypertensive drug47', 'Use antihypertensive drug48', 'Use antihypertensive drug49', 'Use antihypertensive drug50', 'Use antihypertensive drug51', 'Use antihypertensive drug52', 'Use antihypertensive drug53', 'Use antihypertensive drug54', 'Use antihypertensive drug55', 'Use antihypertensive drug56', 'Use antihypertensive drug57', 'Use antihypertensive drug58', 'Use antihypertensive drug59', 'Use antihypertensive drug60', 'Use antihypertensive drug61', 'Use antihypertensive drug62', 'Use antihypertensive drug63', 'Use antihypertensive drug64', 'Use antihypertensive drug65', 'Use antihypertensive drug66', 'Use antihypertensive drug67', 'Use antihypertensive drug68', 'Use antihypertensive drug69', 'Use antihypertensive drug70', 'Use antihypertensive drug71', 'Use antihypertensive drug72', 'Use antihypertensive drug73', 'Use antihypertensive drug74', 'ACE-inhibitor1', 'ACE-inhibitor2', 'ACE-inhibitor3', 'ACE-inhibitor4', 'ACE-inhibitor5', 'ACE-inhibitor6', 'ACE-inhibitor7', 'ACE-inhibitor8', 'ACE-inhibitor9', 'ACE-inhibitor10', 'ACE-inhibitor11', 'ACE-inhibitor12', 'ACE-inhibitor13', 'ACE-inhibitor14', 'ACE-inhibitor15', 'ACE-inhibitor16', 'ACE-inhibitor17', 'ACE-inhibitor18', 'ACE-inhibitor19', 'ACE-inhibitor20', 'ACE-inhibitor21', 'ACE-inhibitor22', 'ACE-inhibitor23', 'ACE-inhibitor24', 'ACE-inhibitor25', 'ACE-inhibitor26', 'ACE-inhibitor27', 'ACE-inhibitor28', 'ACE-inhibitor29', 'ACE-inhibitor30', 'ACE-inhibitor31', 'ACE-inhibitor32', 'ACE-inhibitor33', 'ACE-inhibitor34', 'ACE-inhibitor35', 'ACE-inhibitor36', 'ACE-inhibitor37', 'ACE-inhibitor38', 'ACE-inhibitor39', 'ACE-inhibitor40', 'ACE-inhibitor41', 'ACE-inhibitor42', 'ACE-inhibitor43', 'ACE-inhibitor44', 'ACE-inhibitor45', 'ACE-inhibitor46', 'ACE-inhibitor47', 'ACE-inhibitor48', 'ACE-inhibitor49', 'ACE-inhibitor50', 'ACE-inhibitor51', 'ACE-inhibitor52', 'ACE-inhibitor53', 'ACE-inhibitor54', 'ACE-inhibitor55', 'ACE-inhibitor56', 'ACE-inhibitor57', 'ACE-inhibitor58', 'ACE-inhibitor59', 'ACE-inhibitor60', 'ACE-inhibitor61', 'ACE-inhibitor62', 'ACE-inhibitor63', 'ACE-inhibitor64', 'ACE-inhibitor65', 'ACE-inhibitor66', 'ACE-inhibitor67', 'ACE-inhibitor68', 'ACE-inhibitor69', 'ACE-inhibitor70', 'ACE-inhibitor71', 'ACE-inhibitor72', 'ACE-inhibitor73', 'ACE-inhibitor74', 'beta-blocker1', 'beta-blocker2', 'beta-blocker3', 'beta-blocker4', 'beta-blocker5', 'beta-blocker6', 'beta-blocker7', 'beta-blocker8', 'beta-blocker9', 'beta-blocker10', 'beta-blocker11', 'beta-blocker12', 'beta-blocker13', 'beta-blocker14', 'beta-blocker15', 'beta-blocker16', 'beta-blocker17', 'beta-blocker18', 'beta-blocker19', 'beta-blocker20', 'beta-blocker21', 'beta-blocker22', 'beta-blocker23', 'beta-blocker24', 'beta-blocker25', 'beta-blocker26', 'beta-blocker27', 'beta-blocker28', 'beta-blocker29', 'beta-blocker30', 'beta-blocker31', 'beta-blocker32', 'beta-blocker33', 'beta-blocker34', 'beta-blocker35', 'beta-blocker36', 'beta-blocker37', 'beta-blocker38', 'beta-blocker39', 'beta-blocker40', 'beta-blocker41', 'beta-blocker42', 'beta-blocker43', 'beta-blocker44', 'beta-blocker45', 'beta-blocker46', 'beta-blocker47', 'beta-blocker48', 'beta-blocker49', 'beta-blocker50', 'beta-blocker51', 'beta-blocker52', 'beta-blocker53', 'beta-blocker54', 'beta-blocker55', 'beta-blocker56', 'beta-blocker57', 'beta-blocker58', 'beta-blocker59', 'beta-blocker60', 'beta-blocker61', 'beta-blocker62', 'beta-blocker63', 'beta-blocker64', 'beta-blocker65', 'beta-blocker66', 'beta-blocker67', 'beta-blocker68', 'beta-blocker69', 'beta-blocker70', 'beta-blocker71', 'beta-blocker72', 'beta-blocker73', 'beta-blocker74', 'calcium antagonist1', 'calcium antagonist2', 'calcium antagonist3', 'calcium antagonist4', 'calcium antagonist5', 'calcium antagonist6', 'calcium antagonist7', 'calcium antagonist8', 'calcium antagonist9', 'calcium antagonist10', 'calcium antagonist11', 'calcium antagonist12', 'calcium antagonist13', 'calcium antagonist14', 'calcium antagonist15', 'calcium antagonist16', 'calcium antagonist17', 'calcium antagonist18', 'calcium antagonist19', 'calcium antagonist20', 'calcium antagonist21', 'calcium antagonist22', 'calcium antagonist23', 'calcium antagonist24', 'calcium antagonist25', 'calcium antagonist26', 'calcium antagonist27', 'calcium antagonist28', 'calcium antagonist29', 'calcium antagonist30', 'calcium antagonist31', 'calcium antagonist32', 'calcium antagonist33', 'calcium antagonist34', 'calcium antagonist35', 'calcium antagonist36', 'calcium antagonist37', 'calcium antagonist38', 'calcium antagonist39', 'calcium antagonist40', 'calcium antagonist41', 'calcium antagonist42', 'calcium antagonist43', 'calcium antagonist44', 'calcium antagonist45', 'calcium antagonist46', 'calcium antagonist47', 'calcium antagonist48', 'calcium antagonist49', 'calcium antagonist50', 'calcium antagonist51', 'calcium antagonist52', 'calcium antagonist53', 'calcium antagonist54', 'calcium antagonist55', 'calcium antagonist56', 'calcium antagonist57', 'calcium antagonist58', 'calcium antagonist59', 'calcium antagonist60', 'calcium antagonist61', 'calcium antagonist62', 'calcium antagonist63', 'calcium antagonist64', 'calcium antagonist65', 'calcium antagonist66', 'calcium antagonist67', 'calcium antagonist68', 'calcium antagonist69', 'calcium antagonist70', 'calcium antagonist71', 'calcium antagonist72', 'calcium antagonist73', 'calcium antagonist74', 'diuretic1', 'diuretic2', 'diuretic3', 'diuretic4', 'diuretic5', 'diuretic6', 'diuretic7', 'diuretic8', 'diuretic9', 'diuretic10', 'diuretic11', 'diuretic12', 'diuretic13', 'diuretic14', 'diuretic15', 'diuretic16', 'diuretic17', 'diuretic18', 'diuretic19', 'diuretic20', 'diuretic21', 'diuretic22', 'diuretic23', 'diuretic24', 'diuretic25', 'diuretic26', 'diuretic27', 'diuretic28', 'diuretic29', 'diuretic30', 'diuretic31', 'diuretic32', 'diuretic33', 'diuretic34', 'diuretic35', 'diuretic36', 'diuretic37', 'diuretic38', 'diuretic39', 'diuretic40', 'diuretic41', 'diuretic42', 'diuretic43', 'diuretic44', 'diuretic45', 'diuretic46', 'diuretic47', 'diuretic48', 'diuretic49', 'diuretic50', 'diuretic51', 'diuretic52', 'diuretic53', 'diuretic54', 'diuretic55', 'diuretic56', 'diuretic57', 'diuretic58', 'diuretic59', 'diuretic60', 'diuretic61', 'diuretic62', 'diuretic63', 'diuretic64', 'diuretic65', 'diuretic66', 'diuretic67', 'diuretic68', 'diuretic69', 'diuretic70', 'diuretic71', 'diuretic72', 'diuretic73', 'diuretic74', 'ATI blocker1', 'ATI blocker2', 'ATI blocker3', 'ATI blocker4', 'ATI blocker5', 'ATI blocker6', 'ATI blocker7', 'ATI blocker8', 'ATI blocker9', 'ATI blocker10', 'ATI blocker11', 'ATI blocker12', 'ATI blocker13', 'ATI blocker14', 'ATI blocker15', 'ATI blocker16', 'ATI blocker17', 'ATI blocker18', 'ATI blocker19', 'ATI blocker20', 'ATI blocker21', 'ATI blocker22', 'ATI blocker23', 'ATI blocker24', 'ATI blocker25', 'ATI blocker26', 'ATI blocker27', 'ATI blocker28', 'ATI blocker29', 'ATI blocker30', 'ATI blocker31', 'ATI blocker32', 'ATI blocker33', 'ATI blocker34', 'ATI blocker35', 'ATI blocker36', 'ATI blocker37', 'ATI blocker38', 'ATI blocker39', 'ATI blocker40', 'ATI blocker41', 'ATI blocker42', 'ATI blocker43', 'ATI blocker44', 'ATI blocker45', 'ATI blocker46', 'ATI blocker47', 'ATI blocker48', 'ATI blocker49', 'ATI blocker50', 'ATI blocker51', 'ATI blocker52', 'ATI blocker53', 'ATI blocker54', 'ATI blocker55', 'ATI blocker56', 'ATI blocker57', 'ATI blocker58', 'ATI blocker59', 'ATI blocker60', 'ATI blocker61', 'ATI blocker62', 'ATI blocker63', 'ATI blocker64', 'ATI blocker65', 'ATI blocker66', 'ATI blocker67', 'ATI blocker68', 'ATI blocker69', 'ATI blocker70', 'ATI blocker71', 'ATI blocker72', 'ATI blocker73', 'ATI blocker74', 'OUTROS1', 'OUTROS2', 'OUTROS3', 'OUTROS4', 'OUTROS5', 'OUTROS6', 'OUTROS7', 'OUTROS8', 'OUTROS9', 'OUTROS10', 'OUTROS11', 'OUTROS12', 'OUTROS13', 'OUTROS14', 'OUTROS15', 'OUTROS16', 'OUTROS17', 'OUTROS18', 'OUTROS19', 'OUTROS20', 'OUTROS21', 'OUTROS22', 'OUTROS23', 'OUTROS24', 'OUTROS25', 'OUTROS26', 'OUTROS27', 'OUTROS28', 'OUTROS29', 'OUTROS30', 'OUTROS31', 'OUTROS32', 'OUTROS33', 'OUTROS34', 'OUTROS35', 'OUTROS36', 'OUTROS37', 'OUTROS38', 'OUTROS39', 'OUTROS40', 'OUTROS41', 'OUTROS42', 'OUTROS43', 'OUTROS44', 'OUTROS45', 'OUTROS46', 'OUTROS47', 'OUTROS48', 'OUTROS49', 'OUTROS50', 'OUTROS51', 'OUTROS52', 'OUTROS53', 'OUTROS54', 'OUTROS55', 'OUTROS56', 'OUTROS57', 'OUTROS58', 'OUTROS59', 'OUTROS60', 'OUTROS61', 'OUTROS62', 'OUTROS63', 'OUTROS64', 'OUTROS65', 'OUTROS66', 'OUTROS67', 'OUTROS68', 'OUTROS69', 'OUTROS70', 'OUTROS71', 'OUTROS72', 'OUTROS73', 'OUTROS74', 'Primary renal disease (Diabetes)', 'Primary renal disease (Hypertension)', 'Primary renal disease (CGN (including LES))', 'Primary renal disease (Unknown)', 'Primary renal disease (Others)']\n"
     ]
    }
   ],
   "source": [
    "# Separate features to unique features and time series features\n",
    "timeseries_cols = []\n",
    "time_indices = str(np.arange(100))\n",
    "# print(time_indices)\n",
    "for col in list(df.columns):\n",
    "    add = True\n",
    "    for idx in time_indices:\n",
    "        if idx in col:\n",
    "            add = False\n",
    "    if add == False:\n",
    "        timeseries_cols.append(col)\n",
    "        \n",
    "# Adjust missclassified features\n",
    "adjlist = ['ModalidadeCAPD0APD1Mix2', 'Dropoutsim1', 'Agedic65', 'Educationdic4y', \n",
    "           'Followup1y', 'Followup2y', 'Followup3y', \"death_event_1y\",\"Tech_event_1y\",\n",
    "          \"death_event_2y\",\"Tech_event_2y\", \"death_event_3y\",\"Tech_event_3y\"]\n",
    "for i in range(len(adjlist)):\n",
    "    timeseries_cols.remove(adjlist[i])\n",
    "    \n",
    "unique_cols = ['Hemoglobin', 'Potassium', 'Phosphate',\\\n",
    "                 'FRR', 'codigoclinica', 'ModalidadeCAPD0APD1Mix2',\\\n",
    "                'CenterSizenpatients', 'ModalidadeDPInicial', 'Age',\\\n",
    "                'BMI','IncidentinPD', 'PrevalentinPDNet', \\\n",
    "                'DialysisvintageprePDNet', 'totaldialysisvintage',\\\n",
    "                'Primary renal disease (Diabetes)','Primary renal disease (Hypertension)',\\\n",
    "                'Primary renal disease (CGN (including LES))', 'Primary renal disease (Unknown)',\\\n",
    "                'Primary renal disease (Others)', 'PreviousHD',\\\n",
    "                'Previoustx', 'DaviesScore', 'Peripheralarterydisease',\\\n",
    "                'DM', 'CAD', 'LVH', 'LES', 'HF', 'Cancer', 'Stroke',\\\n",
    "                'Hypertension', 'HIV', 'HCV', 'HBC', 'Gender',\\\n",
    "                'Familyincome', 'Distancefromcenter', 'predialysiscare',\\\n",
    "                'timeofpredialysiscare', 'Racedicwhite', 'Educationdic4y',\\\n",
    "                'Region', 'Centerexperiencepatientyear',\\\n",
    "                'Regionsdic', 'cidade']\n",
    "\n",
    "print(unique_cols)\n",
    "print(timeseries_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build baseline dataframe (without time-series data):\n",
    "df_baseline = df[unique_cols].copy()\n",
    "df_baseline = df_baseline.fillna(0)\n",
    "# display(df_baseline)\n",
    "\n",
    "targets = ['Dropoutsim1', 'Followup1y', 'Followup2y', 'Followup3y',\\\n",
    "           \"death_event_1y\",\"Tech_event_1y\",\\\n",
    "           \"death_event_2y\",\"Tech_event_2y\",\\\n",
    "           \"death_event_3y\",\"Tech_event_3y\",\\\n",
    "           \"Deathevent\",\"TechniqueFailureevent\",\"Causeofdeath\",\"TechFailureDeathnotcens\",\"Causeofdropout\",\\\n",
    "           \"Followup\"]\n",
    "\n",
    "# build targets dataframe:\n",
    "Y = df[targets+['CODPAX']].copy()\n",
    "# display(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hemoglobin</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Phosphate</th>\n",
       "      <th>FRR</th>\n",
       "      <th>Clinic code</th>\n",
       "      <th>CAPD0APD1Mix2 modality</th>\n",
       "      <th>Center size (patients)</th>\n",
       "      <th>Initial modality of PD</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>...</th>\n",
       "      <th>diuretic p4</th>\n",
       "      <th>diuretic p5</th>\n",
       "      <th>diuretic p6</th>\n",
       "      <th>diuretic p7</th>\n",
       "      <th>diuretic p8</th>\n",
       "      <th>diuretic p9</th>\n",
       "      <th>diuretic p10</th>\n",
       "      <th>diuretic p11</th>\n",
       "      <th>diuretic p12</th>\n",
       "      <th>diuretic p13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.933333</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2</td>\n",
       "      <td>20.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.766667</td>\n",
       "      <td>5.933333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>28.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.833333</td>\n",
       "      <td>4.366667</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.2</td>\n",
       "      <td>31.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.066667</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.3</td>\n",
       "      <td>27.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.933333</td>\n",
       "      <td>4.033333</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>8.400000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>9.700000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>3.233333</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>10.466667</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>4.466667</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>11.766667</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>9.866667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5707 rows × 298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hemoglobin  Potassium  Phosphate  FRR  Clinic code  \\\n",
       "0      12.933333   4.433333   5.300000    0            1   \n",
       "1      14.000000   3.766667   5.933333    0            1   \n",
       "2      11.833333   4.366667   6.100000    1            1   \n",
       "3      10.066667   4.733333   5.533333    1            1   \n",
       "4      11.933333   4.033333   4.066667    0            1   \n",
       "...          ...        ...        ...  ...          ...   \n",
       "5702    8.400000   5.500000   4.700000    1          347   \n",
       "5703    9.700000   4.300000   3.233333    1          347   \n",
       "5704   10.466667   4.433333   4.466667    1          347   \n",
       "5705   11.766667   4.533333   3.566667    1          347   \n",
       "5706    9.866667   4.000000   4.100000    1          347   \n",
       "\n",
       "      CAPD0APD1Mix2 modality  Center size (patients)  Initial modality of PD  \\\n",
       "0                          0                     128                     0.0   \n",
       "1                          0                     128                     0.0   \n",
       "2                          1                     128                     1.0   \n",
       "3                          0                     128                     0.0   \n",
       "4                          2                     128                     0.0   \n",
       "...                      ...                     ...                     ...   \n",
       "5702                       1                      66                     1.0   \n",
       "5703                       1                      66                     1.0   \n",
       "5704                       1                      66                     1.0   \n",
       "5705                       1                      66                     1.0   \n",
       "5706                       1                      66                     1.0   \n",
       "\n",
       "       Age   BMI  ...  diuretic p4  diuretic p5  diuretic p6  diuretic p7  \\\n",
       "0     71.2  20.7  ...          0.0          0.0          0.0          0.0   \n",
       "1     23.3  28.3  ...          0.0          0.0          0.0          0.0   \n",
       "2     49.2  31.5  ...          0.0          0.0          0.0          0.0   \n",
       "3     48.3  27.1  ...          0.0          0.0          0.0          0.0   \n",
       "4     93.7  23.1  ...          0.0          0.0          0.0          0.0   \n",
       "...    ...   ...  ...          ...          ...          ...          ...   \n",
       "5702  31.8  22.0  ...          0.0          0.0          0.0          0.0   \n",
       "5703  57.0  21.5  ...          0.0          0.0          0.0          0.0   \n",
       "5704  84.0  23.5  ...          0.0          0.0          0.0          0.0   \n",
       "5705  54.2  35.0  ...          0.0          0.0          0.0          0.0   \n",
       "5706  77.8  20.6  ...          0.0          0.0          0.0          0.0   \n",
       "\n",
       "      diuretic p8  diuretic p9  diuretic p10  diuretic p11  diuretic p12  \\\n",
       "0             0.0          0.0           0.0           0.0           0.0   \n",
       "1             0.0          0.0           0.0           0.0           0.0   \n",
       "2             0.0          0.0           0.0           0.0           0.0   \n",
       "3             0.0          0.0           0.0           0.0           0.0   \n",
       "4             0.0          0.0           0.0           0.0           0.0   \n",
       "...           ...          ...           ...           ...           ...   \n",
       "5702          0.0          0.0           0.0           0.0           0.0   \n",
       "5703          0.0          0.0           0.0           0.0           0.0   \n",
       "5704          0.0          0.0           0.0           0.0           0.0   \n",
       "5705          0.0          0.0           0.0           0.0           0.0   \n",
       "5706          0.0          0.0           0.0           0.0           0.0   \n",
       "\n",
       "      diuretic p13  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "...            ...  \n",
       "5702           0.0  \n",
       "5703           0.0  \n",
       "5704           0.0  \n",
       "5705           0.0  \n",
       "5706           0.0  \n",
       "\n",
       "[5707 rows x 298 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_totalaverage = df[unique_cols].copy()\n",
    "\n",
    "# rename column name to understandable English\n",
    "df_totalaverage = df_totalaverage.rename(columns={\"codigoclinica\": \"Clinic code\",\\\n",
    "                                                  \"ModalidadeCAPD0APD1Mix2\": \"CAPD0APD1Mix2 modality\",\\\n",
    "                                                  \"CenterSizenpatients\": \"Center size (patients)\",\\\n",
    "                                                  \"ModalidadeDPInicial\": \"Initial modality of PD\",\\\n",
    "                                                  \"IncidentinPD\": \"Incident in PD\",\\\n",
    "                                                  \"PrevalentinPDNet\": \"Prevalent in PD Net\",\\\n",
    "                                                  \"DialysisvintageprePDNet\": \"Dialysis vintage pre PD Net\",\\\n",
    "                                                  \"totaldialysisvintage\": \"Total dialysis vintage\",\\\n",
    "                                                  \"PreviousHD\": \"Previous HD\",\\\n",
    "                                                  \"Previoustx\": \"Previous tx\",\\\n",
    "                                                  \"DaviesScore\": \"Davies Score\",\\\n",
    "                                                  \"Peripheralarterydisease\": \"Peripheral artery disease\",\\\n",
    "                                                  \"Familyincome\": \"Family income\",\\\n",
    "                                                  \"Distancefromcenter\": \"Distance from center\",\\\n",
    "                                                  \"predialysiscare\": \"Predialysis care\",\\\n",
    "                                                  \"timeofpredialysiscare\": \"Time of predialysis care\",\\\n",
    "                                                  \"Racedicwhite\": \"Race is white\",\\\n",
    "                                                  \"Educationdic4y\": \"Education more than 4 years\",\\\n",
    "                                                  \"Centerexperiencepatientyear\": \"Center experience (patient-year)\",\\\n",
    "                                                  \"cidade\": \"City\"})\n",
    "\n",
    "Group_p1 = []\n",
    "Ms10ou_p1 = []\n",
    "\n",
    "storage_p1 = [Group_p1, Ms10ou_p1]\n",
    "\n",
    "Mean_PAS_p1 = []\n",
    "Mean_PAD_p1 = []\n",
    "\n",
    "Mean_PAS_p2 = []\n",
    "Mean_PAD_p2 = []\n",
    "\n",
    "storage_p2 = [Mean_PAS_p1, Mean_PAD_p1, Mean_PAS_p2, Mean_PAD_p2]\n",
    "\n",
    "Ureia = dict()\n",
    "Creatinine = dict()\n",
    "TGP = dict()\n",
    "Potassium = dict()\n",
    "Calcium = dict()\n",
    "Phosphate = dict()\n",
    "Glucose = dict()\n",
    "Hemoglobin = dict()\n",
    "Hematocrit = dict()\n",
    "Volume_Total = dict()\n",
    "N_AH_ = dict()\n",
    "Systolic = dict()\n",
    "Diastolic = dict()\n",
    "PAS = dict()\n",
    "PAD = dict()\n",
    "Uso_de_anti_hipert = dict()\n",
    "inibidor = dict()\n",
    "at_i = dict()\n",
    "beta = dict()\n",
    "ant = dict()\n",
    "diu = dict()\n",
    "\n",
    "# label_dict = [Ureia, Creatinine, TGP, Potassium, Calcium, Phosphate, Glucose, \n",
    "#               Hemoglobin, Hematocrit, Volume_Total, N_AH_, Systolic, Diastolic, PAS, PAD, Uso_de_anti_hipert, inibidor]\n",
    "\n",
    "# label_str = ['Ureia', 'Creatinine', 'TGP', 'Potassium', 'Calcium', 'Phosphate', 'Glucose', \n",
    "#               'Hemoglobin', 'Hematocrit','Volume_Total', 'N_AH_', 'Systolic', 'Diastolic','PAS','PAD',\n",
    "#              'Uso_de_anti_hipert', 'inibidor']\n",
    "\n",
    "# remove Volume_Total and N_AH_\n",
    "\n",
    "label_dict = [Ureia, Creatinine, TGP, Potassium, Calcium, Phosphate, Glucose, \n",
    "              Hemoglobin, Hematocrit, Systolic, Diastolic, PAS, PAD, Uso_de_anti_hipert, \n",
    "              inibidor, at_i, beta, ant, diu]\n",
    "\n",
    "# label_str = ['Ureia', 'Creatinine', 'TGP', 'Potassium', 'Calcium', 'Phosphate',\\\n",
    "#              'Glucose', 'Hemoglobin', 'Hematocrit', 'Systolic', 'Diastolic','PAS','PAD',\\\n",
    "#              'Uso_de_anti_hipert', 'inibidor', 'at_i', 'beta', 'ant', 'diu']\n",
    "\n",
    "label_str = ['Ureia', 'Creatinine', 'TGP', 'Potassium', 'Calcium', 'Phosphate',\\\n",
    "             'Glucose', 'Hemoglobin', 'Hematocrit', 'Systolic', 'Diastolic','PAS','PAD',\\\n",
    "             'Use antihypertensive drug', 'ACE-inhibitor', 'ATI blocker', 'beta-blocker',\\\n",
    "             'calcium antagonist', 'diuretic']\n",
    "\n",
    "for item in label_dict:\n",
    "    for i in range(13):\n",
    "        key = 'p'+str(i+1)\n",
    "        item[key] = []\n",
    "    \n",
    "label_idx = 0    \n",
    "for item in label_dict:\n",
    "    count = 0\n",
    "    section = 1\n",
    "    labelname = label_str[label_idx]\n",
    "    for col in timeseries_cols:\n",
    "        if labelname in col:\n",
    "            if 'Mean_' not in col:            \n",
    "                if count < 6:\n",
    "                    count = count + 1\n",
    "                else:\n",
    "                    section = section + 1\n",
    "                    count = 1\n",
    "                key = 'p'+str(section)\n",
    "                try:\n",
    "                    item[key].append(col)\n",
    "                except:\n",
    "                    pass\n",
    "                    \n",
    "                    \n",
    "    label_idx = label_idx + 1\n",
    "\n",
    "indices_p1 = ['Group', 'Ms10ou']\n",
    "\n",
    "indices_p2 = ['Mean_PAS', 'Mean_PAD']\n",
    "\n",
    "\n",
    "\n",
    "# Select certain features as 1 section\n",
    "for col in timeseries_cols:\n",
    "    i = 0\n",
    "    for idx in indices_p1:\n",
    "        if idx in col:\n",
    "            storage_p1[i].append(col)\n",
    "        i = i + 1\n",
    "# print(storage_p1)\n",
    "\n",
    "# Separate certain features to 2 sections (each section contains 4 features)\n",
    "i = 0 # i is the index of feature name\n",
    "for idx in indices_p2:\n",
    "    p = 0\n",
    "    count = 0\n",
    "    for col in timeseries_cols:\n",
    "        if idx in col:\n",
    "            if count < 4:\n",
    "                storage_p2[i+2*p].append(col)\n",
    "                count = count + 1\n",
    "            else:\n",
    "                count = 0\n",
    "                p = p + 1\n",
    "                storage_p2[i+2*p].append(col)\n",
    "                count = count + 1\n",
    "    i = i + 1\n",
    "\n",
    "for i in range(len(indices_p1)):\n",
    "    df_totalaverage.loc[:,indices_p1[i]] = df[storage_p1[i]].mean(axis=1)\n",
    "\n",
    "for i in range(len(indices_p2)):\n",
    "    for p in range(2):\n",
    "        name = indices_p2[i][0:4] + ' ' + indices_p2[i][5:] + ' p' + str(p+1)\n",
    "        df_totalaverage.loc[:,name] = df[storage_p2[i+2*p]].mean(axis=1)       \n",
    "\n",
    "label_idx = 0\n",
    "for item in label_dict:\n",
    "    for p in range(13):\n",
    "        name = label_str[label_idx] + ' p' + str(p+1)\n",
    "        df_totalaverage.loc[:,name] = df[item['p'+str(p+1)]].mean(axis=1)\n",
    "    label_idx = label_idx + 1\n",
    "        \n",
    "    \n",
    "df_totalaverage = df_totalaverage.fillna(0)\n",
    "display(df_totalaverage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hemoglobin</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Phosphate</th>\n",
       "      <th>FRR</th>\n",
       "      <th>Clinic code</th>\n",
       "      <th>CAPD0APD1Mix2 modality</th>\n",
       "      <th>Center size (patients)</th>\n",
       "      <th>Initial modality of PD</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>...</th>\n",
       "      <th>PAS mean months 2Y</th>\n",
       "      <th>PAD mean months 2Y</th>\n",
       "      <th>Use antihypertensive drug mean months 2Y</th>\n",
       "      <th>ACE-inhibitor mean months 2Y</th>\n",
       "      <th>ATI blocker mean months 2Y</th>\n",
       "      <th>beta-blocker mean months 2Y</th>\n",
       "      <th>calcium antagonist mean months 2Y</th>\n",
       "      <th>diuretic mean months 2Y</th>\n",
       "      <th>Mean PAS 3T</th>\n",
       "      <th>Mean PAD 3T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.933333</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2</td>\n",
       "      <td>20.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.766667</td>\n",
       "      <td>5.933333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>28.3</td>\n",
       "      <td>...</td>\n",
       "      <td>135.666667</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.833333</td>\n",
       "      <td>4.366667</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.2</td>\n",
       "      <td>31.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.066667</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.3</td>\n",
       "      <td>27.1</td>\n",
       "      <td>...</td>\n",
       "      <td>174.666667</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.333333</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.933333</td>\n",
       "      <td>4.033333</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.333333</td>\n",
       "      <td>72.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>8.400000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>9.700000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>3.233333</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>10.466667</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>4.466667</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>11.766667</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>9.866667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5707 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hemoglobin  Potassium  Phosphate  FRR  Clinic code  \\\n",
       "0      12.933333   4.433333   5.300000    0            1   \n",
       "1      14.000000   3.766667   5.933333    0            1   \n",
       "2      11.833333   4.366667   6.100000    1            1   \n",
       "3      10.066667   4.733333   5.533333    1            1   \n",
       "4      11.933333   4.033333   4.066667    0            1   \n",
       "...          ...        ...        ...  ...          ...   \n",
       "5702    8.400000   5.500000   4.700000    1          347   \n",
       "5703    9.700000   4.300000   3.233333    1          347   \n",
       "5704   10.466667   4.433333   4.466667    1          347   \n",
       "5705   11.766667   4.533333   3.566667    1          347   \n",
       "5706    9.866667   4.000000   4.100000    1          347   \n",
       "\n",
       "      CAPD0APD1Mix2 modality  Center size (patients)  Initial modality of PD  \\\n",
       "0                          0                     128                     0.0   \n",
       "1                          0                     128                     0.0   \n",
       "2                          1                     128                     1.0   \n",
       "3                          0                     128                     0.0   \n",
       "4                          2                     128                     0.0   \n",
       "...                      ...                     ...                     ...   \n",
       "5702                       1                      66                     1.0   \n",
       "5703                       1                      66                     1.0   \n",
       "5704                       1                      66                     1.0   \n",
       "5705                       1                      66                     1.0   \n",
       "5706                       1                      66                     1.0   \n",
       "\n",
       "       Age   BMI  ...  PAS mean months 2Y  PAD mean months 2Y  \\\n",
       "0     71.2  20.7  ...            0.000000                 0.0   \n",
       "1     23.3  28.3  ...          135.666667                73.0   \n",
       "2     49.2  31.5  ...            0.000000                 0.0   \n",
       "3     48.3  27.1  ...          174.666667                84.0   \n",
       "4     93.7  23.1  ...            0.000000                 0.0   \n",
       "...    ...   ...  ...                 ...                 ...   \n",
       "5702  31.8  22.0  ...            0.000000                 0.0   \n",
       "5703  57.0  21.5  ...            0.000000                 0.0   \n",
       "5704  84.0  23.5  ...            0.000000                 0.0   \n",
       "5705  54.2  35.0  ...            0.000000                 0.0   \n",
       "5706  77.8  20.6  ...            0.000000                 0.0   \n",
       "\n",
       "      Use antihypertensive drug mean months 2Y  ACE-inhibitor mean months 2Y  \\\n",
       "0                                          0.0                           0.0   \n",
       "1                                          0.0                           0.0   \n",
       "2                                          0.0                           0.0   \n",
       "3                                          1.0                           1.0   \n",
       "4                                          0.0                           0.0   \n",
       "...                                        ...                           ...   \n",
       "5702                                       0.0                           0.0   \n",
       "5703                                       0.0                           0.0   \n",
       "5704                                       0.0                           0.0   \n",
       "5705                                       0.0                           0.0   \n",
       "5706                                       0.0                           0.0   \n",
       "\n",
       "      ATI blocker mean months 2Y  beta-blocker mean months 2Y  \\\n",
       "0                            0.0                          0.0   \n",
       "1                            0.0                          0.0   \n",
       "2                            0.0                          0.0   \n",
       "3                            0.0                          0.0   \n",
       "4                            0.0                          0.0   \n",
       "...                          ...                          ...   \n",
       "5702                         0.0                          0.0   \n",
       "5703                         0.0                          0.0   \n",
       "5704                         0.0                          0.0   \n",
       "5705                         0.0                          0.0   \n",
       "5706                         0.0                          0.0   \n",
       "\n",
       "      calcium antagonist mean months 2Y  diuretic mean months 2Y  Mean PAS 3T  \\\n",
       "0                              0.000000                      0.0     0.000000   \n",
       "1                              0.000000                      0.0   136.000000   \n",
       "2                              0.000000                      0.0   147.000000   \n",
       "3                              0.333333                      0.0   169.333333   \n",
       "4                              0.000000                      0.0   129.333333   \n",
       "...                                 ...                      ...          ...   \n",
       "5702                           0.000000                      0.0   120.000000   \n",
       "5703                           0.000000                      0.0     0.000000   \n",
       "5704                           0.000000                      0.0     0.000000   \n",
       "5705                           0.000000                      0.0     0.000000   \n",
       "5706                           0.000000                      0.0     0.000000   \n",
       "\n",
       "      Mean PAD 3T  \n",
       "0        0.000000  \n",
       "1       82.000000  \n",
       "2       80.000000  \n",
       "3       99.000000  \n",
       "4       72.666667  \n",
       "...           ...  \n",
       "5702    80.000000  \n",
       "5703     0.000000  \n",
       "5704     0.000000  \n",
       "5705     0.000000  \n",
       "5706     0.000000  \n",
       "\n",
       "[5707 rows x 65 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline = df[unique_cols].copy()\n",
    "\n",
    "numofpatient = baseline.shape[0]\n",
    "\n",
    "# labelnames = ['Ureia', 'Creatinine', 'TGP', 'Potassium', 'Calcium', 'Phosphate', 'Glucose', \n",
    "#               'Hemoglobin', 'Hematocrit','Volume_Total', 'N_AH_', 'Systolic', 'Diastolic',\n",
    "#              'PAS', 'PAD', 'Uso_de_anti_hipert', 'inibidor']\n",
    "\n",
    "# remove Volume_Total and N_AH_\n",
    "labelnames = ['Ureia', 'Creatinine', 'TGP', 'Potassium', 'Calcium', 'Phosphate', 'Glucose', \n",
    "              'Hemoglobin', 'Hematocrit', 'Systolic', 'Diastolic',\n",
    "             'PAS', 'PAD', 'Use antihypertensive drug', 'ACE-inhibitor', 'ATI blocker', 'beta-blocker',\n",
    "              'calcium antagonist', 'diuretic']\n",
    "\n",
    "dfs = [df[unique_cols], df[unique_cols], df[unique_cols]]\n",
    "maxmonths = [6, 18, 30]\n",
    "\n",
    "\n",
    "for year in range(3):\n",
    "    dfs[year] = dfs[year].rename(columns={\"codigoclinica\": \"Clinic code\",\\\n",
    "                                                  \"ModalidadeCAPD0APD1Mix2\": \"CAPD0APD1Mix2 modality\",\\\n",
    "                                                  \"CenterSizenpatients\": \"Center size (patients)\",\\\n",
    "                                                  \"ModalidadeDPInicial\": \"Initial modality of PD\",\\\n",
    "                                                  \"IncidentinPD\": \"Incident in PD\",\\\n",
    "                                                  \"PrevalentinPDNet\": \"Prevalent in PD Net\",\\\n",
    "                                                  \"DialysisvintageprePDNet\": \"Dialysis vintage pre PD Net\",\\\n",
    "                                                  \"totaldialysisvintage\": \"Total dialysis vintage\",\\\n",
    "                                                  \"Primaryrenaldisease\": \"Primary renal disease\",\\\n",
    "                                                  \"PreviousHD\": \"Previous HD\",\\\n",
    "                                                  \"Previoustx\": \"Previous tx\",\\\n",
    "                                                  \"DaviesScore\": \"Davies Score\",\\\n",
    "                                                  \"Peripheralarterydisease\": \"Peripheral artery disease\",\\\n",
    "                                                  \"Familyincome\": \"Family income\",\\\n",
    "                                                  \"Distancefromcenter\": \"Distance from center\",\\\n",
    "                                                  \"predialysiscare\": \"Predialysis care\",\\\n",
    "                                                  \"timeofpredialysiscare\": \"Time of predialysis care\",\\\n",
    "                                                  \"Racedicwhite\": \"Race is white\",\\\n",
    "                                                  \"Educationdic4y\": \"Education more than 4 years\",\\\n",
    "                                                  \"Centerexperiencepatientyear\": \"Center experience (patient-year)\",\\\n",
    "                                                  \"cidade\": \"City\"})\n",
    "    \n",
    "    \n",
    "    for labelname in labelnames:\n",
    "        for patient_idx in range(numofpatient):\n",
    "            # compute the max index of month including nonzero data\n",
    "            maxmonth = maxmonths[year]\n",
    "            maxname = labelname + str(maxmonth)\n",
    "            temp = df.at[patient_idx, maxname]\n",
    "            while temp == 0 and maxmonth >= maxmonths[year]-5:\n",
    "                maxmonth = maxmonth - 1\n",
    "                maxname = labelname + str(maxmonth)\n",
    "                if maxmonth >= maxmonths[year]-5:\n",
    "                    temp = df.at[patient_idx, maxname]\n",
    "\n",
    "            # compute the average of 3 months\n",
    "            mean_months = 0\n",
    "            if maxmonth >= maxmonths[year]-3:\n",
    "                for i in range(maxmonth-2, maxmonth+1):\n",
    "                    name = labelname + str(i)\n",
    "                    mean_months = mean_months + df.at[patient_idx, name]\n",
    "                mean_months = mean_months/3\n",
    "            elif maxmonth == maxmonths[year]-4:\n",
    "                for i in range(maxmonth-1, maxmonth+1):\n",
    "                    name = labelname + str(i)\n",
    "                    mean_months = mean_months + df.at[patient_idx, name]\n",
    "                mean_months = mean_months/2\n",
    "            elif maxmonth == maxmonths[year]-5:\n",
    "                name = labelname + str(maxmonth)\n",
    "                mean_months = df.at[patient_idx, name]\n",
    "            else:\n",
    "                mean_months = 0\n",
    "            yearname = str(year+1)+'Y'\n",
    "            name = labelname + ' mean months ' + yearname\n",
    "            dfs[year].loc[patient_idx, name] = mean_months\n",
    "\n",
    "\n",
    "extra_1y = ['Mean_PAS_1T', 'Mean_PAD_1T']\n",
    "extra_2y = ['Mean_PAS_3T', 'Mean_PAD_3T']\n",
    "extra_3y = ['Mean_PAS_5T', 'Mean_PAD_5T']\n",
    "extras = [extra_1y, extra_2y, extra_3y]\n",
    "\n",
    "for year in range(3):\n",
    "    for index in extras[year]:\n",
    "            new_name = index[0:4] + ' ' + index[5:8] + ' ' + index[9:]\n",
    "            dfs[year].loc[:,new_name] = df[index]    \n",
    "    dfs[year] = dfs[year].fillna(0)\n",
    "    dfs[year].drop(columns = ['Total dialysis vintage'] , inplace=True)\n",
    "        \n",
    "display(dfs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated learning binary classification\n",
    "\n",
    "* The follow-up event in the 1st, 2nd and 3rd year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 1 #input year you want to investigate\n",
    "\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE_BUFFER = 50\n",
    "\n",
    "client_learning_rate = 0.01\n",
    "server_learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data: \n",
      " X's shape: (5707, 65) \n",
      " y's shape: (5707, 1)\n",
      "unique client IDs: [1, 2, 3, 5, 6, 10, 12, 18, 23, 26, 30, 31, 33, 35, 43, 51, 54, 56, 57, 63, 67, 68, 69, 74, 77, 81, 82, 88, 92, 94, 95, 96, 102, 103, 106, 107, 109, 111, 112, 113, 115, 117, 119, 124, 125, 128, 132, 133, 134, 135, 140, 141, 144, 145, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 167, 171, 172, 174, 176, 177, 179, 180, 184, 186, 187, 191, 201, 208, 210, 214, 216, 217, 218, 221, 223, 226, 227, 229, 235, 237, 241, 248, 251, 258, 261, 262, 263, 267, 269, 270, 279, 280, 281, 283, 287, 290, 314, 320, 322, 331, 333, 334, 335, 336, 342, 343, 345, 346, 347]\n",
      "number of unique client IDs: 121\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "if year == 1:\n",
    "    X_full = dfs[0].copy()\n",
    "    temp = Y[\"Followup\"]\n",
    "\n",
    "    n_full = X_full.shape[0]\n",
    "    n_features = X_full.shape[1]\n",
    "\n",
    "    y_full_array = np.zeros((n_full, ))\n",
    "    for i in range(n_full):\n",
    "        if temp[i] >= 12:\n",
    "            y_full_array[i] = 1\n",
    "\n",
    "    y_full = pd.DataFrame({'label': y_full_array})\n",
    "    \n",
    "elif year == 2:\n",
    "    X_full = dfs[1].copy()\n",
    "    indexNames = df[df[\"Followup1y\"] < 12].index\n",
    "\n",
    "    temp = Y[\"Followup\"]\n",
    "\n",
    "    n_full = X_full.shape[0]\n",
    "    n_features = X_full.shape[1]\n",
    "\n",
    "    y_full_array = np.zeros((n_full, ))\n",
    "    for i in range(n_full):\n",
    "        if temp[i] >= 24:\n",
    "            y_full_array[i] = 1\n",
    "\n",
    "    y_full = pd.DataFrame({'label': y_full_array})\n",
    "\n",
    "    X_full.drop(indexNames , inplace=True)\n",
    "    y_full.drop(indexNames , inplace=True)\n",
    "    \n",
    "elif year == 3:\n",
    "    X_full = dfs[2].copy()\n",
    "    indexNames = df[df[\"Followup2y\"] < 24].index\n",
    "\n",
    "    temp = Y[\"Followup\"]\n",
    "\n",
    "    n_full = X_full.shape[0]\n",
    "    n_features = X_full.shape[1]\n",
    "\n",
    "    y_full_array = np.zeros((n_full, ))\n",
    "    for i in range(n_full):\n",
    "        if temp[i] >= 36:\n",
    "            y_full_array[i] = 1\n",
    "\n",
    "    y_full = pd.DataFrame({'label': y_full_array})\n",
    "\n",
    "    X_full.drop(indexNames , inplace=True)\n",
    "    y_full.drop(indexNames , inplace=True)\n",
    "\n",
    "else:\n",
    "    print('Invalid year number! Please enter again.')\n",
    "\n",
    "    \n",
    "print(f\"Full Data: \\n X's shape: {X_full.shape} \\n y's shape: {y_full.shape}\")    \n",
    "    \n",
    "plt.figure()\n",
    "client_ids = X_full['Clinic code']\n",
    "client_ids.plot.hist()\n",
    "\n",
    "unique_client_ids = set(client_ids)\n",
    "unique_client_ids = list(unique_client_ids)\n",
    "num_unique_client_ids = len(unique_client_ids)\n",
    "\n",
    "print('unique client IDs:', unique_client_ids)\n",
    "print('number of unique client IDs:', num_unique_client_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def make_federated_data(X_full, y_full, selected_client_ids):\n",
    "    X_res = pd.DataFrame()\n",
    "    y_res = pd.DataFrame()\n",
    "#     y_res = []\n",
    "#     y_res = np.array(y_res)\n",
    "    for selected_id in list(set(selected_client_ids)):\n",
    "#         print('Number of samples: %d' % X_res.shape[0])\n",
    "        X_selected = X_full.loc[X_full['Clinic code'] == selected_id]\n",
    "        X_res = pd.concat([X_res, X_selected], ignore_index=True)\n",
    "        y_selected = y_full.loc[X_selected.index]\n",
    "        y_res = pd.concat([y_res, y_selected], ignore_index=True)\n",
    "          \n",
    "    X_res.to_numpy\n",
    "    X_res = tf.convert_to_tensor(X_res, dtype=tf.float32)\n",
    "    y_res.to_numpy\n",
    "    y_res = tf.convert_to_tensor(y_res, dtype=tf.int32)\n",
    "    print('Number of samples: %d' % X_res.shape[0])\n",
    "#     print(X_res.shape)\n",
    "#     print(y_res.shape)\n",
    "\n",
    "    res = tf.data.Dataset.from_tensor_slices((X_res, y_res))\n",
    "\n",
    "    res = res.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE)\n",
    "#     res = res.shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def select_largest_clients(client_ids, k=10):\n",
    "    sorted_list = [item for items, c in Counter(client_ids).most_common() \n",
    "                                      for item in [items]] \n",
    "    result = sorted_list[:k]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model():\n",
    "    model = keras.Sequential([\n",
    "                keras.layers.InputLayer(input_shape=(65,)),\n",
    "                keras.layers.Dense(units=32, activation='relu',dtype='float64'),\n",
    "                keras.layers.Dense(units=1, activation='sigmoid',dtype='float64')\n",
    "            ])\n",
    "    return model\n",
    "\n",
    "def model_fn():\n",
    "  # We _must_ create a new model here, and _not_ capture it from an external\n",
    "  # scope. TFF will call this within different graph contexts.\n",
    "    \n",
    "#     input_spec = collections.OrderedDict(\n",
    "#         x=tf.TensorSpec(shape=[None, 66], dtype=tf.float32),\n",
    "#         y=tf.TensorSpec(shape=[None, 1], dtype=tf.int32))\n",
    "    keras_model = create_keras_model()\n",
    "    return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      input_spec=input_spec,\n",
    "      loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split by clinic ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected clinic codes for testing:  [187, 43, 103, 96, 281, 18, 176, 210, 184, 267, 346, 115, 258, 280, 214, 63, 218, 174, 107, 112, 3, 235, 167, 261]\n",
      "Number of samples: 1275\n"
     ]
    }
   ],
   "source": [
    "# # select clients randomly\n",
    "# test_client_library = list()\n",
    "# for client_id in unique_client_ids:\n",
    "#     if client_id not in selected_client_ids:\n",
    "#         test_client_library.append(client_id)\n",
    "\n",
    "# test_client_ids = np.random.choice(unique_client_ids, size=24, replace=False)\n",
    "test_client_ids = [187,43,103,96,281,18,176,210,184,267,346,115,258,280,214,63,218,174,107,112,3,235,167,261]\n",
    "print('Selected clinic codes for testing: ', test_client_ids)\n",
    "\n",
    "federated_test_data = make_federated_data(X_full, y_full, test_client_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected clinic codes for training:  [ 23 262 335 135  95 269 132 109 342 336  81 156 251 283 144  77 241 111\n",
      "  69 154 223 322  94 279 150 221 149 263 177 345 159  54 314   5 172  10\n",
      "  57  56 119  51  92 237 179 347 334  26 248 124 229 145 113 158 333 343\n",
      " 227 106  30   6 287 270  12 171 191  67 140 186  74 128 157 180 217 201\n",
      "  35  31   2 102  88 125 226 153 117 216 331  82 152 147 320 151 208 133\n",
      " 134   1  68 290  33 141 155]\n",
      "Number of samples: 4432\n"
     ]
    }
   ],
   "source": [
    "client_ids_without_test = []\n",
    "for index in client_ids:\n",
    "    if index not in test_client_ids:\n",
    "        client_ids_without_test.append(index)\n",
    "\n",
    "# selected_client_ids = select_largest_clients(client_ids_without_test, k=12)\n",
    "client_ids_without_test = list(set(client_ids_without_test))\n",
    "selected_client_ids = np.random.choice(client_ids_without_test, 97, replace=False)\n",
    "\n",
    "print('Selected clinic codes for training: ', selected_client_ids)\n",
    "\n",
    "federated_train_data = make_federated_data(X_full, y_full, selected_client_ids)\n",
    "\n",
    "input_spec = federated_train_data.element_spec\n",
    "\n",
    "# print(input_spec)\n",
    "\n",
    "# for itr in federated_train_data:\n",
    "#     print(itr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterative_process = tff.learning.build_federated_averaging_process(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.Adam())\n",
    "\n",
    "# str(iterative_process.initialize.type_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  0, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6175541), ('recall', 0.6763458), ('precision', 0.65861845), ('loss', 0.8461683)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round  1, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.61665165), ('recall', 0.6634845), ('precision', 0.6616422), ('loss', 0.8722419)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round  2, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6246992), ('recall', 0.6779369), ('precision', 0.66627574), ('loss', 0.8502818)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round  3, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.62191635), ('recall', 0.6782021), ('precision', 0.66299415), ('loss', 0.8427963)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round  4, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6223676), ('recall', 0.67501986), ('precision', 0.6645346), ('loss', 0.84551185)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round  5, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6192088), ('recall', 0.67276585), ('precision', 0.6616247), ('loss', 0.85207534)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round  6, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.62815887), ('recall', 0.68562716), ('precision', 0.6677428), ('loss', 0.83359325)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round  7, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6289862), ('recall', 0.69318485), ('precision', 0.6662419), ('loss', 0.8224737)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round  8, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6299639), ('recall', 0.68920714), ('precision', 0.66863906), ('loss', 0.81403893)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round  9, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6234958), ('recall', 0.68257755), ('precision', 0.6634021), ('loss', 0.824289)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 10, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.62815887), ('recall', 0.68814635), ('precision', 0.66692364), ('loss', 0.8349597)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 11, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6319194), ('recall', 0.6910634), ('precision', 0.67026746), ('loss', 0.8188078)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 12, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.62672985), ('recall', 0.67859983), ('precision', 0.668408), ('loss', 0.8502241)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 13, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6295878), ('recall', 0.68880934), ('precision', 0.66833913), ('loss', 0.8179856)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 14, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6268803), ('recall', 0.68522936), ('precision', 0.6664088), ('loss', 0.8149819)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 15, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.62913656), ('recall', 0.68589234), ('precision', 0.6687783), ('loss', 0.81740135)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 16, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6297383), ('recall', 0.6866879), ('precision', 0.66920793), ('loss', 0.8138573)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 17, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.619284), ('recall', 0.6784673), ('precision', 0.6599175), ('loss', 0.82998705)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 18, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.62620336), ('recall', 0.68522936), ('precision', 0.66563624), ('loss', 0.82034534)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 19, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6246992), ('recall', 0.68257755), ('precision', 0.66477275), ('loss', 0.81671625)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 20, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.62672985), ('recall', 0.68841153), ('precision', 0.6652146), ('loss', 0.80911535)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 21, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6280084), ('recall', 0.6807213), ('precision', 0.66918665), ('loss', 0.81877965)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 22, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6255265), ('recall', 0.6821798), ('precision', 0.665847), ('loss', 0.80380267)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 23, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6300391), ('recall', 0.68549454), ('precision', 0.6699495), ('loss', 0.80738306)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 24, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6305656), ('recall', 0.6805887), ('precision', 0.6722106), ('loss', 0.8347866)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 25, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6367329), ('recall', 0.69318485), ('precision', 0.6751033), ('loss', 0.78963804)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 26, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6348526), ('recall', 0.6933174), ('precision', 0.6728864), ('loss', 0.7635451)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 27, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.62861013), ('recall', 0.6819146), ('precision', 0.6694871), ('loss', 0.797896)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 28, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6301143), ('recall', 0.6805887), ('precision', 0.67168283), ('loss', 0.77549905)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 29, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6314681), ('recall', 0.6840361), ('precision', 0.6720948), ('loss', 0.79198515)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 30, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63018954), ('recall', 0.6815168), ('precision', 0.6714566), ('loss', 0.798751)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 31, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63259625), ('recall', 0.68814635), ('precision', 0.67201865), ('loss', 0.7724118)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 32, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63206977), ('recall', 0.6833731), ('precision', 0.6730217), ('loss', 0.7936336)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 33, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6313177), ('recall', 0.6844338), ('precision', 0.67178553), ('loss', 0.7993367)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 34, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6300391), ('recall', 0.6849642), ('precision', 0.67012584), ('loss', 0.7822841)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 35, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6276324), ('recall', 0.6821798), ('precision', 0.6682686), ('loss', 0.78696245)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 36, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.633574), ('recall', 0.6849642), ('precision', 0.6742365), ('loss', 0.764332)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 37, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6207882), ('recall', 0.6722355), ('precision', 0.66361254), ('loss', 0.78598136)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 38, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63342357), ('recall', 0.6886767), ('precision', 0.6727979), ('loss', 0.75604403)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 39, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6257521), ('recall', 0.67767173), ('precision', 0.66758096), ('loss', 0.7725911)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 40, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.62891096), ('recall', 0.6793954), ('precision', 0.67068064), ('loss', 0.7699662)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 41, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.626429), ('recall', 0.6762132), ('precision', 0.66885245), ('loss', 0.7688835)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 42, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6295126), ('recall', 0.6784673), ('precision', 0.67169863), ('loss', 0.7632478)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 43, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63252103), ('recall', 0.68920714), ('precision', 0.6715762), ('loss', 0.7451907)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 44, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.62672985), ('recall', 0.6742243), ('precision', 0.6698722), ('loss', 0.7649528)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 45, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63237065), ('recall', 0.6866879), ('precision', 0.6722482), ('loss', 0.7482482)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 46, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63605595), ('recall', 0.6951737), ('precision', 0.6736477), ('loss', 0.74280316)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 47, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6377858), ('recall', 0.6942456), ('precision', 0.6759618), ('loss', 0.731181)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 48, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6343261), ('recall', 0.6953063), ('precision', 0.6716189), ('loss', 0.73426425)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 49, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6369585), ('recall', 0.6972951), ('precision', 0.67397153), ('loss', 0.72180915)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 50, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63447654), ('recall', 0.69146115), ('precision', 0.6730769), ('loss', 0.74045485)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 51, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6370337), ('recall', 0.69742775), ('precision', 0.6740133), ('loss', 0.72700185)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 52, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64086944), ('recall', 0.70299655), ('precision', 0.6765344), ('loss', 0.70673585)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 53, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63951564), ('recall', 0.702864), ('precision', 0.6750286), ('loss', 0.7398075)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 54, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6461342), ('recall', 0.71546006), ('precision', 0.6783155), ('loss', 0.72500235)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 55, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6357551), ('recall', 0.6929197), ('precision', 0.67406166), ('loss', 0.72199994)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 56, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63583034), ('recall', 0.6968974), ('precision', 0.67281103), ('loss', 0.72314775)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 57, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6377106), ('recall', 0.69835585), ('precision', 0.6744782), ('loss', 0.71546143)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 58, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6392148), ('recall', 0.69676477), ('precision', 0.67675465), ('loss', 0.7173722)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 59, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.645006), ('recall', 0.70697427), ('precision', 0.6799286), ('loss', 0.69429797)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 60, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6377858), ('recall', 0.69702995), ('precision', 0.6750128), ('loss', 0.7117525)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 61, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64297533), ('recall', 0.70432246), ('precision', 0.678503), ('loss', 0.7167585)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 62, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6392148), ('recall', 0.7008751), ('precision', 0.67535454), ('loss', 0.70256644)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 63, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64019257), ('recall', 0.70299655), ('precision', 0.67575836), ('loss', 0.7177822)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 64, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64598376), ('recall', 0.7064439), ('precision', 0.6812428), ('loss', 0.7111568)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 65, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64086944), ('recall', 0.70339435), ('precision', 0.67639935), ('loss', 0.6887805)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 66, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6404182), ('recall', 0.69742775), ('precision', 0.6779224), ('loss', 0.71584177)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 67, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64357704), ('recall', 0.710952), ('precision', 0.6769347), ('loss', 0.7196817)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 68, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6500451), ('recall', 0.7151949), ('precision', 0.6828712), ('loss', 0.7150499)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 69, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64651024), ('recall', 0.70365953), ('precision', 0.6828358), ('loss', 0.70731777)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 70, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64681107), ('recall', 0.71055424), ('precision', 0.6807673), ('loss', 0.71581316)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 71, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6426745), ('recall', 0.70365953), ('precision', 0.67838424), ('loss', 0.7043438)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 72, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6413959), ('recall', 0.70167065), ('precision', 0.6775928), ('loss', 0.70890045)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 73, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64109504), ('recall', 0.6988862), ('precision', 0.6782038), ('loss', 0.6813067)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 74, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6433514), ('recall', 0.70007956), ('precision', 0.68041235), ('loss', 0.68958974)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 75, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.649293), ('recall', 0.7166534), ('precision', 0.68150294), ('loss', 0.69324976)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 76, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6456077), ('recall', 0.7096261), ('precision', 0.6797054), ('loss', 0.6807264)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 77, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6437274), ('recall', 0.7037921), ('precision', 0.67955446), ('loss', 0.6945585)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 78, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.642148), ('recall', 0.7011403), ('precision', 0.6786448), ('loss', 0.68068063)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 79, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64703673), ('recall', 0.7137364), ('precision', 0.67992926), ('loss', 0.6686069)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 80, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64515644), ('recall', 0.7106868), ('precision', 0.6788247), ('loss', 0.7007677)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 81, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6407942), ('recall', 0.69769293), ('precision', 0.6782676), ('loss', 0.69022346)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 82, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64538205), ('recall', 0.7159904), ('precision', 0.67728585), ('loss', 0.70125985)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 83, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65019554), ('recall', 0.72076374), ('precision', 0.68111765), ('loss', 0.691223)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 84, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64462996), ('recall', 0.7061787), ('precision', 0.6797703), ('loss', 0.6826162)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 85, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.650722), ('recall', 0.71625566), ('precision', 0.6832785), ('loss', 0.692311)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 86, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64703673), ('recall', 0.710952), ('precision', 0.6808889), ('loss', 0.6732748)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 87, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6498947), ('recall', 0.7122779), ('precision', 0.68372154), ('loss', 0.69005483)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 88, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6466606), ('recall', 0.708698), ('precision', 0.68123883), ('loss', 0.68098915)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 89, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.654633), ('recall', 0.7166534), ('precision', 0.687659), ('loss', 0.6685222)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 90, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6444795), ('recall', 0.70127285), ('precision', 0.68130875), ('loss', 0.68554276)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 91, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6482401), ('recall', 0.7110846), ('precision', 0.68222874), ('loss', 0.67426485)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 92, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64884174), ('recall', 0.7137364), ('precision', 0.6819967), ('loss', 0.6788392)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 93, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65094763), ('recall', 0.71307343), ('precision', 0.6846595), ('loss', 0.6571945)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 94, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64816487), ('recall', 0.70697427), ('precision', 0.68358976), ('loss', 0.67253196)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 95, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65508425), ('recall', 0.7155927), ('precision', 0.68856853), ('loss', 0.66507375)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 96, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6498947), ('recall', 0.71148235), ('precision', 0.6840026), ('loss', 0.68037283)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 97, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6504212), ('recall', 0.7083002), ('precision', 0.68575096), ('loss', 0.6692702)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 98, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6492178), ('recall', 0.7108194), ('precision', 0.6834523), ('loss', 0.67721933)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n",
      "round 99, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64455473), ('recall', 0.70365953), ('precision', 0.6805591), ('loss', 0.68225205)])), ('stat', OrderedDict([('num_examples', 13296)]))])\n"
     ]
    }
   ],
   "source": [
    "NUM_ROUNDS = 100\n",
    "for round_num in range(NUM_ROUNDS):\n",
    "  state, metrics = iterative_process.next(state, [federated_train_data])\n",
    "  print('round {:2d}, metrics={}'.format(round_num, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Year: 1 Recall: 0.7820207 Precision: 0.69055146 F1 score: 0.7334452853415028\n",
      "Test: Year: 1 Recall: 0.68837804 Precision: 0.6963824 F1 score: 0.6923571155712464\n"
     ]
    }
   ],
   "source": [
    "# evaluation the model\n",
    "evaluation = tff.learning.build_federated_evaluation(model_fn)\n",
    "# str(evaluation.type_signature)\n",
    "\n",
    "train_metrics = evaluation(state.model, [federated_train_data])\n",
    "\n",
    "recall_train = train_metrics['recall']\n",
    "precision_train = train_metrics['precision']\n",
    "f1_train = 2 * recall_train * precision_train / (recall_train + precision_train)\n",
    "print('Train:',\n",
    "      'Year:', year,\n",
    "      'Recall:', recall_train,\n",
    "      'Precision:', precision_train,\n",
    "      'F1 score:', f1_train)\n",
    "\n",
    "test_metrics = evaluation(state.model, [federated_test_data])\n",
    "\n",
    "recall_test = test_metrics['recall']\n",
    "precision_test = test_metrics['precision']\n",
    "f1_test = 2 * recall_test * precision_test / (recall_test + precision_test)\n",
    "print('Test:',\n",
    "      'Year:', year,\n",
    "      'Recall:', recall_test,\n",
    "      'Precision:', precision_test,\n",
    "      'F1 score:', f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trained_model = create_keras_model()\n",
    "\n",
    "state.model.assign_weights_to(\n",
    "    trained_model\n",
    ")\n",
    "\n",
    "prediction = trained_model.predict(X_full)\n",
    "\n",
    "# print(prediction)\n",
    "# print(y_full)\n",
    "\n",
    "\n",
    "plt.hist(prediction)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist(y_full)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split by train-test ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test data\n",
    "import random\n",
    "\n",
    "\n",
    "def split_data_federated(X_full, y_full, train_ratio):\n",
    "    X_train = pd.DataFrame()\n",
    "    y_train = pd.DataFrame()\n",
    "    X_test = pd.DataFrame()\n",
    "    y_test = pd.DataFrame()\n",
    "#     y_res = []\n",
    "#     y_res = np.array(y_res)\n",
    "\n",
    "    train_num = int(train_ratio * X_full.shape[0])\n",
    "    test_num = X_full.shape[0] - train_num\n",
    "\n",
    "    test_ids = np.random.choice(range(X_full.shape[0]), size=test_num, replace=False)\n",
    "    ids_without_test = []\n",
    "    for index in range(X_full.shape[0]):\n",
    "        if index not in test_ids:\n",
    "            ids_without_test.append(index)\n",
    "\n",
    "    # selected_client_ids = select_largest_clients(client_ids_without_test, k=12)\n",
    "    ids_without_test = list(set(ids_without_test))\n",
    "    train_ids = np.random.choice(ids_without_test, train_num, replace=False)\n",
    "    \n",
    "    print(train_ids.shape)\n",
    "    print(test_ids.shape)\n",
    "    \n",
    "    X_train = X_full.iloc[train_ids]\n",
    "    y_train = y_full.iloc[train_ids]\n",
    "    X_test = X_full.iloc[test_ids]\n",
    "    y_test = y_full.iloc[test_ids]\n",
    "    \n",
    "#     for selected_id in selected_client_ids:\n",
    "#         X_selected = X_full.loc[X_full['Clinic code'] == selected_id]\n",
    "#         X_res = pd.concat([X_res, X_selected], ignore_index=True)\n",
    "#         y_selected = y_full.loc[X_selected.index]\n",
    "#         y_res = pd.concat([y_res, y_selected], ignore_index=True)\n",
    "        \n",
    "    X_train.to_numpy\n",
    "    X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "    y_train.to_numpy\n",
    "    y_train = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "    X_test.to_numpy\n",
    "    X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "    y_test.to_numpy\n",
    "    y_test = tf.convert_to_tensor(y_test, dtype=tf.int32)\n",
    "    \n",
    "#     print(X_res.shape)\n",
    "#     print(y_res.shape)\n",
    "\n",
    "    train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "    train_set = train_set.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE)\n",
    "    test_set = test_set.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE)\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5136,)\n",
      "(571,)\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.9\n",
    "federated_train_data, federated_test_data = split_data_federated(X_full, y_full, train_ratio)\n",
    "input_spec = federated_train_data.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterative_process = tff.learning.build_federated_averaging_process(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  0, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6357736), ('recall', 0.7207814), ('precision', 0.6726034), ('loss', 0.69690925)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round  1, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63389146), ('recall', 0.71943414), ('precision', 0.67099476), ('loss', 0.6892359)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round  2, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63518953), ('recall', 0.7189851), ('precision', 0.67254776), ('loss', 0.6952827)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round  3, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6357736), ('recall', 0.7204446), ('precision', 0.672712), ('loss', 0.69327414)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round  4, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6347352), ('recall', 0.7151678), ('precision', 0.6732904), ('loss', 0.6828682)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round  5, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6359034), ('recall', 0.72022), ('precision', 0.67292565), ('loss', 0.6889151)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round  6, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6362279), ('recall', 0.71876055), ('precision', 0.6737529), ('loss', 0.69055915)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round  7, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6327882), ('recall', 0.71673965), ('precision', 0.6706587), ('loss', 0.69391847)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round  8, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63739616), ('recall', 0.72336364), ('precision', 0.67353123), ('loss', 0.6805672)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round  9, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6336319), ('recall', 0.7179746), ('precision', 0.67117965), ('loss', 0.6953958)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 10, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6349299), ('recall', 0.71752554), ('precision', 0.6727368), ('loss', 0.6861887)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 11, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6336319), ('recall', 0.71752554), ('precision', 0.67132354), ('loss', 0.6921901)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 12, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6379803), ('recall', 0.7222409), ('precision', 0.6745308), ('loss', 0.69087)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 13, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6375909), ('recall', 0.72347593), ('precision', 0.67370623), ('loss', 0.68750834)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 14, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64174455), ('recall', 0.7243741), ('precision', 0.6779447), ('loss', 0.68010277)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 15, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6339564), ('recall', 0.7180869), ('precision', 0.67149603), ('loss', 0.67825156)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 16, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63908356), ('recall', 0.7231391), ('precision', 0.67544043), ('loss', 0.678144)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 17, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63661736), ('recall', 0.72179186), ('precision', 0.6731937), ('loss', 0.6810806)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 18, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63525444), ('recall', 0.7152801), ('precision', 0.67382336), ('loss', 0.6860583)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 19, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63953793), ('recall', 0.7247109), ('precision', 0.6754212), ('loss', 0.6760573)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 20, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63609815), ('recall', 0.71954644), ('precision', 0.67335576), ('loss', 0.68254334)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 21, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.639473), ('recall', 0.7250477), ('precision', 0.67524046), ('loss', 0.685209)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 22, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6414849), ('recall', 0.72527224), ('precision', 0.67736185), ('loss', 0.67447037)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 23, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6402518), ('recall', 0.7228023), ('precision', 0.6768293), ('loss', 0.679498)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 24, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64200413), ('recall', 0.729314), ('precision', 0.67659616), ('loss', 0.66638505)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 25, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6402518), ('recall', 0.72572136), ('precision', 0.67586786), ('loss', 0.67535824)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 26, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6431724), ('recall', 0.73032445), ('precision', 0.67753357), ('loss', 0.6746747)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 27, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63999224), ('recall', 0.72167957), ('precision', 0.6769166), ('loss', 0.67296696)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 28, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6399273), ('recall', 0.72347593), ('precision', 0.6762515), ('loss', 0.6744858)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 29, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64524925), ('recall', 0.7327944), ('precision', 0.67897636), ('loss', 0.6648011)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 30, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6433022), ('recall', 0.73111033), ('precision', 0.677416), ('loss', 0.66835856)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 31, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6405114), ('recall', 0.7259459), ('precision', 0.67607695), ('loss', 0.6701423)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 32, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64252335), ('recall', 0.7290895), ('precision', 0.67723435), ('loss', 0.67246515)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 33, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6440161), ('recall', 0.7281913), ('precision', 0.6791623), ('loss', 0.67024416)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 34, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64524925), ('recall', 0.7302122), ('precision', 0.6798369), ('loss', 0.67262447)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 35, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64129025), ('recall', 0.728079), ('precision', 0.67622524), ('loss', 0.6674063)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 36, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.649338), ('recall', 0.73358035), ('precision', 0.68318695), ('loss', 0.6660462)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 37, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6471314), ('recall', 0.733019), ('precision', 0.68095535), ('loss', 0.66750926)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 38, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6479102), ('recall', 0.7358258), ('precision', 0.68086433), ('loss', 0.6666018)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 39, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64641744), ('recall', 0.7332435), ('precision', 0.68009996), ('loss', 0.6669893)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 40, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6497923), ('recall', 0.73548895), ('precision', 0.6830362), ('loss', 0.6632068)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 41, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64641744), ('recall', 0.7321208), ('precision', 0.68047583), ('loss', 0.66201043)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 42, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6484943), ('recall', 0.7348153), ('precision', 0.68184185), ('loss', 0.6697028)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 43, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6471314), ('recall', 0.7312226), ('precision', 0.68156135), ('loss', 0.66178614)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 44, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6484943), ('recall', 0.7339171), ('precision', 0.6821455), ('loss', 0.6625488)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 45, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6441459), ('recall', 0.72661954), ('precision', 0.6798319), ('loss', 0.6692153)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 46, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64739096), ('recall', 0.7336926), ('precision', 0.6810129), ('loss', 0.66035426)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 47, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64953274), ('recall', 0.7368362), ('precision', 0.68229544), ('loss', 0.6613081)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 48, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65083075), ('recall', 0.73537666), ('precision', 0.684216), ('loss', 0.6644773)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 49, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6507009), ('recall', 0.73728526), ('precision', 0.6834218), ('loss', 0.6575494)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 50, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6503115), ('recall', 0.7376221), ('precision', 0.6828812), ('loss', 0.6578146)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 51, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65160954), ('recall', 0.73930615), ('precision', 0.68372965), ('loss', 0.65444934)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 52, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64816976), ('recall', 0.73436624), ('precision', 0.6816382), ('loss', 0.6569437)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 53, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6523884), ('recall', 0.739643), ('precision', 0.68446755), ('loss', 0.65537983)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 54, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65050626), ('recall', 0.73728526), ('precision', 0.68320847), ('loss', 0.65494305)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 55, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6495976), ('recall', 0.7339171), ('precision', 0.6833577), ('loss', 0.6578557)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 56, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6497923), ('recall', 0.7399798), ('precision', 0.6815221), ('loss', 0.654278)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 57, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65212876), ('recall', 0.73840797), ('precision', 0.684605), ('loss', 0.65577775)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 58, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6497923), ('recall', 0.7338049), ('precision', 0.6836105), ('loss', 0.6588584)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 59, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65251815), ('recall', 0.73638713), ('precision', 0.6857292), ('loss', 0.65418077)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 60, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65044135), ('recall', 0.7316717), ('precision', 0.6850625), ('loss', 0.6590769)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 61, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64719623), ('recall', 0.730549), ('precision', 0.68186104), ('loss', 0.6644163)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 62, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6523884), ('recall', 0.7360503), ('precision', 0.6857023), ('loss', 0.66008896)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 63, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6497274), ('recall', 0.73077357), ('precision', 0.6845814), ('loss', 0.65723157)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 64, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65245324), ('recall', 0.73436624), ('precision', 0.68635887), ('loss', 0.6551626)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 65, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6532321), ('recall', 0.7389693), ('precision', 0.685625), ('loss', 0.6475626)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 66, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.653946), ('recall', 0.7352644), ('precision', 0.68770343), ('loss', 0.6551667)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 67, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6558281), ('recall', 0.7389693), ('precision', 0.6884937), ('loss', 0.65407467)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 68, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6540758), ('recall', 0.7356012), ('precision', 0.6877296), ('loss', 0.6551328)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 69, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.654595), ('recall', 0.739643), ('precision', 0.68689394), ('loss', 0.65236664)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 70, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6541407), ('recall', 0.7398675), ('precision', 0.68631536), ('loss', 0.6499194)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 71, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65050626), ('recall', 0.73346806), ('precision', 0.6845138), ('loss', 0.6499158)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 72, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6514149), ('recall', 0.731784), ('precision', 0.68610525), ('loss', 0.65232235)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 73, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6549195), ('recall', 0.7399798), ('precision', 0.6871351), ('loss', 0.6541285)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 74, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6532321), ('recall', 0.7358258), ('precision', 0.6867142), ('loss', 0.6485472)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 75, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65615267), ('recall', 0.740878), ('precision', 0.6881844), ('loss', 0.65001124)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 76, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6578401), ('recall', 0.7430111), ('precision', 0.6893032), ('loss', 0.6432765)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 77, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65654206), ('recall', 0.743797), ('precision', 0.6875973), ('loss', 0.64624333)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 78, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.654595), ('recall', 0.7411025), ('precision', 0.6863887), ('loss', 0.64907265)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 79, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.66160434), ('recall', 0.7449197), ('precision', 0.6928057), ('loss', 0.6470443)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 80, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6587487), ('recall', 0.74413383), ('precision', 0.68991363), ('loss', 0.64647967)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 81, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6550493), ('recall', 0.7380712), ('precision', 0.68794477), ('loss', 0.6501905)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 82, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6591381), ('recall', 0.7426743), ('precision', 0.69086164), ('loss', 0.64876336)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 83, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6586189), ('recall', 0.7420007), ('precision', 0.69052345), ('loss', 0.64316636)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 84, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6582295), ('recall', 0.7415516), ('precision', 0.69024974), ('loss', 0.64462864)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 85, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6544652), ('recall', 0.7338049), ('precision', 0.68879753), ('loss', 0.64860827)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 86, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6586189), ('recall', 0.7426743), ('precision', 0.6902849), ('loss', 0.643495)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 87, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65777516), ('recall', 0.7416639), ('precision', 0.68970555), ('loss', 0.64333445)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 88, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6580997), ('recall', 0.7389693), ('precision', 0.69102365), ('loss', 0.6460373)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 89, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65647715), ('recall', 0.7377344), ('precision', 0.68965155), ('loss', 0.64849937)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 90, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65641224), ('recall', 0.7389693), ('precision', 0.6891425), ('loss', 0.64824003)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 91, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65952754), ('recall', 0.74435836), ('precision', 0.69069695), ('loss', 0.64697886)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 92, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6580348), ('recall', 0.7395307), ('precision', 0.69075084), ('loss', 0.63925916)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 93, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6591381), ('recall', 0.74334794), ('precision', 0.69062275), ('loss', 0.63961715)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 94, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6602414), ('recall', 0.74368477), ('precision', 0.6917293), ('loss', 0.64468604)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 95, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6575156), ('recall', 0.7376221), ('precision', 0.69085175), ('loss', 0.64600956)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 96, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6596573), ('recall', 0.74604243), ('precision', 0.69024616), ('loss', 0.64253634)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 97, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6627077), ('recall', 0.74604243), ('precision', 0.69363254), ('loss', 0.6408077)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 98, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6602414), ('recall', 0.74435836), ('precision', 0.69148934), ('loss', 0.63462454)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 99, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6621885), ('recall', 0.74143934), ('precision', 0.69471914), ('loss', 0.64184886)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n"
     ]
    }
   ],
   "source": [
    "NUM_ROUNDS = 100\n",
    "for round_num in range(NUM_ROUNDS):\n",
    "  state, metrics = iterative_process.next(state, [federated_train_data])\n",
    "  print('round {:2d}, metrics={}'.format(round_num, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Year: 1 Recall: 0.8804311 Precision: 0.6626109 F1 score: 0.756146967812784\n",
      "Test: Year: 1 Recall: 0.847561 Precision: 0.6318182 F1 score: 0.7239583386108276\n"
     ]
    }
   ],
   "source": [
    "# evaluation the model\n",
    "evaluation = tff.learning.build_federated_evaluation(model_fn)\n",
    "# str(evaluation.type_signature)\n",
    "\n",
    "train_metrics = evaluation(state.model, [federated_train_data])\n",
    "\n",
    "recall_train = train_metrics['recall']\n",
    "precision_train = train_metrics['precision']\n",
    "f1_train = 2 * recall_train * precision_train / (recall_train + precision_train)\n",
    "print('Train:',\n",
    "      'Year:', year,\n",
    "      'Recall:', recall_train,\n",
    "      'Precision:', precision_train,\n",
    "      'F1 score:', f1_train)\n",
    "\n",
    "test_metrics = evaluation(state.model, [federated_test_data])\n",
    "\n",
    "recall_test = test_metrics['recall']\n",
    "precision_test = test_metrics['precision']\n",
    "f1_test = 2 * recall_test * precision_test / (recall_test + precision_test)\n",
    "print('Test:',\n",
    "      'Year:', year,\n",
    "      'Recall:', recall_test,\n",
    "      'Precision:', precision_test,\n",
    "      'F1 score:', f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trained_model = create_keras_model()\n",
    "\n",
    "state.model.assign_weights_to(\n",
    "    trained_model\n",
    ")\n",
    "\n",
    "prediction = trained_model.predict(X_full)\n",
    "\n",
    "# print(prediction)\n",
    "# print(y_full)\n",
    "\n",
    "\n",
    "plt.hist(prediction)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist(y_full)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
