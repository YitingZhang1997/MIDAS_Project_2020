{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tensorflow_federated_nightly also bring in tf_nightly, which\n",
    "# # can causes a duplicate tensorboard install, leading to errors.\n",
    "# !pip uninstall --yes tensorboard tb-nightly\n",
    "\n",
    "# !pip install --quiet --upgrade tensorflow_federated_nightly\n",
    "# !pip install --quiet --upgrade nest_asyncio\n",
    "# !pip install --quiet tb-nightly  # or tensorboard, but not both\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yitzhang/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:43: UserWarning: You are currently using a nightly version of TensorFlow (2.5.0-dev20210103). \n",
      "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
      "If you encounter a bug, do not file an issue on GitHub.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yitzhang/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:59: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yitzhang/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:59: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'Hello, World!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "tff.federated_computation(lambda: 'Hello, World!')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "filename = 'BRAZPD_UnofM_all.csv'\n",
    "\n",
    "df = pd.read_csv(filename, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODPAX</th>\n",
       "      <th>Hemoglobin</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Phosphate</th>\n",
       "      <th>Mean_PAS_1T</th>\n",
       "      <th>Mean_PAD_1T</th>\n",
       "      <th>Mean_PAS_2T</th>\n",
       "      <th>Mean_PAD_2T</th>\n",
       "      <th>Mean_PAS_3T</th>\n",
       "      <th>Mean_PAD_3T</th>\n",
       "      <th>...</th>\n",
       "      <th>Diastolic70</th>\n",
       "      <th>Systolic71</th>\n",
       "      <th>Diastolic71</th>\n",
       "      <th>Systolic72</th>\n",
       "      <th>Diastolic72</th>\n",
       "      <th>Systolic73</th>\n",
       "      <th>Diastolic73</th>\n",
       "      <th>Systolic74</th>\n",
       "      <th>Diastolic74</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1349037</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>110.500000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1349040</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.766667</td>\n",
       "      <td>5.933333</td>\n",
       "      <td>129.500000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>120.333333</td>\n",
       "      <td>68.666667</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1349048</td>\n",
       "      <td>11.833333</td>\n",
       "      <td>4.366667</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>154.666667</td>\n",
       "      <td>87.666667</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1349051</td>\n",
       "      <td>10.066667</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>147.333333</td>\n",
       "      <td>92.333333</td>\n",
       "      <td>169.333333</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1349055</td>\n",
       "      <td>11.933333</td>\n",
       "      <td>4.033333</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>103.500000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>154.666667</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>129.333333</td>\n",
       "      <td>72.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>347457070</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>347457071</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>3.233333</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>113.333333</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>347457072</td>\n",
       "      <td>10.466667</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>4.466667</td>\n",
       "      <td>136.666667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>143.333333</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>347457073</td>\n",
       "      <td>11.766667</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>136.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>347457074</td>\n",
       "      <td>9.866667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5707 rows × 1735 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CODPAX  Hemoglobin  Potassium  Phosphate  Mean_PAS_1T  Mean_PAD_1T  \\\n",
       "0       1349037   12.933333   4.433333   5.300000   110.500000    70.000000   \n",
       "1       1349040   14.000000   3.766667   5.933333   129.500000    77.000000   \n",
       "2       1349048   11.833333   4.366667   6.100000   158.000000    81.000000   \n",
       "3       1349051   10.066667   4.733333   5.533333   140.000000    75.000000   \n",
       "4       1349055   11.933333   4.033333   4.066667   103.500000    60.000000   \n",
       "...         ...         ...        ...        ...          ...          ...   \n",
       "5702  347457070    8.400000   5.500000   4.700000   126.666667    76.666667   \n",
       "5703  347457071    9.700000   4.300000   3.233333   130.000000    80.000000   \n",
       "5704  347457072   10.466667   4.433333   4.466667   136.666667    80.000000   \n",
       "5705  347457073   11.766667   4.533333   3.566667   126.666667    80.000000   \n",
       "5706  347457074    9.866667   4.000000   4.100000   126.666667    80.000000   \n",
       "\n",
       "      Mean_PAS_2T  Mean_PAD_2T  Mean_PAS_3T  Mean_PAD_3T  ...  Diastolic70  \\\n",
       "0      125.000000    80.000000          NaN          NaN  ...          NaN   \n",
       "1      120.333333    68.666667   136.000000    82.000000  ...          NaN   \n",
       "2      154.666667    87.666667   147.000000    80.000000  ...          NaN   \n",
       "3      147.333333    92.333333   169.333333    99.000000  ...          NaN   \n",
       "4      154.666667    82.000000   129.333333    72.666667  ...          NaN   \n",
       "...           ...          ...          ...          ...  ...          ...   \n",
       "5702   126.666667    83.333333   120.000000    80.000000  ...          NaN   \n",
       "5703   113.333333    73.333333          NaN          NaN  ...          NaN   \n",
       "5704   143.333333    73.333333          NaN          NaN  ...          NaN   \n",
       "5705   136.666667    83.333333          NaN          NaN  ...          NaN   \n",
       "5706   130.000000    76.666667          NaN          NaN  ...          NaN   \n",
       "\n",
       "      Systolic71  Diastolic71  Systolic72  Diastolic72  Systolic73  \\\n",
       "0            NaN          NaN         NaN          NaN         NaN   \n",
       "1            NaN          NaN         NaN          NaN         NaN   \n",
       "2            NaN          NaN         NaN          NaN         NaN   \n",
       "3            NaN          NaN         NaN          NaN         NaN   \n",
       "4            NaN          NaN         NaN          NaN         NaN   \n",
       "...          ...          ...         ...          ...         ...   \n",
       "5702         NaN          NaN         NaN          NaN         NaN   \n",
       "5703         NaN          NaN         NaN          NaN         NaN   \n",
       "5704         NaN          NaN         NaN          NaN         NaN   \n",
       "5705         NaN          NaN         NaN          NaN         NaN   \n",
       "5706         NaN          NaN         NaN          NaN         NaN   \n",
       "\n",
       "      Diastolic73  Systolic74  Diastolic74  _merge  \n",
       "0             NaN         NaN          NaN       3  \n",
       "1             NaN         NaN          NaN       3  \n",
       "2             NaN         NaN          NaN       3  \n",
       "3             NaN         NaN          NaN       3  \n",
       "4             NaN         NaN          NaN       3  \n",
       "...           ...         ...          ...     ...  \n",
       "5702          NaN         NaN          NaN       3  \n",
       "5703          NaN         NaN          NaN       3  \n",
       "5704          NaN         NaN          NaN       3  \n",
       "5705          NaN         NaN          NaN       3  \n",
       "5706          NaN         NaN          NaN       3  \n",
       "\n",
       "[5707 rows x 1735 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODPAX</th>\n",
       "      <th>Hemoglobin</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Phosphate</th>\n",
       "      <th>Mean_PAS_1T</th>\n",
       "      <th>Mean_PAD_1T</th>\n",
       "      <th>Mean_PAS_2T</th>\n",
       "      <th>Mean_PAD_2T</th>\n",
       "      <th>Mean_PAS_3T</th>\n",
       "      <th>Mean_PAD_3T</th>\n",
       "      <th>...</th>\n",
       "      <th>OUTROS65</th>\n",
       "      <th>OUTROS66</th>\n",
       "      <th>OUTROS67</th>\n",
       "      <th>OUTROS68</th>\n",
       "      <th>OUTROS69</th>\n",
       "      <th>OUTROS70</th>\n",
       "      <th>OUTROS71</th>\n",
       "      <th>OUTROS72</th>\n",
       "      <th>OUTROS73</th>\n",
       "      <th>OUTROS74</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1349037</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>110.500000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1349040</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.766667</td>\n",
       "      <td>5.933333</td>\n",
       "      <td>129.500000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>120.333333</td>\n",
       "      <td>68.666667</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1349048</td>\n",
       "      <td>11.833333</td>\n",
       "      <td>4.366667</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>154.666667</td>\n",
       "      <td>87.666667</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1349051</td>\n",
       "      <td>10.066667</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>147.333333</td>\n",
       "      <td>92.333333</td>\n",
       "      <td>169.333333</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1349055</td>\n",
       "      <td>11.933333</td>\n",
       "      <td>4.033333</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>103.500000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>154.666667</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>129.333333</td>\n",
       "      <td>72.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>347457070</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>347457071</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>3.233333</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>113.333333</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>347457072</td>\n",
       "      <td>10.466667</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>4.466667</td>\n",
       "      <td>136.666667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>143.333333</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>347457073</td>\n",
       "      <td>11.766667</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>136.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>347457074</td>\n",
       "      <td>9.866667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5707 rows × 1735 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CODPAX  Hemoglobin  Potassium  Phosphate  Mean_PAS_1T  Mean_PAD_1T  \\\n",
       "0       1349037   12.933333   4.433333   5.300000   110.500000    70.000000   \n",
       "1       1349040   14.000000   3.766667   5.933333   129.500000    77.000000   \n",
       "2       1349048   11.833333   4.366667   6.100000   158.000000    81.000000   \n",
       "3       1349051   10.066667   4.733333   5.533333   140.000000    75.000000   \n",
       "4       1349055   11.933333   4.033333   4.066667   103.500000    60.000000   \n",
       "...         ...         ...        ...        ...          ...          ...   \n",
       "5702  347457070    8.400000   5.500000   4.700000   126.666667    76.666667   \n",
       "5703  347457071    9.700000   4.300000   3.233333   130.000000    80.000000   \n",
       "5704  347457072   10.466667   4.433333   4.466667   136.666667    80.000000   \n",
       "5705  347457073   11.766667   4.533333   3.566667   126.666667    80.000000   \n",
       "5706  347457074    9.866667   4.000000   4.100000   126.666667    80.000000   \n",
       "\n",
       "      Mean_PAS_2T  Mean_PAD_2T  Mean_PAS_3T  Mean_PAD_3T  ...  OUTROS65  \\\n",
       "0      125.000000    80.000000          NaN          NaN  ...         0   \n",
       "1      120.333333    68.666667   136.000000    82.000000  ...         0   \n",
       "2      154.666667    87.666667   147.000000    80.000000  ...         0   \n",
       "3      147.333333    92.333333   169.333333    99.000000  ...         0   \n",
       "4      154.666667    82.000000   129.333333    72.666667  ...         0   \n",
       "...           ...          ...          ...          ...  ...       ...   \n",
       "5702   126.666667    83.333333   120.000000    80.000000  ...         0   \n",
       "5703   113.333333    73.333333          NaN          NaN  ...         0   \n",
       "5704   143.333333    73.333333          NaN          NaN  ...         0   \n",
       "5705   136.666667    83.333333          NaN          NaN  ...         0   \n",
       "5706   130.000000    76.666667          NaN          NaN  ...         0   \n",
       "\n",
       "      OUTROS66  OUTROS67  OUTROS68  OUTROS69  OUTROS70  OUTROS71  OUTROS72  \\\n",
       "0            0         0         0         0         0         0         0   \n",
       "1            0         0         0         0         0         0         0   \n",
       "2            0         0         0         0         0         0         0   \n",
       "3            0         0         0         0         0         0         0   \n",
       "4            0         0         0         0         0         0         0   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5702         0         0         0         0         0         0         0   \n",
       "5703         0         0         0         0         0         0         0   \n",
       "5704         0         0         0         0         0         0         0   \n",
       "5705         0         0         0         0         0         0         0   \n",
       "5706         0         0         0         0         0         0         0   \n",
       "\n",
       "      OUTROS73  OUTROS74  \n",
       "0            0         0  \n",
       "1            0         0  \n",
       "2            0         0  \n",
       "3            0         0  \n",
       "4            0         0  \n",
       "...        ...       ...  \n",
       "5702         0         0  \n",
       "5703         0         0  \n",
       "5704         0         0  \n",
       "5705         0         0  \n",
       "5706         0         0  \n",
       "\n",
       "[5707 rows x 1735 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "nMeasurements = 75\n",
    "nColumns = 1735\n",
    "nRecords = 5707\n",
    "timeseries_names = ['Ureia', 'Creatinine', 'TGP', 'Potassium', 'Calcium', 'Phosphate', 'Glucose', \n",
    "              'Hemoglobin', 'Hematocrit','Volume_Total', 'Systolic', 'Diastolic', 'N_AH_']\n",
    "\n",
    "different_format_ts_names = ['Mes_1_PAS', 'Mes_1_PAD', 'Mes_1_Uso_de_anti_hipert', 'Mes_1_inibidor',\\\n",
    "                             'Mes_1_beta', 'Mes_1_ant', 'Mes_1_diu', 'Mes_1_at_i', 'Mes_1_OUTROS']\n",
    "\n",
    "# Put timeseries names into standard format\n",
    "p = re.compile('[0-9]')\n",
    "strip = re.compile('Mes_[0-9]_')\n",
    "for timeseries in different_format_ts_names:\n",
    "    for i in range(1,nMeasurements):\n",
    "        try:\n",
    "            old_label = p.sub(str(i), timeseries)\n",
    "            new_label = strip.sub('',timeseries)\n",
    "            df[new_label+str(i)] = pd.Series(df[old_label])\n",
    "            df.drop([old_label],axis=1, inplace=True)\n",
    "        except:\n",
    "            print(f'Column {timeseries}{i} does not exist')\n",
    "    timeseries_names.append(new_label)\n",
    "    \n",
    "# make sure we don't have duplicate columns\n",
    "assert nColumns == df.shape[1]\n",
    "\n",
    "rename_dict = dict()\n",
    "rename_keys = {\"Uso_de_anti_hipert\": \"Use antihypertensive drug\",\\\n",
    "               \"inibidor\": \"ACE-inhibitor\",\\\n",
    "               \"at_i\": \"ATI blocker\",\\\n",
    "               \"beta\": \"beta-blocker\",\\\n",
    "               \"ant\": \"calcium antagonist\",\\\n",
    "               \"diu\": \"diuretic\"}\n",
    "for item in rename_keys.items():\n",
    "    key, value = item\n",
    "    for i in range(74):\n",
    "        new_key = key+str(i+1)\n",
    "        new_value = value+str(i+1)\n",
    "        rename_dict[new_key] = new_value\n",
    "        \n",
    "df = df.rename(columns=rename_dict)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODPAX</th>\n",
       "      <th>Hemoglobin</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Phosphate</th>\n",
       "      <th>Mean_PAS_1T</th>\n",
       "      <th>Mean_PAD_1T</th>\n",
       "      <th>Mean_PAS_2T</th>\n",
       "      <th>Mean_PAD_2T</th>\n",
       "      <th>Mean_PAS_3T</th>\n",
       "      <th>Mean_PAD_3T</th>\n",
       "      <th>...</th>\n",
       "      <th>OUTROS70</th>\n",
       "      <th>OUTROS71</th>\n",
       "      <th>OUTROS72</th>\n",
       "      <th>OUTROS73</th>\n",
       "      <th>OUTROS74</th>\n",
       "      <th>Primary renal disease (Diabetes)</th>\n",
       "      <th>Primary renal disease (Hypertension)</th>\n",
       "      <th>Primary renal disease (CGN (including LES))</th>\n",
       "      <th>Primary renal disease (Unknown)</th>\n",
       "      <th>Primary renal disease (Others)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1349037</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>110.500000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1349040</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.766667</td>\n",
       "      <td>5.933333</td>\n",
       "      <td>129.500000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>120.333333</td>\n",
       "      <td>68.666667</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1349048</td>\n",
       "      <td>11.833333</td>\n",
       "      <td>4.366667</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>154.666667</td>\n",
       "      <td>87.666667</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1349051</td>\n",
       "      <td>10.066667</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>147.333333</td>\n",
       "      <td>92.333333</td>\n",
       "      <td>169.333333</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1349055</td>\n",
       "      <td>11.933333</td>\n",
       "      <td>4.033333</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>103.500000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>154.666667</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>129.333333</td>\n",
       "      <td>72.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>347457070</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>347457071</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>3.233333</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>113.333333</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>347457072</td>\n",
       "      <td>10.466667</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>4.466667</td>\n",
       "      <td>136.666667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>143.333333</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>347457073</td>\n",
       "      <td>11.766667</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>136.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>347457074</td>\n",
       "      <td>9.866667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>126.666667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5707 rows × 1740 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CODPAX  Hemoglobin  Potassium  Phosphate  Mean_PAS_1T  Mean_PAD_1T  \\\n",
       "0       1349037   12.933333   4.433333   5.300000   110.500000    70.000000   \n",
       "1       1349040   14.000000   3.766667   5.933333   129.500000    77.000000   \n",
       "2       1349048   11.833333   4.366667   6.100000   158.000000    81.000000   \n",
       "3       1349051   10.066667   4.733333   5.533333   140.000000    75.000000   \n",
       "4       1349055   11.933333   4.033333   4.066667   103.500000    60.000000   \n",
       "...         ...         ...        ...        ...          ...          ...   \n",
       "5702  347457070    8.400000   5.500000   4.700000   126.666667    76.666667   \n",
       "5703  347457071    9.700000   4.300000   3.233333   130.000000    80.000000   \n",
       "5704  347457072   10.466667   4.433333   4.466667   136.666667    80.000000   \n",
       "5705  347457073   11.766667   4.533333   3.566667   126.666667    80.000000   \n",
       "5706  347457074    9.866667   4.000000   4.100000   126.666667    80.000000   \n",
       "\n",
       "      Mean_PAS_2T  Mean_PAD_2T  Mean_PAS_3T  Mean_PAD_3T  ...  OUTROS70  \\\n",
       "0      125.000000    80.000000     0.000000     0.000000  ...         0   \n",
       "1      120.333333    68.666667   136.000000    82.000000  ...         0   \n",
       "2      154.666667    87.666667   147.000000    80.000000  ...         0   \n",
       "3      147.333333    92.333333   169.333333    99.000000  ...         0   \n",
       "4      154.666667    82.000000   129.333333    72.666667  ...         0   \n",
       "...           ...          ...          ...          ...  ...       ...   \n",
       "5702   126.666667    83.333333   120.000000    80.000000  ...         0   \n",
       "5703   113.333333    73.333333     0.000000     0.000000  ...         0   \n",
       "5704   143.333333    73.333333     0.000000     0.000000  ...         0   \n",
       "5705   136.666667    83.333333     0.000000     0.000000  ...         0   \n",
       "5706   130.000000    76.666667     0.000000     0.000000  ...         0   \n",
       "\n",
       "      OUTROS71  OUTROS72  OUTROS73  OUTROS74  \\\n",
       "0            0         0         0         0   \n",
       "1            0         0         0         0   \n",
       "2            0         0         0         0   \n",
       "3            0         0         0         0   \n",
       "4            0         0         0         0   \n",
       "...        ...       ...       ...       ...   \n",
       "5702         0         0         0         0   \n",
       "5703         0         0         0         0   \n",
       "5704         0         0         0         0   \n",
       "5705         0         0         0         0   \n",
       "5706         0         0         0         0   \n",
       "\n",
       "      Primary renal disease (Diabetes)  Primary renal disease (Hypertension)  \\\n",
       "0                                  1.0                                   0.0   \n",
       "1                                  0.0                                   0.0   \n",
       "2                                  1.0                                   0.0   \n",
       "3                                  1.0                                   0.0   \n",
       "4                                  0.0                                   1.0   \n",
       "...                                ...                                   ...   \n",
       "5702                               0.0                                   1.0   \n",
       "5703                               0.0                                   0.0   \n",
       "5704                               0.0                                   0.0   \n",
       "5705                               0.0                                   0.0   \n",
       "5706                               1.0                                   0.0   \n",
       "\n",
       "      Primary renal disease (CGN (including LES))  \\\n",
       "0                                             0.0   \n",
       "1                                             0.0   \n",
       "2                                             0.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "...                                           ...   \n",
       "5702                                          0.0   \n",
       "5703                                          0.0   \n",
       "5704                                          0.0   \n",
       "5705                                          0.0   \n",
       "5706                                          0.0   \n",
       "\n",
       "      Primary renal disease (Unknown)  Primary renal disease (Others)  \n",
       "0                                 0.0                             0.0  \n",
       "1                                 1.0                             0.0  \n",
       "2                                 0.0                             0.0  \n",
       "3                                 0.0                             0.0  \n",
       "4                                 0.0                             0.0  \n",
       "...                               ...                             ...  \n",
       "5702                              0.0                             0.0  \n",
       "5703                              0.0                             1.0  \n",
       "5704                              0.0                             1.0  \n",
       "5705                              0.0                             1.0  \n",
       "5706                              0.0                             0.0  \n",
       "\n",
       "[5707 rows x 1740 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Primaryrenaldisease']==81,'Primary renal disease (Diabetes)'] = 1\n",
    "\n",
    "df.loc[df['Primaryrenaldisease']==100,'Primary renal disease (Hypertension)'] = 1\n",
    "\n",
    "df.loc[df['Primaryrenaldisease']==13,'Primary renal disease (CGN (including LES))'] = 1\n",
    "df.loc[df['Primaryrenaldisease']==10,'Primary renal disease (CGN (including LES))'] = 1\n",
    "\n",
    "df.loc[df['Primaryrenaldisease']==0,'Primary renal disease (Unknown)'] = 1\n",
    "\n",
    "df.loc[df['Primaryrenaldisease']==20,'Primary renal disease (Others)'] = 1\n",
    "df.loc[df['Primaryrenaldisease']==20,'Primary renal disease (Others)'] = 1\n",
    "df.loc[df['Primaryrenaldisease']==30,'Primary renal disease (Others)'] = 1\n",
    "df.loc[df['Primaryrenaldisease']==40,'Primary renal disease (Others)'] = 1\n",
    "df.loc[df['Primaryrenaldisease']==42,'Primary renal disease (Others)'] = 1\n",
    "df.loc[df['Primaryrenaldisease']==50,'Primary renal disease (Others)'] = 1\n",
    "df.loc[df['Primaryrenaldisease']==70,'Primary renal disease (Others)'] = 1\n",
    "\n",
    "df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection and Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hemoglobin', 'Potassium', 'Phosphate', 'FRR', 'codigoclinica', 'ModalidadeCAPD0APD1Mix2', 'CenterSizenpatients', 'ModalidadeDPInicial', 'Age', 'BMI', 'IncidentinPD', 'PrevalentinPDNet', 'DialysisvintageprePDNet', 'totaldialysisvintage', 'Primary renal disease (Diabetes)', 'Primary renal disease (Hypertension)', 'Primary renal disease (CGN (including LES))', 'Primary renal disease (Unknown)', 'Primary renal disease (Others)', 'PreviousHD', 'Previoustx', 'DaviesScore', 'Peripheralarterydisease', 'DM', 'CAD', 'LVH', 'LES', 'HF', 'Cancer', 'Stroke', 'Hypertension', 'HIV', 'HCV', 'HBC', 'Gender', 'Familyincome', 'Distancefromcenter', 'predialysiscare', 'timeofpredialysiscare', 'Racedicwhite', 'Educationdic4y', 'Region', 'Centerexperiencepatientyear', 'Regionsdic', 'cidade']\n",
      "['Mean_PAS_1T', 'Mean_PAD_1T', 'Mean_PAS_2T', 'Mean_PAD_2T', 'Mean_PAS_3T', 'Mean_PAD_3T', 'Mean_PAS_4T', 'Mean_PAD_4T', 'Mean_PAS_5T', 'Mean_PAD_5T', 'Mean_PAS_6T', 'Mean_PAD_6T', 'Mean_PAS_7T', 'Mean_PAD_7T', 'Mean_PAS_8T', 'Mean_PAD_8T', 'CR_death_event_1y', 'CR_death_event_2y', 'CR_death_event_3y', 'Group_2T', 'Group_3T', 'Ureia1', 'Creatinine1', 'TGP1', 'Potassium1', 'Calcium1', 'Phosphate1', 'Glucose1', 'Hemoglobin1', 'Hematocrit1', 'Ureia2', 'Creatinine2', 'TGP2', 'Potassium2', 'Calcium2', 'Phosphate2', 'Glucose2', 'Hemoglobin2', 'Hematocrit2', 'Ureia3', 'Creatinine3', 'TGP3', 'Potassium3', 'Calcium3', 'Phosphate3', 'Glucose3', 'Hemoglobin3', 'Hematocrit3', 'Ureia4', 'Creatinine4', 'TGP4', 'Potassium4', 'Calcium4', 'Phosphate4', 'Glucose4', 'Hemoglobin4', 'Hematocrit4', 'Ureia5', 'Creatinine5', 'TGP5', 'Potassium5', 'Calcium5', 'Phosphate5', 'Glucose5', 'Hemoglobin5', 'Hematocrit5', 'Ureia6', 'Creatinine6', 'TGP6', 'Potassium6', 'Calcium6', 'Phosphate6', 'Glucose6', 'Hemoglobin6', 'Hematocrit6', 'Ureia7', 'Creatinine7', 'TGP7', 'Potassium7', 'Calcium7', 'Phosphate7', 'Glucose7', 'Hemoglobin7', 'Hematocrit7', 'Ureia8', 'Creatinine8', 'TGP8', 'Potassium8', 'Calcium8', 'Phosphate8', 'Glucose8', 'Hemoglobin8', 'Hematocrit8', 'Ureia9', 'Creatinine9', 'TGP9', 'Potassium9', 'Calcium9', 'Phosphate9', 'Glucose9', 'Hemoglobin9', 'Hematocrit9', 'Ureia10', 'Creatinine10', 'TGP10', 'Potassium10', 'Calcium10', 'Phosphate10', 'Glucose10', 'Hemoglobin10', 'Hematocrit10', 'Ureia11', 'Creatinine11', 'TGP11', 'Potassium11', 'Calcium11', 'Phosphate11', 'Glucose11', 'Hemoglobin11', 'Hematocrit11', 'Ureia12', 'Creatinine12', 'TGP12', 'Potassium12', 'Calcium12', 'Phosphate12', 'Glucose12', 'Hemoglobin12', 'Hematocrit12', 'Ureia13', 'Creatinine13', 'TGP13', 'Potassium13', 'Calcium13', 'Phosphate13', 'Glucose13', 'Hemoglobin13', 'Hematocrit13', 'Ureia14', 'Creatinine14', 'TGP14', 'Potassium14', 'Calcium14', 'Phosphate14', 'Glucose14', 'Hemoglobin14', 'Hematocrit14', 'Ureia15', 'Creatinine15', 'TGP15', 'Potassium15', 'Calcium15', 'Phosphate15', 'Glucose15', 'Hemoglobin15', 'Hematocrit15', 'Ureia16', 'Creatinine16', 'TGP16', 'Potassium16', 'Calcium16', 'Phosphate16', 'Glucose16', 'Hemoglobin16', 'Hematocrit16', 'Ureia17', 'Creatinine17', 'TGP17', 'Potassium17', 'Calcium17', 'Phosphate17', 'Glucose17', 'Hemoglobin17', 'Hematocrit17', 'Ureia18', 'Creatinine18', 'TGP18', 'Potassium18', 'Calcium18', 'Phosphate18', 'Glucose18', 'Hemoglobin18', 'Hematocrit18', 'Ureia19', 'Creatinine19', 'TGP19', 'Potassium19', 'Calcium19', 'Phosphate19', 'Glucose19', 'Hemoglobin19', 'Hematocrit19', 'Ureia20', 'Creatinine20', 'TGP20', 'Potassium20', 'Calcium20', 'Phosphate20', 'Glucose20', 'Hemoglobin20', 'Hematocrit20', 'Ureia21', 'Creatinine21', 'TGP21', 'Potassium21', 'Calcium21', 'Phosphate21', 'Glucose21', 'Hemoglobin21', 'Hematocrit21', 'Ureia22', 'Creatinine22', 'TGP22', 'Potassium22', 'Calcium22', 'Phosphate22', 'Glucose22', 'Hemoglobin22', 'Hematocrit22', 'Ureia23', 'Creatinine23', 'TGP23', 'Potassium23', 'Calcium23', 'Phosphate23', 'Glucose23', 'Hemoglobin23', 'Hematocrit23', 'Ureia24', 'Creatinine24', 'TGP24', 'Potassium24', 'Calcium24', 'Phosphate24', 'Glucose24', 'Hemoglobin24', 'Hematocrit24', 'Ureia25', 'Creatinine25', 'TGP25', 'Potassium25', 'Calcium25', 'Phosphate25', 'Glucose25', 'Hemoglobin25', 'Hematocrit25', 'Ureia26', 'Creatinine26', 'TGP26', 'Potassium26', 'Calcium26', 'Phosphate26', 'Glucose26', 'Hemoglobin26', 'Hematocrit26', 'Ureia27', 'Creatinine27', 'TGP27', 'Potassium27', 'Calcium27', 'Phosphate27', 'Glucose27', 'Hemoglobin27', 'Hematocrit27', 'Ureia28', 'Creatinine28', 'TGP28', 'Potassium28', 'Calcium28', 'Phosphate28', 'Glucose28', 'Hemoglobin28', 'Hematocrit28', 'Ureia29', 'Creatinine29', 'TGP29', 'Potassium29', 'Calcium29', 'Phosphate29', 'Glucose29', 'Hemoglobin29', 'Hematocrit29', 'Ureia30', 'Creatinine30', 'TGP30', 'Potassium30', 'Calcium30', 'Phosphate30', 'Glucose30', 'Hemoglobin30', 'Hematocrit30', 'Ureia31', 'Creatinine31', 'TGP31', 'Potassium31', 'Calcium31', 'Phosphate31', 'Glucose31', 'Hemoglobin31', 'Hematocrit31', 'Ureia32', 'Creatinine32', 'TGP32', 'Potassium32', 'Calcium32', 'Phosphate32', 'Glucose32', 'Hemoglobin32', 'Hematocrit32', 'Ureia33', 'Creatinine33', 'TGP33', 'Potassium33', 'Calcium33', 'Phosphate33', 'Glucose33', 'Hemoglobin33', 'Hematocrit33', 'Ureia34', 'Creatinine34', 'TGP34', 'Potassium34', 'Calcium34', 'Phosphate34', 'Glucose34', 'Hemoglobin34', 'Hematocrit34', 'Ureia35', 'Creatinine35', 'TGP35', 'Potassium35', 'Calcium35', 'Phosphate35', 'Glucose35', 'Hemoglobin35', 'Hematocrit35', 'Ureia36', 'Creatinine36', 'TGP36', 'Potassium36', 'Calcium36', 'Phosphate36', 'Glucose36', 'Hemoglobin36', 'Hematocrit36', 'Ureia37', 'Creatinine37', 'TGP37', 'Potassium37', 'Calcium37', 'Phosphate37', 'Glucose37', 'Hemoglobin37', 'Hematocrit37', 'Ureia38', 'Creatinine38', 'TGP38', 'Potassium38', 'Calcium38', 'Phosphate38', 'Glucose38', 'Hemoglobin38', 'Hematocrit38', 'Ureia39', 'Creatinine39', 'TGP39', 'Potassium39', 'Calcium39', 'Phosphate39', 'Glucose39', 'Hemoglobin39', 'Hematocrit39', 'Ureia40', 'Creatinine40', 'TGP40', 'Potassium40', 'Calcium40', 'Phosphate40', 'Glucose40', 'Hemoglobin40', 'Hematocrit40', 'Ureia41', 'Creatinine41', 'TGP41', 'Potassium41', 'Calcium41', 'Phosphate41', 'Glucose41', 'Hemoglobin41', 'Hematocrit41', 'Ureia42', 'Creatinine42', 'TGP42', 'Potassium42', 'Calcium42', 'Phosphate42', 'Glucose42', 'Hemoglobin42', 'Hematocrit42', 'Ureia43', 'Creatinine43', 'TGP43', 'Potassium43', 'Calcium43', 'Phosphate43', 'Glucose43', 'Hemoglobin43', 'Hematocrit43', 'Ureia44', 'Creatinine44', 'TGP44', 'Potassium44', 'Calcium44', 'Phosphate44', 'Glucose44', 'Hemoglobin44', 'Hematocrit44', 'Ureia45', 'Creatinine45', 'TGP45', 'Potassium45', 'Calcium45', 'Phosphate45', 'Glucose45', 'Hemoglobin45', 'Hematocrit45', 'Ureia46', 'Creatinine46', 'TGP46', 'Potassium46', 'Calcium46', 'Phosphate46', 'Glucose46', 'Hemoglobin46', 'Hematocrit46', 'Ureia47', 'Creatinine47', 'TGP47', 'Potassium47', 'Calcium47', 'Phosphate47', 'Glucose47', 'Hemoglobin47', 'Hematocrit47', 'Ureia48', 'Creatinine48', 'TGP48', 'Potassium48', 'Calcium48', 'Phosphate48', 'Glucose48', 'Hemoglobin48', 'Hematocrit48', 'Ureia49', 'Creatinine49', 'TGP49', 'Potassium49', 'Calcium49', 'Phosphate49', 'Glucose49', 'Hemoglobin49', 'Hematocrit49', 'Ureia50', 'Creatinine50', 'TGP50', 'Potassium50', 'Calcium50', 'Phosphate50', 'Glucose50', 'Hemoglobin50', 'Hematocrit50', 'Ureia51', 'Creatinine51', 'TGP51', 'Potassium51', 'Calcium51', 'Phosphate51', 'Glucose51', 'Hemoglobin51', 'Hematocrit51', 'Ureia52', 'Creatinine52', 'TGP52', 'Potassium52', 'Calcium52', 'Phosphate52', 'Glucose52', 'Hemoglobin52', 'Hematocrit52', 'Ureia53', 'Creatinine53', 'TGP53', 'Potassium53', 'Calcium53', 'Phosphate53', 'Glucose53', 'Hemoglobin53', 'Hematocrit53', 'Ureia54', 'Creatinine54', 'TGP54', 'Potassium54', 'Calcium54', 'Phosphate54', 'Glucose54', 'Hemoglobin54', 'Hematocrit54', 'Ureia55', 'Creatinine55', 'TGP55', 'Potassium55', 'Calcium55', 'Phosphate55', 'Glucose55', 'Hemoglobin55', 'Hematocrit55', 'Ureia56', 'Creatinine56', 'TGP56', 'Potassium56', 'Calcium56', 'Phosphate56', 'Glucose56', 'Hemoglobin56', 'Hematocrit56', 'Ureia57', 'Creatinine57', 'TGP57', 'Potassium57', 'Calcium57', 'Phosphate57', 'Glucose57', 'Hemoglobin57', 'Hematocrit57', 'Ureia58', 'Creatinine58', 'TGP58', 'Potassium58', 'Calcium58', 'Phosphate58', 'Glucose58', 'Hemoglobin58', 'Hematocrit58', 'Ureia59', 'Creatinine59', 'TGP59', 'Potassium59', 'Calcium59', 'Phosphate59', 'Glucose59', 'Hemoglobin59', 'Hematocrit59', 'Ureia60', 'Creatinine60', 'TGP60', 'Potassium60', 'Calcium60', 'Phosphate60', 'Glucose60', 'Hemoglobin60', 'Hematocrit60', 'Ureia61', 'Creatinine61', 'TGP61', 'Potassium61', 'Calcium61', 'Phosphate61', 'Glucose61', 'Hemoglobin61', 'Hematocrit61', 'Ureia62', 'Creatinine62', 'TGP62', 'Potassium62', 'Calcium62', 'Phosphate62', 'Glucose62', 'Hemoglobin62', 'Hematocrit62', 'Ureia63', 'Creatinine63', 'TGP63', 'Potassium63', 'Calcium63', 'Phosphate63', 'Glucose63', 'Hemoglobin63', 'Hematocrit63', 'Ureia64', 'Creatinine64', 'TGP64', 'Potassium64', 'Calcium64', 'Phosphate64', 'Glucose64', 'Hemoglobin64', 'Hematocrit64', 'Ureia65', 'Creatinine65', 'TGP65', 'Potassium65', 'Calcium65', 'Phosphate65', 'Glucose65', 'Hemoglobin65', 'Hematocrit65', 'Ureia66', 'Creatinine66', 'TGP66', 'Potassium66', 'Calcium66', 'Phosphate66', 'Glucose66', 'Hemoglobin66', 'Hematocrit66', 'Ureia67', 'Creatinine67', 'TGP67', 'Potassium67', 'Calcium67', 'Phosphate67', 'Glucose67', 'Hemoglobin67', 'Hematocrit67', 'Ureia68', 'Creatinine68', 'TGP68', 'Potassium68', 'Calcium68', 'Phosphate68', 'Glucose68', 'Hemoglobin68', 'Hematocrit68', 'Ureia69', 'Creatinine69', 'TGP69', 'Potassium69', 'Calcium69', 'Phosphate69', 'Glucose69', 'Hemoglobin69', 'Hematocrit69', 'Ureia70', 'Creatinine70', 'TGP70', 'Potassium70', 'Calcium70', 'Phosphate70', 'Glucose70', 'Hemoglobin70', 'Hematocrit70', 'Ureia71', 'Creatinine71', 'TGP71', 'Potassium71', 'Calcium71', 'Phosphate71', 'Glucose71', 'Hemoglobin71', 'Hematocrit71', 'Volume_Total1', 'Volume_Total2', 'Volume_Total3', 'Volume_Total4', 'Volume_Total5', 'Volume_Total6', 'Volume_Total7', 'Volume_Total8', 'Volume_Total9', 'Volume_Total10', 'Volume_Total11', 'Volume_Total12', 'Volume_Total13', 'Volume_Total14', 'Volume_Total15', 'Volume_Total16', 'Volume_Total17', 'Volume_Total18', 'Volume_Total19', 'Volume_Total20', 'Volume_Total21', 'Volume_Total22', 'Volume_Total23', 'Volume_Total24', 'Volume_Total25', 'Volume_Total26', 'Volume_Total27', 'Volume_Total28', 'Volume_Total29', 'Volume_Total30', 'Volume_Total31', 'Volume_Total32', 'Volume_Total33', 'Volume_Total34', 'Volume_Total35', 'Volume_Total36', 'Volume_Total37', 'Volume_Total38', 'Volume_Total39', 'Volume_Total40', 'Volume_Total41', 'Volume_Total42', 'Volume_Total43', 'Volume_Total44', 'Volume_Total45', 'Volume_Total46', 'Volume_Total47', 'Volume_Total48', 'Volume_Total49', 'Volume_Total50', 'Volume_Total51', 'Volume_Total52', 'Volume_Total53', 'Volume_Total54', 'Volume_Total55', 'Volume_Total56', 'Volume_Total57', 'Volume_Total58', 'Volume_Total59', 'Volume_Total60', 'Volume_Total61', 'Volume_Total62', 'Volume_Total63', 'Volume_Total64', 'Volume_Total65', 'Volume_Total66', 'Volume_Total67', 'Volume_Total68', 'Volume_Total69', 'Volume_Total70', 'Volume_Total71', 'Volume_Total72', 'N_AH_1', 'N_AH_2', 'N_AH_3', 'N_AH_4', 'N_AH_5', 'N_AH_6', 'N_AH_7', 'N_AH_8', 'N_AH_9', 'N_AH_10', 'N_AH_11', 'N_AH_12', 'N_AH_13', 'N_AH_14', 'N_AH_15', 'N_AH_16', 'N_AH_17', 'N_AH_18', 'N_AH_19', 'N_AH_20', 'N_AH_21', 'N_AH_22', 'N_AH_23', 'N_AH_24', 'N_AH_25', 'N_AH_26', 'N_AH_27', 'N_AH_28', 'N_AH_29', 'N_AH_30', 'N_AH_31', 'N_AH_32', 'N_AH_33', 'N_AH_34', 'N_AH_35', 'N_AH_36', 'N_AH_37', 'N_AH_38', 'N_AH_39', 'N_AH_40', 'N_AH_41', 'N_AH_42', 'N_AH_43', 'N_AH_44', 'N_AH_45', 'N_AH_46', 'N_AH_47', 'N_AH_48', 'N_AH_49', 'N_AH_50', 'N_AH_51', 'N_AH_52', 'N_AH_53', 'N_AH_54', 'N_AH_55', 'N_AH_56', 'N_AH_57', 'N_AH_58', 'N_AH_59', 'N_AH_60', 'N_AH_61', 'N_AH_62', 'N_AH_63', 'N_AH_64', 'N_AH_65', 'N_AH_66', 'N_AH_67', 'N_AH_68', 'N_AH_69', 'N_AH_70', 'N_AH_71', 'N_AH_72', 'N_AH_73', 'N_AH_74', 'Phosphate_pre1', 'Phosphate_pre2', 'Phosphate_pre3', 'Phosphate_pre4', 'Phosphate_pre5', 'Phosphate_pre6', 'Potassium_pre1', 'Potassium_pre2', 'Potassium_pre3', 'Potassium_pre4', 'Potassium_pre5', 'Potassium_pre6', 'Ms10ou1', 'Systolic1', 'Diastolic1', 'Systolic2', 'Diastolic2', 'Systolic3', 'Diastolic3', 'Systolic4', 'Diastolic4', 'Systolic5', 'Diastolic5', 'Systolic6', 'Diastolic6', 'Systolic7', 'Diastolic7', 'Systolic8', 'Diastolic8', 'Systolic9', 'Diastolic9', 'Systolic10', 'Diastolic10', 'Systolic11', 'Diastolic11', 'Systolic12', 'Diastolic12', 'Systolic13', 'Diastolic13', 'Systolic14', 'Diastolic14', 'Systolic15', 'Diastolic15', 'Systolic16', 'Diastolic16', 'Systolic17', 'Diastolic17', 'Systolic18', 'Diastolic18', 'Systolic19', 'Diastolic19', 'Systolic20', 'Diastolic20', 'Systolic21', 'Diastolic21', 'Systolic22', 'Diastolic22', 'Systolic23', 'Diastolic23', 'Systolic24', 'Diastolic24', 'Systolic25', 'Diastolic25', 'Systolic26', 'Diastolic26', 'Systolic27', 'Diastolic27', 'Systolic28', 'Diastolic28', 'Systolic29', 'Diastolic29', 'Systolic30', 'Diastolic30', 'Systolic31', 'Diastolic31', 'Systolic32', 'Diastolic32', 'Systolic33', 'Diastolic33', 'Systolic34', 'Diastolic34', 'Systolic35', 'Diastolic35', 'Systolic36', 'Diastolic36', 'Systolic37', 'Diastolic37', 'Systolic38', 'Diastolic38', 'Systolic39', 'Diastolic39', 'Systolic40', 'Diastolic40', 'Systolic41', 'Diastolic41', 'Systolic42', 'Diastolic42', 'Systolic43', 'Diastolic43', 'Systolic44', 'Diastolic44', 'Systolic45', 'Diastolic45', 'Systolic46', 'Diastolic46', 'Systolic47', 'Diastolic47', 'Systolic48', 'Diastolic48', 'Systolic49', 'Diastolic49', 'Systolic50', 'Diastolic50', 'Systolic51', 'Diastolic51', 'Systolic52', 'Diastolic52', 'Systolic53', 'Diastolic53', 'Systolic54', 'Diastolic54', 'Systolic55', 'Diastolic55', 'Systolic56', 'Diastolic56', 'Systolic57', 'Diastolic57', 'Systolic58', 'Diastolic58', 'Systolic59', 'Diastolic59', 'Systolic60', 'Diastolic60', 'Systolic61', 'Diastolic61', 'Systolic62', 'Diastolic62', 'Systolic63', 'Diastolic63', 'Systolic64', 'Diastolic64', 'Systolic65', 'Diastolic65', 'Systolic66', 'Diastolic66', 'Systolic67', 'Diastolic67', 'Systolic68', 'Diastolic68', 'Systolic69', 'Diastolic69', 'Systolic70', 'Diastolic70', 'Systolic71', 'Diastolic71', 'Systolic72', 'Diastolic72', 'Systolic73', 'Diastolic73', 'Systolic74', 'Diastolic74', 'PAS1', 'PAS2', 'PAS3', 'PAS4', 'PAS5', 'PAS6', 'PAS7', 'PAS8', 'PAS9', 'PAS10', 'PAS11', 'PAS12', 'PAS13', 'PAS14', 'PAS15', 'PAS16', 'PAS17', 'PAS18', 'PAS19', 'PAS20', 'PAS21', 'PAS22', 'PAS23', 'PAS24', 'PAS25', 'PAS26', 'PAS27', 'PAS28', 'PAS29', 'PAS30', 'PAS31', 'PAS32', 'PAS33', 'PAS34', 'PAS35', 'PAS36', 'PAS37', 'PAS38', 'PAS39', 'PAS40', 'PAS41', 'PAS42', 'PAS43', 'PAS44', 'PAS45', 'PAS46', 'PAS47', 'PAS48', 'PAS49', 'PAS50', 'PAS51', 'PAS52', 'PAS53', 'PAS54', 'PAS55', 'PAS56', 'PAS57', 'PAS58', 'PAS59', 'PAS60', 'PAS61', 'PAS62', 'PAS63', 'PAS64', 'PAS65', 'PAS66', 'PAS67', 'PAS68', 'PAS69', 'PAS70', 'PAS71', 'PAS72', 'PAS73', 'PAS74', 'PAD1', 'PAD2', 'PAD3', 'PAD4', 'PAD5', 'PAD6', 'PAD7', 'PAD8', 'PAD9', 'PAD10', 'PAD11', 'PAD12', 'PAD13', 'PAD14', 'PAD15', 'PAD16', 'PAD17', 'PAD18', 'PAD19', 'PAD20', 'PAD21', 'PAD22', 'PAD23', 'PAD24', 'PAD25', 'PAD26', 'PAD27', 'PAD28', 'PAD29', 'PAD30', 'PAD31', 'PAD32', 'PAD33', 'PAD34', 'PAD35', 'PAD36', 'PAD37', 'PAD38', 'PAD39', 'PAD40', 'PAD41', 'PAD42', 'PAD43', 'PAD44', 'PAD45', 'PAD46', 'PAD47', 'PAD48', 'PAD49', 'PAD50', 'PAD51', 'PAD52', 'PAD53', 'PAD54', 'PAD55', 'PAD56', 'PAD57', 'PAD58', 'PAD59', 'PAD60', 'PAD61', 'PAD62', 'PAD63', 'PAD64', 'PAD65', 'PAD66', 'PAD67', 'PAD68', 'PAD69', 'PAD70', 'PAD71', 'PAD72', 'PAD73', 'PAD74', 'Use antihypertensive drug1', 'Use antihypertensive drug2', 'Use antihypertensive drug3', 'Use antihypertensive drug4', 'Use antihypertensive drug5', 'Use antihypertensive drug6', 'Use antihypertensive drug7', 'Use antihypertensive drug8', 'Use antihypertensive drug9', 'Use antihypertensive drug10', 'Use antihypertensive drug11', 'Use antihypertensive drug12', 'Use antihypertensive drug13', 'Use antihypertensive drug14', 'Use antihypertensive drug15', 'Use antihypertensive drug16', 'Use antihypertensive drug17', 'Use antihypertensive drug18', 'Use antihypertensive drug19', 'Use antihypertensive drug20', 'Use antihypertensive drug21', 'Use antihypertensive drug22', 'Use antihypertensive drug23', 'Use antihypertensive drug24', 'Use antihypertensive drug25', 'Use antihypertensive drug26', 'Use antihypertensive drug27', 'Use antihypertensive drug28', 'Use antihypertensive drug29', 'Use antihypertensive drug30', 'Use antihypertensive drug31', 'Use antihypertensive drug32', 'Use antihypertensive drug33', 'Use antihypertensive drug34', 'Use antihypertensive drug35', 'Use antihypertensive drug36', 'Use antihypertensive drug37', 'Use antihypertensive drug38', 'Use antihypertensive drug39', 'Use antihypertensive drug40', 'Use antihypertensive drug41', 'Use antihypertensive drug42', 'Use antihypertensive drug43', 'Use antihypertensive drug44', 'Use antihypertensive drug45', 'Use antihypertensive drug46', 'Use antihypertensive drug47', 'Use antihypertensive drug48', 'Use antihypertensive drug49', 'Use antihypertensive drug50', 'Use antihypertensive drug51', 'Use antihypertensive drug52', 'Use antihypertensive drug53', 'Use antihypertensive drug54', 'Use antihypertensive drug55', 'Use antihypertensive drug56', 'Use antihypertensive drug57', 'Use antihypertensive drug58', 'Use antihypertensive drug59', 'Use antihypertensive drug60', 'Use antihypertensive drug61', 'Use antihypertensive drug62', 'Use antihypertensive drug63', 'Use antihypertensive drug64', 'Use antihypertensive drug65', 'Use antihypertensive drug66', 'Use antihypertensive drug67', 'Use antihypertensive drug68', 'Use antihypertensive drug69', 'Use antihypertensive drug70', 'Use antihypertensive drug71', 'Use antihypertensive drug72', 'Use antihypertensive drug73', 'Use antihypertensive drug74', 'ACE-inhibitor1', 'ACE-inhibitor2', 'ACE-inhibitor3', 'ACE-inhibitor4', 'ACE-inhibitor5', 'ACE-inhibitor6', 'ACE-inhibitor7', 'ACE-inhibitor8', 'ACE-inhibitor9', 'ACE-inhibitor10', 'ACE-inhibitor11', 'ACE-inhibitor12', 'ACE-inhibitor13', 'ACE-inhibitor14', 'ACE-inhibitor15', 'ACE-inhibitor16', 'ACE-inhibitor17', 'ACE-inhibitor18', 'ACE-inhibitor19', 'ACE-inhibitor20', 'ACE-inhibitor21', 'ACE-inhibitor22', 'ACE-inhibitor23', 'ACE-inhibitor24', 'ACE-inhibitor25', 'ACE-inhibitor26', 'ACE-inhibitor27', 'ACE-inhibitor28', 'ACE-inhibitor29', 'ACE-inhibitor30', 'ACE-inhibitor31', 'ACE-inhibitor32', 'ACE-inhibitor33', 'ACE-inhibitor34', 'ACE-inhibitor35', 'ACE-inhibitor36', 'ACE-inhibitor37', 'ACE-inhibitor38', 'ACE-inhibitor39', 'ACE-inhibitor40', 'ACE-inhibitor41', 'ACE-inhibitor42', 'ACE-inhibitor43', 'ACE-inhibitor44', 'ACE-inhibitor45', 'ACE-inhibitor46', 'ACE-inhibitor47', 'ACE-inhibitor48', 'ACE-inhibitor49', 'ACE-inhibitor50', 'ACE-inhibitor51', 'ACE-inhibitor52', 'ACE-inhibitor53', 'ACE-inhibitor54', 'ACE-inhibitor55', 'ACE-inhibitor56', 'ACE-inhibitor57', 'ACE-inhibitor58', 'ACE-inhibitor59', 'ACE-inhibitor60', 'ACE-inhibitor61', 'ACE-inhibitor62', 'ACE-inhibitor63', 'ACE-inhibitor64', 'ACE-inhibitor65', 'ACE-inhibitor66', 'ACE-inhibitor67', 'ACE-inhibitor68', 'ACE-inhibitor69', 'ACE-inhibitor70', 'ACE-inhibitor71', 'ACE-inhibitor72', 'ACE-inhibitor73', 'ACE-inhibitor74', 'beta-blocker1', 'beta-blocker2', 'beta-blocker3', 'beta-blocker4', 'beta-blocker5', 'beta-blocker6', 'beta-blocker7', 'beta-blocker8', 'beta-blocker9', 'beta-blocker10', 'beta-blocker11', 'beta-blocker12', 'beta-blocker13', 'beta-blocker14', 'beta-blocker15', 'beta-blocker16', 'beta-blocker17', 'beta-blocker18', 'beta-blocker19', 'beta-blocker20', 'beta-blocker21', 'beta-blocker22', 'beta-blocker23', 'beta-blocker24', 'beta-blocker25', 'beta-blocker26', 'beta-blocker27', 'beta-blocker28', 'beta-blocker29', 'beta-blocker30', 'beta-blocker31', 'beta-blocker32', 'beta-blocker33', 'beta-blocker34', 'beta-blocker35', 'beta-blocker36', 'beta-blocker37', 'beta-blocker38', 'beta-blocker39', 'beta-blocker40', 'beta-blocker41', 'beta-blocker42', 'beta-blocker43', 'beta-blocker44', 'beta-blocker45', 'beta-blocker46', 'beta-blocker47', 'beta-blocker48', 'beta-blocker49', 'beta-blocker50', 'beta-blocker51', 'beta-blocker52', 'beta-blocker53', 'beta-blocker54', 'beta-blocker55', 'beta-blocker56', 'beta-blocker57', 'beta-blocker58', 'beta-blocker59', 'beta-blocker60', 'beta-blocker61', 'beta-blocker62', 'beta-blocker63', 'beta-blocker64', 'beta-blocker65', 'beta-blocker66', 'beta-blocker67', 'beta-blocker68', 'beta-blocker69', 'beta-blocker70', 'beta-blocker71', 'beta-blocker72', 'beta-blocker73', 'beta-blocker74', 'calcium antagonist1', 'calcium antagonist2', 'calcium antagonist3', 'calcium antagonist4', 'calcium antagonist5', 'calcium antagonist6', 'calcium antagonist7', 'calcium antagonist8', 'calcium antagonist9', 'calcium antagonist10', 'calcium antagonist11', 'calcium antagonist12', 'calcium antagonist13', 'calcium antagonist14', 'calcium antagonist15', 'calcium antagonist16', 'calcium antagonist17', 'calcium antagonist18', 'calcium antagonist19', 'calcium antagonist20', 'calcium antagonist21', 'calcium antagonist22', 'calcium antagonist23', 'calcium antagonist24', 'calcium antagonist25', 'calcium antagonist26', 'calcium antagonist27', 'calcium antagonist28', 'calcium antagonist29', 'calcium antagonist30', 'calcium antagonist31', 'calcium antagonist32', 'calcium antagonist33', 'calcium antagonist34', 'calcium antagonist35', 'calcium antagonist36', 'calcium antagonist37', 'calcium antagonist38', 'calcium antagonist39', 'calcium antagonist40', 'calcium antagonist41', 'calcium antagonist42', 'calcium antagonist43', 'calcium antagonist44', 'calcium antagonist45', 'calcium antagonist46', 'calcium antagonist47', 'calcium antagonist48', 'calcium antagonist49', 'calcium antagonist50', 'calcium antagonist51', 'calcium antagonist52', 'calcium antagonist53', 'calcium antagonist54', 'calcium antagonist55', 'calcium antagonist56', 'calcium antagonist57', 'calcium antagonist58', 'calcium antagonist59', 'calcium antagonist60', 'calcium antagonist61', 'calcium antagonist62', 'calcium antagonist63', 'calcium antagonist64', 'calcium antagonist65', 'calcium antagonist66', 'calcium antagonist67', 'calcium antagonist68', 'calcium antagonist69', 'calcium antagonist70', 'calcium antagonist71', 'calcium antagonist72', 'calcium antagonist73', 'calcium antagonist74', 'diuretic1', 'diuretic2', 'diuretic3', 'diuretic4', 'diuretic5', 'diuretic6', 'diuretic7', 'diuretic8', 'diuretic9', 'diuretic10', 'diuretic11', 'diuretic12', 'diuretic13', 'diuretic14', 'diuretic15', 'diuretic16', 'diuretic17', 'diuretic18', 'diuretic19', 'diuretic20', 'diuretic21', 'diuretic22', 'diuretic23', 'diuretic24', 'diuretic25', 'diuretic26', 'diuretic27', 'diuretic28', 'diuretic29', 'diuretic30', 'diuretic31', 'diuretic32', 'diuretic33', 'diuretic34', 'diuretic35', 'diuretic36', 'diuretic37', 'diuretic38', 'diuretic39', 'diuretic40', 'diuretic41', 'diuretic42', 'diuretic43', 'diuretic44', 'diuretic45', 'diuretic46', 'diuretic47', 'diuretic48', 'diuretic49', 'diuretic50', 'diuretic51', 'diuretic52', 'diuretic53', 'diuretic54', 'diuretic55', 'diuretic56', 'diuretic57', 'diuretic58', 'diuretic59', 'diuretic60', 'diuretic61', 'diuretic62', 'diuretic63', 'diuretic64', 'diuretic65', 'diuretic66', 'diuretic67', 'diuretic68', 'diuretic69', 'diuretic70', 'diuretic71', 'diuretic72', 'diuretic73', 'diuretic74', 'ATI blocker1', 'ATI blocker2', 'ATI blocker3', 'ATI blocker4', 'ATI blocker5', 'ATI blocker6', 'ATI blocker7', 'ATI blocker8', 'ATI blocker9', 'ATI blocker10', 'ATI blocker11', 'ATI blocker12', 'ATI blocker13', 'ATI blocker14', 'ATI blocker15', 'ATI blocker16', 'ATI blocker17', 'ATI blocker18', 'ATI blocker19', 'ATI blocker20', 'ATI blocker21', 'ATI blocker22', 'ATI blocker23', 'ATI blocker24', 'ATI blocker25', 'ATI blocker26', 'ATI blocker27', 'ATI blocker28', 'ATI blocker29', 'ATI blocker30', 'ATI blocker31', 'ATI blocker32', 'ATI blocker33', 'ATI blocker34', 'ATI blocker35', 'ATI blocker36', 'ATI blocker37', 'ATI blocker38', 'ATI blocker39', 'ATI blocker40', 'ATI blocker41', 'ATI blocker42', 'ATI blocker43', 'ATI blocker44', 'ATI blocker45', 'ATI blocker46', 'ATI blocker47', 'ATI blocker48', 'ATI blocker49', 'ATI blocker50', 'ATI blocker51', 'ATI blocker52', 'ATI blocker53', 'ATI blocker54', 'ATI blocker55', 'ATI blocker56', 'ATI blocker57', 'ATI blocker58', 'ATI blocker59', 'ATI blocker60', 'ATI blocker61', 'ATI blocker62', 'ATI blocker63', 'ATI blocker64', 'ATI blocker65', 'ATI blocker66', 'ATI blocker67', 'ATI blocker68', 'ATI blocker69', 'ATI blocker70', 'ATI blocker71', 'ATI blocker72', 'ATI blocker73', 'ATI blocker74', 'OUTROS1', 'OUTROS2', 'OUTROS3', 'OUTROS4', 'OUTROS5', 'OUTROS6', 'OUTROS7', 'OUTROS8', 'OUTROS9', 'OUTROS10', 'OUTROS11', 'OUTROS12', 'OUTROS13', 'OUTROS14', 'OUTROS15', 'OUTROS16', 'OUTROS17', 'OUTROS18', 'OUTROS19', 'OUTROS20', 'OUTROS21', 'OUTROS22', 'OUTROS23', 'OUTROS24', 'OUTROS25', 'OUTROS26', 'OUTROS27', 'OUTROS28', 'OUTROS29', 'OUTROS30', 'OUTROS31', 'OUTROS32', 'OUTROS33', 'OUTROS34', 'OUTROS35', 'OUTROS36', 'OUTROS37', 'OUTROS38', 'OUTROS39', 'OUTROS40', 'OUTROS41', 'OUTROS42', 'OUTROS43', 'OUTROS44', 'OUTROS45', 'OUTROS46', 'OUTROS47', 'OUTROS48', 'OUTROS49', 'OUTROS50', 'OUTROS51', 'OUTROS52', 'OUTROS53', 'OUTROS54', 'OUTROS55', 'OUTROS56', 'OUTROS57', 'OUTROS58', 'OUTROS59', 'OUTROS60', 'OUTROS61', 'OUTROS62', 'OUTROS63', 'OUTROS64', 'OUTROS65', 'OUTROS66', 'OUTROS67', 'OUTROS68', 'OUTROS69', 'OUTROS70', 'OUTROS71', 'OUTROS72', 'OUTROS73', 'OUTROS74', 'Primary renal disease (Diabetes)', 'Primary renal disease (Hypertension)', 'Primary renal disease (CGN (including LES))', 'Primary renal disease (Unknown)', 'Primary renal disease (Others)']\n"
     ]
    }
   ],
   "source": [
    "# Separate features to unique features and time series features\n",
    "timeseries_cols = []\n",
    "time_indices = str(np.arange(100))\n",
    "# print(time_indices)\n",
    "for col in list(df.columns):\n",
    "    add = True\n",
    "    for idx in time_indices:\n",
    "        if idx in col:\n",
    "            add = False\n",
    "    if add == False:\n",
    "        timeseries_cols.append(col)\n",
    "        \n",
    "# Adjust missclassified features\n",
    "adjlist = ['ModalidadeCAPD0APD1Mix2', 'Dropoutsim1', 'Agedic65', 'Educationdic4y', \n",
    "           'Followup1y', 'Followup2y', 'Followup3y', \"death_event_1y\",\"Tech_event_1y\",\n",
    "          \"death_event_2y\",\"Tech_event_2y\", \"death_event_3y\",\"Tech_event_3y\"]\n",
    "for i in range(len(adjlist)):\n",
    "    timeseries_cols.remove(adjlist[i])\n",
    "    \n",
    "unique_cols = ['Hemoglobin', 'Potassium', 'Phosphate',\\\n",
    "                 'FRR', 'codigoclinica', 'ModalidadeCAPD0APD1Mix2',\\\n",
    "                'CenterSizenpatients', 'ModalidadeDPInicial', 'Age',\\\n",
    "                'BMI','IncidentinPD', 'PrevalentinPDNet', \\\n",
    "                'DialysisvintageprePDNet', 'totaldialysisvintage',\\\n",
    "                'Primary renal disease (Diabetes)','Primary renal disease (Hypertension)',\\\n",
    "                'Primary renal disease (CGN (including LES))', 'Primary renal disease (Unknown)',\\\n",
    "                'Primary renal disease (Others)', 'PreviousHD',\\\n",
    "                'Previoustx', 'DaviesScore', 'Peripheralarterydisease',\\\n",
    "                'DM', 'CAD', 'LVH', 'LES', 'HF', 'Cancer', 'Stroke',\\\n",
    "                'Hypertension', 'HIV', 'HCV', 'HBC', 'Gender',\\\n",
    "                'Familyincome', 'Distancefromcenter', 'predialysiscare',\\\n",
    "                'timeofpredialysiscare', 'Racedicwhite', 'Educationdic4y',\\\n",
    "                'Region', 'Centerexperiencepatientyear',\\\n",
    "                'Regionsdic', 'cidade']\n",
    "\n",
    "print(unique_cols)\n",
    "print(timeseries_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build baseline dataframe (without time-series data):\n",
    "df_baseline = df[unique_cols].copy()\n",
    "df_baseline = df_baseline.fillna(0)\n",
    "# display(df_baseline)\n",
    "\n",
    "targets = ['Dropoutsim1', 'Followup1y', 'Followup2y', 'Followup3y',\\\n",
    "           \"death_event_1y\",\"Tech_event_1y\",\\\n",
    "           \"death_event_2y\",\"Tech_event_2y\",\\\n",
    "           \"death_event_3y\",\"Tech_event_3y\",\\\n",
    "           \"Deathevent\",\"TechniqueFailureevent\",\"Causeofdeath\",\"TechFailureDeathnotcens\",\"Causeofdropout\",\\\n",
    "           \"Followup\"]\n",
    "\n",
    "# build targets dataframe:\n",
    "Y = df[targets+['CODPAX']].copy()\n",
    "# display(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hemoglobin</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Phosphate</th>\n",
       "      <th>FRR</th>\n",
       "      <th>Clinic code</th>\n",
       "      <th>CAPD0APD1Mix2 modality</th>\n",
       "      <th>Center size (patients)</th>\n",
       "      <th>Initial modality of PD</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>...</th>\n",
       "      <th>diuretic p4</th>\n",
       "      <th>diuretic p5</th>\n",
       "      <th>diuretic p6</th>\n",
       "      <th>diuretic p7</th>\n",
       "      <th>diuretic p8</th>\n",
       "      <th>diuretic p9</th>\n",
       "      <th>diuretic p10</th>\n",
       "      <th>diuretic p11</th>\n",
       "      <th>diuretic p12</th>\n",
       "      <th>diuretic p13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.933333</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2</td>\n",
       "      <td>20.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.766667</td>\n",
       "      <td>5.933333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>28.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.833333</td>\n",
       "      <td>4.366667</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.2</td>\n",
       "      <td>31.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.066667</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.3</td>\n",
       "      <td>27.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.933333</td>\n",
       "      <td>4.033333</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>8.400000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>9.700000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>3.233333</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>10.466667</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>4.466667</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>11.766667</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>9.866667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5707 rows × 298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hemoglobin  Potassium  Phosphate  FRR  Clinic code  \\\n",
       "0      12.933333   4.433333   5.300000    0            1   \n",
       "1      14.000000   3.766667   5.933333    0            1   \n",
       "2      11.833333   4.366667   6.100000    1            1   \n",
       "3      10.066667   4.733333   5.533333    1            1   \n",
       "4      11.933333   4.033333   4.066667    0            1   \n",
       "...          ...        ...        ...  ...          ...   \n",
       "5702    8.400000   5.500000   4.700000    1          347   \n",
       "5703    9.700000   4.300000   3.233333    1          347   \n",
       "5704   10.466667   4.433333   4.466667    1          347   \n",
       "5705   11.766667   4.533333   3.566667    1          347   \n",
       "5706    9.866667   4.000000   4.100000    1          347   \n",
       "\n",
       "      CAPD0APD1Mix2 modality  Center size (patients)  Initial modality of PD  \\\n",
       "0                          0                     128                     0.0   \n",
       "1                          0                     128                     0.0   \n",
       "2                          1                     128                     1.0   \n",
       "3                          0                     128                     0.0   \n",
       "4                          2                     128                     0.0   \n",
       "...                      ...                     ...                     ...   \n",
       "5702                       1                      66                     1.0   \n",
       "5703                       1                      66                     1.0   \n",
       "5704                       1                      66                     1.0   \n",
       "5705                       1                      66                     1.0   \n",
       "5706                       1                      66                     1.0   \n",
       "\n",
       "       Age   BMI  ...  diuretic p4  diuretic p5  diuretic p6  diuretic p7  \\\n",
       "0     71.2  20.7  ...          0.0          0.0          0.0          0.0   \n",
       "1     23.3  28.3  ...          0.0          0.0          0.0          0.0   \n",
       "2     49.2  31.5  ...          0.0          0.0          0.0          0.0   \n",
       "3     48.3  27.1  ...          0.0          0.0          0.0          0.0   \n",
       "4     93.7  23.1  ...          0.0          0.0          0.0          0.0   \n",
       "...    ...   ...  ...          ...          ...          ...          ...   \n",
       "5702  31.8  22.0  ...          0.0          0.0          0.0          0.0   \n",
       "5703  57.0  21.5  ...          0.0          0.0          0.0          0.0   \n",
       "5704  84.0  23.5  ...          0.0          0.0          0.0          0.0   \n",
       "5705  54.2  35.0  ...          0.0          0.0          0.0          0.0   \n",
       "5706  77.8  20.6  ...          0.0          0.0          0.0          0.0   \n",
       "\n",
       "      diuretic p8  diuretic p9  diuretic p10  diuretic p11  diuretic p12  \\\n",
       "0             0.0          0.0           0.0           0.0           0.0   \n",
       "1             0.0          0.0           0.0           0.0           0.0   \n",
       "2             0.0          0.0           0.0           0.0           0.0   \n",
       "3             0.0          0.0           0.0           0.0           0.0   \n",
       "4             0.0          0.0           0.0           0.0           0.0   \n",
       "...           ...          ...           ...           ...           ...   \n",
       "5702          0.0          0.0           0.0           0.0           0.0   \n",
       "5703          0.0          0.0           0.0           0.0           0.0   \n",
       "5704          0.0          0.0           0.0           0.0           0.0   \n",
       "5705          0.0          0.0           0.0           0.0           0.0   \n",
       "5706          0.0          0.0           0.0           0.0           0.0   \n",
       "\n",
       "      diuretic p13  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "...            ...  \n",
       "5702           0.0  \n",
       "5703           0.0  \n",
       "5704           0.0  \n",
       "5705           0.0  \n",
       "5706           0.0  \n",
       "\n",
       "[5707 rows x 298 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_totalaverage = df[unique_cols].copy()\n",
    "\n",
    "# rename column name to understandable English\n",
    "df_totalaverage = df_totalaverage.rename(columns={\"codigoclinica\": \"Clinic code\",\\\n",
    "                                                  \"ModalidadeCAPD0APD1Mix2\": \"CAPD0APD1Mix2 modality\",\\\n",
    "                                                  \"CenterSizenpatients\": \"Center size (patients)\",\\\n",
    "                                                  \"ModalidadeDPInicial\": \"Initial modality of PD\",\\\n",
    "                                                  \"IncidentinPD\": \"Incident in PD\",\\\n",
    "                                                  \"PrevalentinPDNet\": \"Prevalent in PD Net\",\\\n",
    "                                                  \"DialysisvintageprePDNet\": \"Dialysis vintage pre PD Net\",\\\n",
    "                                                  \"totaldialysisvintage\": \"Total dialysis vintage\",\\\n",
    "                                                  \"PreviousHD\": \"Previous HD\",\\\n",
    "                                                  \"Previoustx\": \"Previous tx\",\\\n",
    "                                                  \"DaviesScore\": \"Davies Score\",\\\n",
    "                                                  \"Peripheralarterydisease\": \"Peripheral artery disease\",\\\n",
    "                                                  \"Familyincome\": \"Family income\",\\\n",
    "                                                  \"Distancefromcenter\": \"Distance from center\",\\\n",
    "                                                  \"predialysiscare\": \"Predialysis care\",\\\n",
    "                                                  \"timeofpredialysiscare\": \"Time of predialysis care\",\\\n",
    "                                                  \"Racedicwhite\": \"Race is white\",\\\n",
    "                                                  \"Educationdic4y\": \"Education more than 4 years\",\\\n",
    "                                                  \"Centerexperiencepatientyear\": \"Center experience (patient-year)\",\\\n",
    "                                                  \"cidade\": \"City\"})\n",
    "\n",
    "Group_p1 = []\n",
    "Ms10ou_p1 = []\n",
    "\n",
    "storage_p1 = [Group_p1, Ms10ou_p1]\n",
    "\n",
    "Mean_PAS_p1 = []\n",
    "Mean_PAD_p1 = []\n",
    "\n",
    "Mean_PAS_p2 = []\n",
    "Mean_PAD_p2 = []\n",
    "\n",
    "storage_p2 = [Mean_PAS_p1, Mean_PAD_p1, Mean_PAS_p2, Mean_PAD_p2]\n",
    "\n",
    "Ureia = dict()\n",
    "Creatinine = dict()\n",
    "TGP = dict()\n",
    "Potassium = dict()\n",
    "Calcium = dict()\n",
    "Phosphate = dict()\n",
    "Glucose = dict()\n",
    "Hemoglobin = dict()\n",
    "Hematocrit = dict()\n",
    "Volume_Total = dict()\n",
    "N_AH_ = dict()\n",
    "Systolic = dict()\n",
    "Diastolic = dict()\n",
    "PAS = dict()\n",
    "PAD = dict()\n",
    "Uso_de_anti_hipert = dict()\n",
    "inibidor = dict()\n",
    "at_i = dict()\n",
    "beta = dict()\n",
    "ant = dict()\n",
    "diu = dict()\n",
    "\n",
    "# label_dict = [Ureia, Creatinine, TGP, Potassium, Calcium, Phosphate, Glucose, \n",
    "#               Hemoglobin, Hematocrit, Volume_Total, N_AH_, Systolic, Diastolic, PAS, PAD, Uso_de_anti_hipert, inibidor]\n",
    "\n",
    "# label_str = ['Ureia', 'Creatinine', 'TGP', 'Potassium', 'Calcium', 'Phosphate', 'Glucose', \n",
    "#               'Hemoglobin', 'Hematocrit','Volume_Total', 'N_AH_', 'Systolic', 'Diastolic','PAS','PAD',\n",
    "#              'Uso_de_anti_hipert', 'inibidor']\n",
    "\n",
    "# remove Volume_Total and N_AH_\n",
    "\n",
    "label_dict = [Ureia, Creatinine, TGP, Potassium, Calcium, Phosphate, Glucose, \n",
    "              Hemoglobin, Hematocrit, Systolic, Diastolic, PAS, PAD, Uso_de_anti_hipert, \n",
    "              inibidor, at_i, beta, ant, diu]\n",
    "\n",
    "# label_str = ['Ureia', 'Creatinine', 'TGP', 'Potassium', 'Calcium', 'Phosphate',\\\n",
    "#              'Glucose', 'Hemoglobin', 'Hematocrit', 'Systolic', 'Diastolic','PAS','PAD',\\\n",
    "#              'Uso_de_anti_hipert', 'inibidor', 'at_i', 'beta', 'ant', 'diu']\n",
    "\n",
    "label_str = ['Ureia', 'Creatinine', 'TGP', 'Potassium', 'Calcium', 'Phosphate',\\\n",
    "             'Glucose', 'Hemoglobin', 'Hematocrit', 'Systolic', 'Diastolic','PAS','PAD',\\\n",
    "             'Use antihypertensive drug', 'ACE-inhibitor', 'ATI blocker', 'beta-blocker',\\\n",
    "             'calcium antagonist', 'diuretic']\n",
    "\n",
    "for item in label_dict:\n",
    "    for i in range(13):\n",
    "        key = 'p'+str(i+1)\n",
    "        item[key] = []\n",
    "    \n",
    "label_idx = 0    \n",
    "for item in label_dict:\n",
    "    count = 0\n",
    "    section = 1\n",
    "    labelname = label_str[label_idx]\n",
    "    for col in timeseries_cols:\n",
    "        if labelname in col:\n",
    "            if 'Mean_' not in col:            \n",
    "                if count < 6:\n",
    "                    count = count + 1\n",
    "                else:\n",
    "                    section = section + 1\n",
    "                    count = 1\n",
    "                key = 'p'+str(section)\n",
    "                try:\n",
    "                    item[key].append(col)\n",
    "                except:\n",
    "                    pass\n",
    "                    \n",
    "                    \n",
    "    label_idx = label_idx + 1\n",
    "\n",
    "indices_p1 = ['Group', 'Ms10ou']\n",
    "\n",
    "indices_p2 = ['Mean_PAS', 'Mean_PAD']\n",
    "\n",
    "\n",
    "\n",
    "# Select certain features as 1 section\n",
    "for col in timeseries_cols:\n",
    "    i = 0\n",
    "    for idx in indices_p1:\n",
    "        if idx in col:\n",
    "            storage_p1[i].append(col)\n",
    "        i = i + 1\n",
    "# print(storage_p1)\n",
    "\n",
    "# Separate certain features to 2 sections (each section contains 4 features)\n",
    "i = 0 # i is the index of feature name\n",
    "for idx in indices_p2:\n",
    "    p = 0\n",
    "    count = 0\n",
    "    for col in timeseries_cols:\n",
    "        if idx in col:\n",
    "            if count < 4:\n",
    "                storage_p2[i+2*p].append(col)\n",
    "                count = count + 1\n",
    "            else:\n",
    "                count = 0\n",
    "                p = p + 1\n",
    "                storage_p2[i+2*p].append(col)\n",
    "                count = count + 1\n",
    "    i = i + 1\n",
    "\n",
    "for i in range(len(indices_p1)):\n",
    "    df_totalaverage.loc[:,indices_p1[i]] = df[storage_p1[i]].mean(axis=1)\n",
    "\n",
    "for i in range(len(indices_p2)):\n",
    "    for p in range(2):\n",
    "        name = indices_p2[i][0:4] + ' ' + indices_p2[i][5:] + ' p' + str(p+1)\n",
    "        df_totalaverage.loc[:,name] = df[storage_p2[i+2*p]].mean(axis=1)       \n",
    "\n",
    "label_idx = 0\n",
    "for item in label_dict:\n",
    "    for p in range(13):\n",
    "        name = label_str[label_idx] + ' p' + str(p+1)\n",
    "        df_totalaverage.loc[:,name] = df[item['p'+str(p+1)]].mean(axis=1)\n",
    "    label_idx = label_idx + 1\n",
    "        \n",
    "    \n",
    "df_totalaverage = df_totalaverage.fillna(0)\n",
    "display(df_totalaverage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hemoglobin</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Phosphate</th>\n",
       "      <th>FRR</th>\n",
       "      <th>Clinic code</th>\n",
       "      <th>CAPD0APD1Mix2 modality</th>\n",
       "      <th>Center size (patients)</th>\n",
       "      <th>Initial modality of PD</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>...</th>\n",
       "      <th>PAS mean months 2Y</th>\n",
       "      <th>PAD mean months 2Y</th>\n",
       "      <th>Use antihypertensive drug mean months 2Y</th>\n",
       "      <th>ACE-inhibitor mean months 2Y</th>\n",
       "      <th>ATI blocker mean months 2Y</th>\n",
       "      <th>beta-blocker mean months 2Y</th>\n",
       "      <th>calcium antagonist mean months 2Y</th>\n",
       "      <th>diuretic mean months 2Y</th>\n",
       "      <th>Mean PAS 3T</th>\n",
       "      <th>Mean PAD 3T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.933333</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2</td>\n",
       "      <td>20.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.766667</td>\n",
       "      <td>5.933333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>28.3</td>\n",
       "      <td>...</td>\n",
       "      <td>135.666667</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.833333</td>\n",
       "      <td>4.366667</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.2</td>\n",
       "      <td>31.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.066667</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.3</td>\n",
       "      <td>27.1</td>\n",
       "      <td>...</td>\n",
       "      <td>174.666667</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.333333</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.933333</td>\n",
       "      <td>4.033333</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.333333</td>\n",
       "      <td>72.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>8.400000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>9.700000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>3.233333</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>10.466667</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>4.466667</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>11.766667</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>9.866667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5707 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hemoglobin  Potassium  Phosphate  FRR  Clinic code  \\\n",
       "0      12.933333   4.433333   5.300000    0            1   \n",
       "1      14.000000   3.766667   5.933333    0            1   \n",
       "2      11.833333   4.366667   6.100000    1            1   \n",
       "3      10.066667   4.733333   5.533333    1            1   \n",
       "4      11.933333   4.033333   4.066667    0            1   \n",
       "...          ...        ...        ...  ...          ...   \n",
       "5702    8.400000   5.500000   4.700000    1          347   \n",
       "5703    9.700000   4.300000   3.233333    1          347   \n",
       "5704   10.466667   4.433333   4.466667    1          347   \n",
       "5705   11.766667   4.533333   3.566667    1          347   \n",
       "5706    9.866667   4.000000   4.100000    1          347   \n",
       "\n",
       "      CAPD0APD1Mix2 modality  Center size (patients)  Initial modality of PD  \\\n",
       "0                          0                     128                     0.0   \n",
       "1                          0                     128                     0.0   \n",
       "2                          1                     128                     1.0   \n",
       "3                          0                     128                     0.0   \n",
       "4                          2                     128                     0.0   \n",
       "...                      ...                     ...                     ...   \n",
       "5702                       1                      66                     1.0   \n",
       "5703                       1                      66                     1.0   \n",
       "5704                       1                      66                     1.0   \n",
       "5705                       1                      66                     1.0   \n",
       "5706                       1                      66                     1.0   \n",
       "\n",
       "       Age   BMI  ...  PAS mean months 2Y  PAD mean months 2Y  \\\n",
       "0     71.2  20.7  ...            0.000000                 0.0   \n",
       "1     23.3  28.3  ...          135.666667                73.0   \n",
       "2     49.2  31.5  ...            0.000000                 0.0   \n",
       "3     48.3  27.1  ...          174.666667                84.0   \n",
       "4     93.7  23.1  ...            0.000000                 0.0   \n",
       "...    ...   ...  ...                 ...                 ...   \n",
       "5702  31.8  22.0  ...            0.000000                 0.0   \n",
       "5703  57.0  21.5  ...            0.000000                 0.0   \n",
       "5704  84.0  23.5  ...            0.000000                 0.0   \n",
       "5705  54.2  35.0  ...            0.000000                 0.0   \n",
       "5706  77.8  20.6  ...            0.000000                 0.0   \n",
       "\n",
       "      Use antihypertensive drug mean months 2Y  ACE-inhibitor mean months 2Y  \\\n",
       "0                                          0.0                           0.0   \n",
       "1                                          0.0                           0.0   \n",
       "2                                          0.0                           0.0   \n",
       "3                                          1.0                           1.0   \n",
       "4                                          0.0                           0.0   \n",
       "...                                        ...                           ...   \n",
       "5702                                       0.0                           0.0   \n",
       "5703                                       0.0                           0.0   \n",
       "5704                                       0.0                           0.0   \n",
       "5705                                       0.0                           0.0   \n",
       "5706                                       0.0                           0.0   \n",
       "\n",
       "      ATI blocker mean months 2Y  beta-blocker mean months 2Y  \\\n",
       "0                            0.0                          0.0   \n",
       "1                            0.0                          0.0   \n",
       "2                            0.0                          0.0   \n",
       "3                            0.0                          0.0   \n",
       "4                            0.0                          0.0   \n",
       "...                          ...                          ...   \n",
       "5702                         0.0                          0.0   \n",
       "5703                         0.0                          0.0   \n",
       "5704                         0.0                          0.0   \n",
       "5705                         0.0                          0.0   \n",
       "5706                         0.0                          0.0   \n",
       "\n",
       "      calcium antagonist mean months 2Y  diuretic mean months 2Y  Mean PAS 3T  \\\n",
       "0                              0.000000                      0.0     0.000000   \n",
       "1                              0.000000                      0.0   136.000000   \n",
       "2                              0.000000                      0.0   147.000000   \n",
       "3                              0.333333                      0.0   169.333333   \n",
       "4                              0.000000                      0.0   129.333333   \n",
       "...                                 ...                      ...          ...   \n",
       "5702                           0.000000                      0.0   120.000000   \n",
       "5703                           0.000000                      0.0     0.000000   \n",
       "5704                           0.000000                      0.0     0.000000   \n",
       "5705                           0.000000                      0.0     0.000000   \n",
       "5706                           0.000000                      0.0     0.000000   \n",
       "\n",
       "      Mean PAD 3T  \n",
       "0        0.000000  \n",
       "1       82.000000  \n",
       "2       80.000000  \n",
       "3       99.000000  \n",
       "4       72.666667  \n",
       "...           ...  \n",
       "5702    80.000000  \n",
       "5703     0.000000  \n",
       "5704     0.000000  \n",
       "5705     0.000000  \n",
       "5706     0.000000  \n",
       "\n",
       "[5707 rows x 65 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline = df[unique_cols].copy()\n",
    "\n",
    "numofpatient = baseline.shape[0]\n",
    "\n",
    "# labelnames = ['Ureia', 'Creatinine', 'TGP', 'Potassium', 'Calcium', 'Phosphate', 'Glucose', \n",
    "#               'Hemoglobin', 'Hematocrit','Volume_Total', 'N_AH_', 'Systolic', 'Diastolic',\n",
    "#              'PAS', 'PAD', 'Uso_de_anti_hipert', 'inibidor']\n",
    "\n",
    "# remove Volume_Total and N_AH_\n",
    "labelnames = ['Ureia', 'Creatinine', 'TGP', 'Potassium', 'Calcium', 'Phosphate', 'Glucose', \n",
    "              'Hemoglobin', 'Hematocrit', 'Systolic', 'Diastolic',\n",
    "             'PAS', 'PAD', 'Use antihypertensive drug', 'ACE-inhibitor', 'ATI blocker', 'beta-blocker',\n",
    "              'calcium antagonist', 'diuretic']\n",
    "\n",
    "dfs = [df[unique_cols], df[unique_cols], df[unique_cols]]\n",
    "maxmonths = [6, 18, 30]\n",
    "\n",
    "\n",
    "for year in range(3):\n",
    "    dfs[year] = dfs[year].rename(columns={\"codigoclinica\": \"Clinic code\",\\\n",
    "                                                  \"ModalidadeCAPD0APD1Mix2\": \"CAPD0APD1Mix2 modality\",\\\n",
    "                                                  \"CenterSizenpatients\": \"Center size (patients)\",\\\n",
    "                                                  \"ModalidadeDPInicial\": \"Initial modality of PD\",\\\n",
    "                                                  \"IncidentinPD\": \"Incident in PD\",\\\n",
    "                                                  \"PrevalentinPDNet\": \"Prevalent in PD Net\",\\\n",
    "                                                  \"DialysisvintageprePDNet\": \"Dialysis vintage pre PD Net\",\\\n",
    "                                                  \"totaldialysisvintage\": \"Total dialysis vintage\",\\\n",
    "                                                  \"Primaryrenaldisease\": \"Primary renal disease\",\\\n",
    "                                                  \"PreviousHD\": \"Previous HD\",\\\n",
    "                                                  \"Previoustx\": \"Previous tx\",\\\n",
    "                                                  \"DaviesScore\": \"Davies Score\",\\\n",
    "                                                  \"Peripheralarterydisease\": \"Peripheral artery disease\",\\\n",
    "                                                  \"Familyincome\": \"Family income\",\\\n",
    "                                                  \"Distancefromcenter\": \"Distance from center\",\\\n",
    "                                                  \"predialysiscare\": \"Predialysis care\",\\\n",
    "                                                  \"timeofpredialysiscare\": \"Time of predialysis care\",\\\n",
    "                                                  \"Racedicwhite\": \"Race is white\",\\\n",
    "                                                  \"Educationdic4y\": \"Education more than 4 years\",\\\n",
    "                                                  \"Centerexperiencepatientyear\": \"Center experience (patient-year)\",\\\n",
    "                                                  \"cidade\": \"City\"})\n",
    "    \n",
    "    \n",
    "    for labelname in labelnames:\n",
    "        for patient_idx in range(numofpatient):\n",
    "            # compute the max index of month including nonzero data\n",
    "            maxmonth = maxmonths[year]\n",
    "            maxname = labelname + str(maxmonth)\n",
    "            temp = df.at[patient_idx, maxname]\n",
    "            while temp == 0 and maxmonth >= maxmonths[year]-5:\n",
    "                maxmonth = maxmonth - 1\n",
    "                maxname = labelname + str(maxmonth)\n",
    "                if maxmonth >= maxmonths[year]-5:\n",
    "                    temp = df.at[patient_idx, maxname]\n",
    "\n",
    "            # compute the average of 3 months\n",
    "            mean_months = 0\n",
    "            if maxmonth >= maxmonths[year]-3:\n",
    "                for i in range(maxmonth-2, maxmonth+1):\n",
    "                    name = labelname + str(i)\n",
    "                    mean_months = mean_months + df.at[patient_idx, name]\n",
    "                mean_months = mean_months/3\n",
    "            elif maxmonth == maxmonths[year]-4:\n",
    "                for i in range(maxmonth-1, maxmonth+1):\n",
    "                    name = labelname + str(i)\n",
    "                    mean_months = mean_months + df.at[patient_idx, name]\n",
    "                mean_months = mean_months/2\n",
    "            elif maxmonth == maxmonths[year]-5:\n",
    "                name = labelname + str(maxmonth)\n",
    "                mean_months = df.at[patient_idx, name]\n",
    "            else:\n",
    "                mean_months = 0\n",
    "            yearname = str(year+1)+'Y'\n",
    "            name = labelname + ' mean months ' + yearname\n",
    "            dfs[year].loc[patient_idx, name] = mean_months\n",
    "\n",
    "\n",
    "extra_1y = ['Mean_PAS_1T', 'Mean_PAD_1T']\n",
    "extra_2y = ['Mean_PAS_3T', 'Mean_PAD_3T']\n",
    "extra_3y = ['Mean_PAS_5T', 'Mean_PAD_5T']\n",
    "extras = [extra_1y, extra_2y, extra_3y]\n",
    "\n",
    "for year in range(3):\n",
    "    for index in extras[year]:\n",
    "            new_name = index[0:4] + ' ' + index[5:8] + ' ' + index[9:]\n",
    "            dfs[year].loc[:,new_name] = df[index]    \n",
    "    dfs[year] = dfs[year].fillna(0)\n",
    "    dfs[year].drop(columns = ['Total dialysis vintage'] , inplace=True)\n",
    "        \n",
    "display(dfs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated learning binary classification\n",
    "\n",
    "* The follow-up event in the 1st, 2nd and 3rd year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 1 #input year you want to investigate\n",
    "\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE_BUFFER = 50\n",
    "\n",
    "client_learning_rate = 0.01\n",
    "server_learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data: \n",
      " X's shape: (5707, 65) \n",
      " y's shape: (5707, 1)\n",
      "unique client IDs: [1, 2, 3, 5, 6, 10, 12, 18, 23, 26, 30, 31, 33, 35, 43, 51, 54, 56, 57, 63, 67, 68, 69, 74, 77, 81, 82, 88, 92, 94, 95, 96, 102, 103, 106, 107, 109, 111, 112, 113, 115, 117, 119, 124, 125, 128, 132, 133, 134, 135, 140, 141, 144, 145, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 167, 171, 172, 174, 176, 177, 179, 180, 184, 186, 187, 191, 201, 208, 210, 214, 216, 217, 218, 221, 223, 226, 227, 229, 235, 237, 241, 248, 251, 258, 261, 262, 263, 267, 269, 270, 279, 280, 281, 283, 287, 290, 314, 320, 322, 331, 333, 334, 335, 336, 342, 343, 345, 346, 347]\n",
      "number of unique client IDs: 121\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "if year == 1:\n",
    "    X_full = dfs[0].copy()\n",
    "    temp = Y[\"Followup\"]\n",
    "\n",
    "    n_full = X_full.shape[0]\n",
    "    n_features = X_full.shape[1]\n",
    "\n",
    "    y_full_array = np.zeros((n_full, ))\n",
    "    for i in range(n_full):\n",
    "        if temp[i] >= 12:\n",
    "            y_full_array[i] = 1\n",
    "\n",
    "    y_full = pd.DataFrame({'label': y_full_array})\n",
    "    \n",
    "elif year == 2:\n",
    "    X_full = dfs[1].copy()\n",
    "    indexNames = df[df[\"Followup1y\"] < 12].index\n",
    "\n",
    "    temp = Y[\"Followup\"]\n",
    "\n",
    "    n_full = X_full.shape[0]\n",
    "    n_features = X_full.shape[1]\n",
    "\n",
    "    y_full_array = np.zeros((n_full, ))\n",
    "    for i in range(n_full):\n",
    "        if temp[i] >= 24:\n",
    "            y_full_array[i] = 1\n",
    "\n",
    "    y_full = pd.DataFrame({'label': y_full_array})\n",
    "\n",
    "    X_full.drop(indexNames , inplace=True)\n",
    "    y_full.drop(indexNames , inplace=True)\n",
    "    \n",
    "elif year == 3:\n",
    "    X_full = dfs[2].copy()\n",
    "    indexNames = df[df[\"Followup2y\"] < 24].index\n",
    "\n",
    "    temp = Y[\"Followup\"]\n",
    "\n",
    "    n_full = X_full.shape[0]\n",
    "    n_features = X_full.shape[1]\n",
    "\n",
    "    y_full_array = np.zeros((n_full, ))\n",
    "    for i in range(n_full):\n",
    "        if temp[i] >= 36:\n",
    "            y_full_array[i] = 1\n",
    "\n",
    "    y_full = pd.DataFrame({'label': y_full_array})\n",
    "\n",
    "    X_full.drop(indexNames , inplace=True)\n",
    "    y_full.drop(indexNames , inplace=True)\n",
    "\n",
    "else:\n",
    "    print('Invalid year number! Please enter again.')\n",
    "\n",
    "    \n",
    "print(f\"Full Data: \\n X's shape: {X_full.shape} \\n y's shape: {y_full.shape}\")    \n",
    "    \n",
    "plt.figure()\n",
    "client_ids = X_full['Clinic code']\n",
    "client_ids.plot.hist()\n",
    "\n",
    "unique_client_ids = set(client_ids)\n",
    "unique_client_ids = list(unique_client_ids)\n",
    "num_unique_client_ids = len(unique_client_ids)\n",
    "\n",
    "print('unique client IDs:', unique_client_ids)\n",
    "print('number of unique client IDs:', num_unique_client_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def make_federated_data(X_full, y_full, selected_client_ids):\n",
    "    X_res = pd.DataFrame()\n",
    "    y_res = pd.DataFrame()\n",
    "#     y_res = []\n",
    "#     y_res = np.array(y_res)\n",
    "    for selected_id in selected_client_ids:\n",
    "        X_selected = X_full.loc[X_full['Clinic code'] == selected_id]\n",
    "        X_res = pd.concat([X_res, X_selected], ignore_index=True)\n",
    "        y_selected = y_full.loc[X_selected.index]\n",
    "        y_res = pd.concat([y_res, y_selected], ignore_index=True)\n",
    "        \n",
    "    X_res.to_numpy\n",
    "    X_res = tf.convert_to_tensor(X_res, dtype=tf.float32)\n",
    "    y_res.to_numpy\n",
    "\n",
    "    y_res = tf.convert_to_tensor(y_res, dtype=tf.int32)\n",
    "    print('Number of samples: %d' % X_res.shape[0])\n",
    "#     print(X_res.shape)\n",
    "#     print(y_res.shape)\n",
    "\n",
    "    res = tf.data.Dataset.from_tensor_slices((X_res, y_res))\n",
    "\n",
    "    res = res.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def select_largest_clients(client_ids, k=10):\n",
    "    sorted_list = [item for items, c in Counter(client_ids).most_common() \n",
    "                                      for item in [items]] \n",
    "    result = sorted_list[:k]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model():\n",
    "    model = keras.Sequential([\n",
    "                keras.layers.InputLayer(input_shape=(65,)),\n",
    "                keras.layers.Dense(units=32, activation='relu',dtype='float64'),\n",
    "                keras.layers.Dense(units=1, activation='sigmoid',dtype='float64')\n",
    "            ])\n",
    "    return model\n",
    "\n",
    "def model_fn():\n",
    "  # We _must_ create a new model here, and _not_ capture it from an external\n",
    "  # scope. TFF will call this within different graph contexts.\n",
    "    \n",
    "#     input_spec = collections.OrderedDict(\n",
    "#         x=tf.TensorSpec(shape=[None, 66], dtype=tf.float32),\n",
    "#         y=tf.TensorSpec(shape=[None, 1], dtype=tf.int32))\n",
    "    keras_model = create_keras_model()\n",
    "    return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      input_spec=input_spec,\n",
    "      loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split by clinic ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected clinic codes for testing:  [174, 2, 261, 281, 270, 82, 134, 94, 343, 54, 172, 208, 201, 57, 263, 333, 150, 241, 346, 94, 96, 201, 112, 152]\n",
      "Number of samples: 1247\n"
     ]
    }
   ],
   "source": [
    "# import random\n",
    "\n",
    "# # select clients randomly\n",
    "# test_client_library = list()\n",
    "# for client_id in unique_client_ids:\n",
    "#     if client_id not in selected_client_ids:\n",
    "#         test_client_library.append(client_id)\n",
    "\n",
    "# test_client_ids = random.choices(unique_client_ids, k=24)\n",
    "test_client_ids = [174, 2, 261, 281, 270, 82, 134, 94, 343, 54, 172, 208, 201, 57, 263, 333, 150, 241, 346, 94, 96, 201, 112, 152]\n",
    "\n",
    "print('Selected clinic codes for testing: ', test_client_ids)\n",
    "\n",
    "federated_test_data = make_federated_data(X_full, y_full, test_client_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected clinic codes for training:  [10, 157, 88, 159, 132, 135, 167, 12, 124, 147, 125, 117, 216, 125, 113, 159, 157, 147, 153, 334, 336, 119, 68, 43, 5, 223, 63, 10, 109, 167, 3, 77, 68, 167, 95, 51, 216, 3, 347, 167, 23, 176, 5, 216, 218, 63, 43, 218, 1, 124, 26, 151, 248, 115, 334, 132, 223, 111, 210, 235, 35, 154, 235, 117, 88, 279, 128, 117, 237, 262, 117, 18, 132, 210, 153, 103, 63, 30, 320, 77, 111, 133, 30, 5, 237, 106, 63, 320, 106, 167, 35, 124, 33, 30, 30, 154, 235]\n",
      "Number of samples: 7539\n"
     ]
    }
   ],
   "source": [
    "## Test making federated data\n",
    "import random\n",
    "\n",
    "# # select clients randomly\n",
    "# selected_client_ids = random.choices(unique_client_ids, k=10)\n",
    "\n",
    "# select clients according to frequency\n",
    "client_ids_without_test = []\n",
    "for index in client_ids:\n",
    "    if index not in test_client_ids:\n",
    "        client_ids_without_test.append(index)\n",
    "\n",
    "# selected_client_ids = select_largest_clients(client_ids_without_test, k=12)\n",
    "selected_client_ids = random.choices(client_ids_without_test, k=97)\n",
    "\n",
    "print('Selected clinic codes for training: ', selected_client_ids)\n",
    "\n",
    "federated_train_data = make_federated_data(X_full, y_full, selected_client_ids)\n",
    "\n",
    "input_spec = federated_train_data.element_spec\n",
    "\n",
    "# print(input_spec)\n",
    "\n",
    "# for itr in federated_train_data:\n",
    "#     print(itr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterative_process = tff.learning.build_federated_averaging_process(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.Adam())\n",
    "\n",
    "# str(iterative_process.initialize.type_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  0, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65990186), ('recall', 0.74240696), ('precision', 0.6936207), ('loss', 0.68086034)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round  1, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65848696), ('recall', 0.7382964), ('precision', 0.6935288), ('loss', 0.68208724)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round  2, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.66127247), ('recall', 0.7459085), ('precision', 0.69388187), ('loss', 0.6845831)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round  3, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6595481), ('recall', 0.74347264), ('precision', 0.6928424), ('loss', 0.6762602)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round  4, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65596676), ('recall', 0.7403517), ('precision', 0.68998295), ('loss', 0.6900491)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round  5, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6598134), ('recall', 0.7404278), ('precision', 0.6942402), ('loss', 0.6821573)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round  6, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.66206837), ('recall', 0.74347264), ('precision', 0.6956553), ('loss', 0.6782528)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round  7, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.66304106), ('recall', 0.7459846), ('precision', 0.69582504), ('loss', 0.6661622)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round  8, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.664058), ('recall', 0.7479638), ('precision', 0.6962375), ('loss', 0.6720942)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round  9, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6643675), ('recall', 0.7465936), ('precision', 0.697086), ('loss', 0.66909707)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 10, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65844274), ('recall', 0.7390576), ('precision', 0.6932029), ('loss', 0.6818276)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 11, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6599461), ('recall', 0.7429398), ('precision', 0.69347733), ('loss', 0.68105656)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 12, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.66025555), ('recall', 0.74012333), ('precision', 0.6948474), ('loss', 0.6713643)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 13, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6606535), ('recall', 0.74096066), ('precision', 0.69498783), ('loss', 0.6728322)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 14, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6619799), ('recall', 0.74491894), ('precision', 0.6950284), ('loss', 0.67374164)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 15, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.66777205), ('recall', 0.7473548), ('precision', 0.70063514), ('loss', 0.6692263)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 16, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6574258), ('recall', 0.73745906), ('precision', 0.69264317), ('loss', 0.6732535)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 17, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.66927534), ('recall', 0.7524549), ('precision', 0.70041806), ('loss', 0.6554617)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 18, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6617146), ('recall', 0.7460607), ('precision', 0.69431853), ('loss', 0.67464644)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 19, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6636159), ('recall', 0.74568015), ('precision', 0.6965797), ('loss', 0.6667205)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 20, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6642791), ('recall', 0.7447667), ('precision', 0.69766116), ('loss', 0.66339266)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 21, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.665915), ('recall', 0.74834436), ('precision', 0.69817483), ('loss', 0.65879256)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 22, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.66202414), ('recall', 0.74233085), ('precision', 0.69602454), ('loss', 0.66169316)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 23, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.66206837), ('recall', 0.741798), ('precision', 0.69627035), ('loss', 0.6569017)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 24, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6641464), ('recall', 0.7429398), ('precision', 0.69819015), ('loss', 0.66589713)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 25, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.66631293), ('recall', 0.7495623), ('precision', 0.6981707), ('loss', 0.65583676)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 26, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6661803), ('recall', 0.74705034), ('precision', 0.6989531), ('loss', 0.6574186)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 27, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.66542864), ('recall', 0.74362487), ('precision', 0.69938433), ('loss', 0.66846824)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 28, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.671265), ('recall', 0.75451016), ('precision', 0.7018836), ('loss', 0.64981335)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 29, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.66392535), ('recall', 0.7440055), ('precision', 0.69754493), ('loss', 0.66564053)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 30, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6648539), ('recall', 0.7444622), ('precision', 0.6984218), ('loss', 0.6641089)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 31, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6706902), ('recall', 0.7533684), ('precision', 0.70166606), ('loss', 0.64741224)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 32, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6653845), ('recall', 0.7460607), ('precision', 0.6984251), ('loss', 0.6606306)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 33, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6618473), ('recall', 0.74423385), ('precision', 0.69512975), ('loss', 0.6669049)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 34, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6645002), ('recall', 0.7452995), ('precision', 0.69771254), ('loss', 0.65671694)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 35, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6716629), ('recall', 0.75557584), ('precision', 0.7019306), ('loss', 0.65096706)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 36, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6676836), ('recall', 0.7491817), ('precision', 0.6998507), ('loss', 0.65217024)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 37, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.66622454), ('recall', 0.7479638), ('precision', 0.69866323), ('loss', 0.65927315)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 38, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6670646), ('recall', 0.75047576), ('precision', 0.6986748), ('loss', 0.646701)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 39, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.673122), ('recall', 0.7582401), ('precision', 0.70256734), ('loss', 0.6440951)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 40, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.67091125), ('recall', 0.75237876), ('precision', 0.7022879), ('loss', 0.6490274)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 41, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.67153025), ('recall', 0.7526833), ('precision', 0.70287174), ('loss', 0.64833736)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 42, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.66914266), ('recall', 0.75017124), ('precision', 0.7011241), ('loss', 0.6478715)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 43, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.66847944), ('recall', 0.75314), ('precision', 0.69927204), ('loss', 0.6559303)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 44, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6673741), ('recall', 0.7485727), ('precision', 0.6997296), ('loss', 0.6501367)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 45, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.66967326), ('recall', 0.7488011), ('precision', 0.7022416), ('loss', 0.6489962)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 46, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.67360836), ('recall', 0.7568699), ('precision', 0.7036303), ('loss', 0.6384739)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 47, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.67206085), ('recall', 0.75443405), ('precision', 0.70280814), ('loss', 0.64203346)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 48, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.67055756), ('recall', 0.75184596), ('precision', 0.70208985), ('loss', 0.6458001)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n",
      "round 49, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.671884), ('recall', 0.75222653), ('precision', 0.7034453), ('loss', 0.638848)])), ('stat', OrderedDict([('num_examples', 22617)]))])\n"
     ]
    }
   ],
   "source": [
    "NUM_ROUNDS = 50\n",
    "for round_num in range(NUM_ROUNDS):\n",
    "  state, metrics = iterative_process.next(state, [federated_train_data])\n",
    "  print('round {:2d}, metrics={}'.format(round_num, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Year: 1 Recall: 0.59579813 Precision: 0.7439407 F1 score: 0.6616789375218105\n",
      "Test: Year: 1 Recall: 0.66803277 Precision: 0.6143216 F1 score: 0.6400523360748471\n"
     ]
    }
   ],
   "source": [
    "# evaluation the model\n",
    "evaluation = tff.learning.build_federated_evaluation(model_fn)\n",
    "# str(evaluation.type_signature)\n",
    "\n",
    "train_metrics = evaluation(state.model, [federated_train_data])\n",
    "\n",
    "recall_train = train_metrics['recall']\n",
    "precision_train = train_metrics['precision']\n",
    "f1_train = 2 * recall_train * precision_train / (recall_train + precision_train)\n",
    "print('Train:',\n",
    "      'Year:', year,\n",
    "      'Recall:', recall_train,\n",
    "      'Precision:', precision_train,\n",
    "      'F1 score:', f1_train)\n",
    "\n",
    "test_metrics = evaluation(state.model, [federated_test_data])\n",
    "\n",
    "recall_test = test_metrics['recall']\n",
    "precision_test = test_metrics['precision']\n",
    "f1_test = 2 * recall_test * precision_test / (recall_test + precision_test)\n",
    "print('Test:',\n",
    "      'Year:', year,\n",
    "      'Recall:', recall_test,\n",
    "      'Precision:', precision_test,\n",
    "      'F1 score:', f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trained_model = create_keras_model()\n",
    "\n",
    "state.model.assign_weights_to(\n",
    "    trained_model\n",
    ")\n",
    "\n",
    "prediction = trained_model.predict(X_full)\n",
    "\n",
    "# print(prediction)\n",
    "# print(y_full)\n",
    "\n",
    "\n",
    "plt.hist(prediction)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist(y_full)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split by train-test ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test data\n",
    "import random\n",
    "\n",
    "\n",
    "def split_data_federated(X_full, y_full, train_ratio):\n",
    "    X_train = pd.DataFrame()\n",
    "    y_train = pd.DataFrame()\n",
    "    X_test = pd.DataFrame()\n",
    "    y_test = pd.DataFrame()\n",
    "#     y_res = []\n",
    "#     y_res = np.array(y_res)\n",
    "\n",
    "    train_num = int(train_ratio * X_full.shape[0])\n",
    "    test_num = X_full.shape[0] - train_num\n",
    "    \n",
    "    train_ids = random.sample(range(X_full.shape[0]), train_num)\n",
    "    test_ids = random.sample(range(X_full.shape[0]), test_num)\n",
    "    \n",
    "    X_train = X_full.iloc[train_ids]\n",
    "    y_train = y_full.iloc[train_ids]\n",
    "    X_test = X_full.iloc[test_ids]\n",
    "    y_test = y_full.iloc[test_ids]\n",
    "    \n",
    "#     for selected_id in selected_client_ids:\n",
    "#         X_selected = X_full.loc[X_full['Clinic code'] == selected_id]\n",
    "#         X_res = pd.concat([X_res, X_selected], ignore_index=True)\n",
    "#         y_selected = y_full.loc[X_selected.index]\n",
    "#         y_res = pd.concat([y_res, y_selected], ignore_index=True)\n",
    "        \n",
    "    X_train.to_numpy\n",
    "    X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "    y_train.to_numpy\n",
    "    y_train = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "    X_test.to_numpy\n",
    "    X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "    y_test.to_numpy\n",
    "    y_test = tf.convert_to_tensor(y_test, dtype=tf.int32)\n",
    "    \n",
    "#     print(X_res.shape)\n",
    "#     print(y_res.shape)\n",
    "\n",
    "    train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "    train_set = train_set.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE)\n",
    "    test_set = test_set.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE)\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "federated_train_data, federated_test_data = split_data_federated(X_full, y_full, train_ratio)\n",
    "input_spec = federated_train_data.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterative_process = tff.learning.build_federated_averaging_process(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  0, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63817495), ('recall', 0.7171956), ('precision', 0.6754637), ('loss', 0.6901554)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round  1, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6400571), ('recall', 0.72180957), ('precision', 0.6760118), ('loss', 0.68861943)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round  2, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.635514), ('recall', 0.7086428), ('precision', 0.67535394), ('loss', 0.7068531)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round  3, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6375909), ('recall', 0.71652037), ('precision', 0.6750424), ('loss', 0.6937465)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round  4, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6390187), ('recall', 0.71787083), ('precision', 0.6761713), ('loss', 0.69609326)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round  5, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64700156), ('recall', 0.7252982), ('precision', 0.68251616), ('loss', 0.688168)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round  6, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63616306), ('recall', 0.713707), ('precision', 0.6743939), ('loss', 0.69445276)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round  7, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64719623), ('recall', 0.7284492), ('precision', 0.6816554), ('loss', 0.6716918)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round  8, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64654726), ('recall', 0.7297997), ('precision', 0.6804827), ('loss', 0.6737655)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round  9, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6431724), ('recall', 0.71955884), ('precision', 0.6802128), ('loss', 0.6981591)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 10, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6427181), ('recall', 0.7197839), ('precision', 0.6796302), ('loss', 0.6891185)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 11, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64213395), ('recall', 0.72180957), ('precision', 0.6782995), ('loss', 0.6907641)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 12, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64648235), ('recall', 0.7251857), ('precision', 0.6819769), ('loss', 0.678541)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 13, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.644081), ('recall', 0.7228224), ('precision', 0.6801143), ('loss', 0.67871124)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 14, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6445353), ('recall', 0.7234976), ('precision', 0.68038946), ('loss', 0.68299353)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 15, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64258826), ('recall', 0.71640784), ('precision', 0.68063724), ('loss', 0.6818123)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 16, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6427181), ('recall', 0.71865857), ('precision', 0.68001276), ('loss', 0.68583214)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 17, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6401869), ('recall', 0.71708304), ('precision', 0.6777281), ('loss', 0.68863523)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 18, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.638824), ('recall', 0.710781), ('precision', 0.67833745), ('loss', 0.68733376)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 19, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6449247), ('recall', 0.72721136), ('precision', 0.67956674), ('loss', 0.6762181)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 20, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63869417), ('recall', 0.7138195), ('precision', 0.6771645), ('loss', 0.69992846)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 21, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6372014), ('recall', 0.713707), ('precision', 0.67554325), ('loss', 0.698357)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 22, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6482996), ('recall', 0.7265361), ('precision', 0.6835363), ('loss', 0.6724302)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 23, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.63733125), ('recall', 0.70684224), ('precision', 0.67800087), ('loss', 0.7035416)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 24, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64816976), ('recall', 0.7269863), ('precision', 0.68323636), ('loss', 0.67570424)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 25, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6442108), ('recall', 0.72473556), ('precision', 0.6796116), ('loss', 0.67662674)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 26, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6471314), ('recall', 0.7279991), ('precision', 0.68173677), ('loss', 0.669033)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 27, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6491433), ('recall', 0.730925), ('precision', 0.6829653), ('loss', 0.668366)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 28, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64479494), ('recall', 0.72428536), ('precision', 0.6804102), ('loss', 0.67727125)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 29, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65122014), ('recall', 0.73317575), ('precision', 0.6844925), ('loss', 0.66358787)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 30, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6501168), ('recall', 0.7295746), ('precision', 0.6845106), ('loss', 0.6708969)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 31, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64518434), ('recall', 0.72327256), ('precision', 0.6811871), ('loss', 0.6746377)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 32, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6482996), ('recall', 0.72293496), ('precision', 0.6847884), ('loss', 0.6792497)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 33, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6523884), ('recall', 0.7345262), ('precision', 0.6853213), ('loss', 0.6573555)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 34, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64161474), ('recall', 0.7147198), ('precision', 0.6801242), ('loss', 0.6882012)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 35, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6492731), ('recall', 0.72901195), ('precision', 0.68376607), ('loss', 0.6663135)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 36, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6476506), ('recall', 0.72316), ('precision', 0.6839808), ('loss', 0.67510456)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 37, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6450545), ('recall', 0.7191087), ('precision', 0.68247354), ('loss', 0.68229365)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 38, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64252335), ('recall', 0.7126941), ('precision', 0.6818476), ('loss', 0.6903934)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 39, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6439512), ('recall', 0.72045916), ('precision', 0.68077415), ('loss', 0.6785182)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 40, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65122014), ('recall', 0.7334009), ('precision', 0.68441504), ('loss', 0.65998054)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 41, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6449896), ('recall', 0.71899617), ('precision', 0.6824396), ('loss', 0.68178886)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 42, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6522586), ('recall', 0.7302498), ('precision', 0.68666667), ('loss', 0.6631519)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 43, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64167964), ('recall', 0.7144947), ('precision', 0.6802743), ('loss', 0.6880943)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 44, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6458333), ('recall', 0.7258609), ('precision', 0.6810263), ('loss', 0.6659968)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 45, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65478975), ('recall', 0.7344137), ('precision', 0.68803376), ('loss', 0.65734005)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 46, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64388627), ('recall', 0.71584517), ('precision', 0.6822911), ('loss', 0.6797784)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 47, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65511423), ('recall', 0.7355391), ('precision', 0.688), ('loss', 0.6554988)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 48, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6467419), ('recall', 0.72169703), ('precision', 0.68347013), ('loss', 0.6676514)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 49, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6418744), ('recall', 0.71685797), ('precision', 0.67968416), ('loss', 0.673749)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 50, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6446002), ('recall', 0.71865857), ('precision', 0.6821192), ('loss', 0.6787312)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 51, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6496625), ('recall', 0.72822416), ('precision', 0.6844722), ('loss', 0.671146)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 52, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6476506), ('recall', 0.7212469), ('precision', 0.68464905), ('loss', 0.6763788)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 53, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6474559), ('recall', 0.7223723), ('precision', 0.6840367), ('loss', 0.66326565)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 54, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6482996), ('recall', 0.72180957), ('precision', 0.6851832), ('loss', 0.67818993)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 55, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65777516), ('recall', 0.7381274), ('precision', 0.6900579), ('loss', 0.65110433)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 56, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6507009), ('recall', 0.7266487), ('precision', 0.6861849), ('loss', 0.66968834)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 57, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.653297), ('recall', 0.7337385), ('precision', 0.68660486), ('loss', 0.6552762)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 58, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64804), ('recall', 0.7215845), ('precision', 0.68496954), ('loss', 0.67000115)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 59, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6533619), ('recall', 0.733851), ('precision', 0.6866379), ('loss', 0.65902954)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 60, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65524405), ('recall', 0.7337385), ('precision', 0.6887809), ('loss', 0.65713674)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 61, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65297246), ('recall', 0.73069996), ('precision', 0.68730813), ('loss', 0.6556981)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 62, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6523235), ('recall', 0.7267612), ('precision', 0.6879727), ('loss', 0.6588419)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 63, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6522586), ('recall', 0.7304749), ('precision', 0.6865877), ('loss', 0.65531844)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 64, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65634733), ('recall', 0.73115015), ('precision', 0.6909497), ('loss', 0.6571174)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 65, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6549844), ('recall', 0.7345262), ('precision', 0.68821174), ('loss', 0.6479798)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 66, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6549844), ('recall', 0.7305874), ('precision', 0.6896112), ('loss', 0.6513986)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 67, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65206385), ('recall', 0.7340761), ('precision', 0.6851171), ('loss', 0.6555817)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 68, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65595794), ('recall', 0.7363268), ('precision', 0.6886644), ('loss', 0.6511417)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 69, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6575805), ('recall', 0.7391402), ('precision', 0.68948144), ('loss', 0.6481873)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 70, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6545301), ('recall', 0.732388), ('precision', 0.6884587), ('loss', 0.65713614)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 71, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65511423), ('recall', 0.7297997), ('precision', 0.6900404), ('loss', 0.655928)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 72, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6523884), ('recall', 0.7310376), ('precision', 0.6865356), ('loss', 0.6559777)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 73, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65608776), ('recall', 0.7376772), ('precision', 0.6883335), ('loss', 0.6514773)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 74, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65115523), ('recall', 0.7266487), ('precision', 0.68669575), ('loss', 0.6572958)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 75, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6553738), ('recall', 0.73430115), ('precision', 0.688727), ('loss', 0.65343285)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 76, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6490135), ('recall', 0.7209093), ('precision', 0.68630815), ('loss', 0.6693259)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 77, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6510254), ('recall', 0.7249606), ('precision', 0.68714666), ('loss', 0.66439074)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 78, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65524405), ('recall', 0.73002476), ('precision', 0.6901064), ('loss', 0.65940183)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 79, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.64823467), ('recall', 0.720009), ('precision', 0.6857449), ('loss', 0.6836829)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 80, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6546599), ('recall', 0.7281116), ('precision', 0.69013333), ('loss', 0.65588236)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 81, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65167445), ('recall', 0.7266487), ('precision', 0.6872805), ('loss', 0.6532066)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 82, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.656607), ('recall', 0.7334009), ('precision', 0.6904333), ('loss', 0.65072596)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 83, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65673673), ('recall', 0.7337385), ('precision', 0.69045854), ('loss', 0.64753604)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 84, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65076584), ('recall', 0.7249606), ('precision', 0.6868536), ('loss', 0.6559399)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 85, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65517914), ('recall', 0.7286743), ('precision', 0.69051933), ('loss', 0.668978)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 86, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.66082555), ('recall', 0.7412784), ('precision', 0.6923481), ('loss', 0.6450844)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 87, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.653297), ('recall', 0.7305874), ('precision', 0.68771183), ('loss', 0.65578574)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 88, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65245324), ('recall', 0.7283367), ('precision', 0.6875598), ('loss', 0.6554877)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 89, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6519341), ('recall', 0.72574836), ('precision', 0.68789333), ('loss', 0.660088)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 90, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6496625), ('recall', 0.72417283), ('precision', 0.6858879), ('loss', 0.65701807)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 91, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6586189), ('recall', 0.73463875), ('precision', 0.6922588), ('loss', 0.64893615)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 92, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6586189), ('recall', 0.7373396), ('precision', 0.6912851), ('loss', 0.65118784)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 93, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6574507), ('recall', 0.73216295), ('precision', 0.69183326), ('loss', 0.65206933)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 94, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6566719), ('recall', 0.73362595), ('precision', 0.69042575), ('loss', 0.6465091)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 95, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65998185), ('recall', 0.73823994), ('precision', 0.69249445), ('loss', 0.6459393)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 96, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.65096056), ('recall', 0.7249606), ('precision', 0.68707335), ('loss', 0.66527975)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 97, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6485592), ('recall', 0.72327256), ('precision', 0.68496215), ('loss', 0.6624898)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 98, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6490135), ('recall', 0.71955884), ('precision', 0.6867884), ('loss', 0.66609377)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n",
      "round 99, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('binary_accuracy', 0.6548546), ('recall', 0.72934955), ('precision', 0.68990844), ('loss', 0.64892524)])), ('stat', OrderedDict([('num_examples', 15408)]))])\n"
     ]
    }
   ],
   "source": [
    "NUM_ROUNDS = 100\n",
    "for round_num in range(NUM_ROUNDS):\n",
    "  state, metrics = iterative_process.next(state, [federated_train_data])\n",
    "  print('round {:2d}, metrics={}'.format(round_num, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Year: 1 Recall: 0.8629305 Precision: 0.6814183 F1 score: 0.761507568562586\n",
      "Test: Year: 1 Recall: 0.8521739 Precision: 0.7033493 F1 score: 0.7706422420184373\n"
     ]
    }
   ],
   "source": [
    "# evaluation the model\n",
    "evaluation = tff.learning.build_federated_evaluation(model_fn)\n",
    "# str(evaluation.type_signature)\n",
    "\n",
    "train_metrics = evaluation(state.model, [federated_train_data])\n",
    "\n",
    "recall_train = train_metrics['recall']\n",
    "precision_train = train_metrics['precision']\n",
    "f1_train = 2 * recall_train * precision_train / (recall_train + precision_train)\n",
    "print('Train:',\n",
    "      'Year:', year,\n",
    "      'Recall:', recall_train,\n",
    "      'Precision:', precision_train,\n",
    "      'F1 score:', f1_train)\n",
    "\n",
    "test_metrics = evaluation(state.model, [federated_test_data])\n",
    "\n",
    "recall_test = test_metrics['recall']\n",
    "precision_test = test_metrics['precision']\n",
    "f1_test = 2 * recall_test * precision_test / (recall_test + precision_test)\n",
    "print('Test:',\n",
    "      'Year:', year,\n",
    "      'Recall:', recall_test,\n",
    "      'Precision:', precision_test,\n",
    "      'F1 score:', f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trained_model = create_keras_model()\n",
    "\n",
    "state.model.assign_weights_to(\n",
    "    trained_model\n",
    ")\n",
    "\n",
    "prediction = trained_model.predict(X_full)\n",
    "\n",
    "# print(prediction)\n",
    "# print(y_full)\n",
    "\n",
    "\n",
    "plt.hist(prediction)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist(y_full)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
